{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7914f18",
   "metadata": {},
   "source": [
    "# Model Implementation and Learning\n",
    "\n",
    "This notebook is intended for the the main function operations for the projects, including function for preprocessing, learning and prediction results. Toward the end of the notebook we run the code on the imported dataset. The results are then stored locally. Note, the run time may take time,it took circa 8 hours on my personal PC.\n",
    "\n",
    "### Table of code blocks\n",
    "\n",
    "[1) Preprocessing](#1)\n",
    "\n",
    "[2) LSTM](#2)\n",
    "\n",
    "[3) Attention Model](#3)\n",
    "\n",
    "[4) RNN](#4)\n",
    "\n",
    "[5) GRU](#5)\n",
    "\n",
    "[6) CKCNN](#6)\n",
    "\n",
    "[7) Results and Prediction Generators](#7)\n",
    "\n",
    "[8) Data Learner and Optimizer](#8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b4b5bae2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, SimpleRNN,Flatten, Dense\n",
    "from tensorflow.keras.layers import Reshape,  AdditiveAttention, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import ckconv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "set_seed(10)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f9ed0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "T =10 #timesteps\n",
    "ratio = 0.5 # train/test ratio\n",
    "input_D = 5 #input dimension\n",
    "output_D = 1 #output_dimension\n",
    "df = pd.read_csv(\"SP 500 Stock Prices 2014-2017.csv\").sort_values(by  = \"symbol\") # data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79efb2d",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing <a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "51f1a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data according to the relevant timestep offset\n",
    "def preprocessor(data, target_offset ):\n",
    "    scaler_list=[]\n",
    "    n_seq = int((len(data) - (T + target_offset - 1) ))\n",
    "    X = np.zeros((n_seq, T , input_D))\n",
    "    Y = np.zeros((n_seq  ,  output_D))\n",
    "    X_unscaled = np.zeros((n_seq  , T , input_D))\n",
    "    Y_unscaled = np.zeros((n_seq  , output_D))\n",
    "\n",
    "    #use min-max scaler to scale the data\n",
    "    for t in range(n_seq):\n",
    "        input_point = data[t:t+T+target_offset]\n",
    "        scaler = MinMaxScaler().fit(input_point)\n",
    "        scaler_list.append(scaler)\n",
    "        scaled_input_point =scaler.transform(input_point)\n",
    "        feature_inputs = scaled_input_point[:-target_offset]    \n",
    "        target_outputs = scaled_input_point[-1:,3:4][0][0]\n",
    "        feature_inputs_unscaled = input_point[:-target_offset]\n",
    "        targt_outputs_unscaled = input_point[-1:,3:4]\n",
    "\n",
    "        X[t,:,:] = feature_inputs \n",
    "        Y[t,:]=target_outputs\n",
    "        X_unscaled[t,:,:] = feature_inputs_unscaled\n",
    "        Y_unscaled[t,:] = targt_outputs_unscaled\n",
    "                \n",
    "    return X, Y , X_unscaled, Y_unscaled, scaler_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "644d3f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the data to train and test according to the given train-test ratio\n",
    "# consider both scaled data and unscaled\n",
    "def trainTestSplit(ratio,X, Y , X_unscaled, Y_unscaled):\n",
    "\n",
    "    n_train  =  int(len(X) * ratio  )\n",
    "    X_train = X[:n_train]\n",
    "    Y_train = Y[:n_train]\n",
    "    X_test = X[n_train:]\n",
    "    Y_test = Y[n_train:]\n",
    "    \n",
    "    # unscaled - raw data\n",
    "    X_train_unscaled = X_unscaled[:n_train]\n",
    "    Y_train_unscaled = Y_unscaled[:n_train]\n",
    "    X_test_unscaled = X_unscaled[n_train:]\n",
    "    Y_test_unscaled = Y_unscaled[n_train:]\n",
    "    \n",
    "    return X_train,Y_train, X_test, Y_test, X_train_unscaled, Y_train_unscaled, X_test_unscaled, Y_test_unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1a138e",
   "metadata": {},
   "source": [
    "## LSTM Implementation <a name=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d6716a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelLSTM(epochs: int,  X_train, Y_train , X_test, Y_test,lr,units,batch , verbose, callback,plot_summary = True):\n",
    "\n",
    "    i = Input(shape=(T, input_D))\n",
    "    x = LSTM(units)(i)\n",
    "    x = Dense(output_D)(x)\n",
    "\n",
    "    model = Model(i, x)\n",
    "    model.compile(\n",
    "      loss='mse',\n",
    "      optimizer=Adam(learning_rate=lr),)\n",
    "    \n",
    "    if plot_summary == True:\n",
    "        print(model.summary())\n",
    "    \n",
    "    if callback==True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "        r = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                      validation_data=(X_test, Y_test),\n",
    "                      callbacks=[callback], verbose=verbose,batch_size=batch)\n",
    "    else:\n",
    "        r = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                      validation_data=(X_test, Y_test),verbose=verbose,batch_size=batch)        \n",
    "            \n",
    "    return r,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a224b17",
   "metadata": {},
   "source": [
    "## Attention Models <a name=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "30baa693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super().__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "    self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "  def call(self, query, value):\n",
    "\n",
    "    # From Eqn. (4), `W1@ht`.\n",
    "    w1_query = self.W1(query)\n",
    "    # From Eqn. (4), `W2@hs`.\n",
    "    w2_key = self.W2(value)\n",
    "\n",
    "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "    value_mask = tf.ones(tf.shape(value)[:-1], dtype=bool)\n",
    "\n",
    "    context_vector = self.attention(\n",
    "        inputs = [w1_query, value, w2_key],\n",
    "        mask=[query_mask, value_mask],)\n",
    "    \n",
    "    return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0a421cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attentionGRU(epochs: int,  X_train, Y_train , X_test, Y_test,lr,units,batch , verbose, callback,plot_summary = True):\n",
    "\n",
    "    i = Input(shape=(T, input_D))\n",
    "    h_t,h_s = GRU(units,return_sequences = True, return_state = True)(i)\n",
    "    attention_layer = BahdanauAttention(units)\n",
    "    context_vector = attention_layer(query=h_t,value=h_s)\n",
    "    context_and_rnn_output = tf.concat([context_vector, h_t], axis=-1)\n",
    "    context_and_rnn_output = Flatten()(context_and_rnn_output)\n",
    "    output = Dense(1)(context_and_rnn_output )\n",
    "\n",
    "    model = Model(i, output)\n",
    "    model.compile(\n",
    "      loss='mse',\n",
    "      optimizer=Adam(learning_rate=lr),)\n",
    "    \n",
    "    if plot_summary == True:\n",
    "        print(model.summary())\n",
    "    \n",
    "    if callback==True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "        r = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                      validation_data=(X_test, Y_test),\n",
    "                      callbacks=[callback], verbose=verbose,batch_size=batch)\n",
    "    else:\n",
    "        r = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                      validation_data=(X_test, Y_test),verbose=verbose,batch_size=batch)  \n",
    "    \n",
    "    return r,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193df8f4",
   "metadata": {},
   "source": [
    "## RNN Implementation <a name=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b12ac236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelRNN(epochs: int,  X_train, Y_train , X_test, Y_test,lr,units,batch , verbose, callback,plot_summary = True):\n",
    "\n",
    "    i = Input(shape=(T, input_D))\n",
    "    x = SimpleRNN(units)(i)\n",
    "    x = Dense(output_D)(x)\n",
    "    model = Model(i, x)\n",
    "    model.compile(\n",
    "      loss='mse',\n",
    "      optimizer=Adam(learning_rate=lr),)\n",
    "    \n",
    "    if plot_summary == True:\n",
    "        print(model.summary())\n",
    "    \n",
    "    if callback==True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "        r = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                      validation_data=(X_test, Y_test),\n",
    "                      callbacks=[callback], verbose=verbose,batch_size=batch)\n",
    "    else:\n",
    "        r = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                      validation_data=(X_test, Y_test),verbose=verbose,batch_size=batch)      \n",
    "    return r,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde2b75",
   "metadata": {},
   "source": [
    "## GRU Implementation  <a name=\"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9ae58513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelGRU(epochs: int,  X_train, Y_train , X_test, Y_test,lr,units,batch , verbose, callback,plot_summary = True):\n",
    "\n",
    "    i = Input(shape=(T, input_D))\n",
    "    x = GRU(units)(i)\n",
    "    x = Dense(output_D)(x)\n",
    "    model = Model(i, x)\n",
    "    model.compile(\n",
    "      loss='mse',\n",
    "      optimizer=Adam(learning_rate=lr),)\n",
    "    \n",
    "    if plot_summary == True:\n",
    "        print(model.summary())\n",
    "    \n",
    "    if callback==True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "        r = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                      validation_data=(X_test, Y_test),\n",
    "                      callbacks=[callback], verbose=verbose,batch_size=batch)\n",
    "    else:\n",
    "        r = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                      validation_data=(X_test, Y_test),verbose=verbose,batch_size=batch)  \n",
    "    \n",
    "    return r,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101bc79",
   "metadata": {},
   "source": [
    "## CKCNN Implementation  <a name=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a7488c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "class CKCNN_backbone(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        num_blocks: int,\n",
    "        kernelnet_hidden_channels: int,\n",
    "        kernelnet_activation_function: str,\n",
    "        kernelnet_norm_type: str,\n",
    "        dim_linear: int,\n",
    "        bias: bool,\n",
    "        omega_0: bool,\n",
    "        dropout: float,\n",
    "        weight_dropout: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Add num_blocks CKBlocks to a sequential called self.backbone\n",
    "        blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            block_in_channels = in_channels if i == 0 else hidden_channels\n",
    "            blocks.append(\n",
    "                ckconv.nn.CKBlock(\n",
    "                    block_in_channels,\n",
    "                    hidden_channels,\n",
    "                    kernelnet_hidden_channels,\n",
    "                    kernelnet_activation_function,\n",
    "                    kernelnet_norm_type,\n",
    "                    dim_linear,\n",
    "                    bias,\n",
    "                    omega_0,\n",
    "                    dropout,\n",
    "                    weight_dropout,\n",
    "                )\n",
    "            )\n",
    "        self.backbone = torch.nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5e12b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKCNN(CKCNN_backbone):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        hidden_channels: int,\n",
    "        num_blocks: int,\n",
    "        kernelnet_hidden_channels: int,\n",
    "        kernelnet_activation_function: str,\n",
    "        kernelnet_norm_type: str,\n",
    "        dim_linear: int,\n",
    "        bias: bool,\n",
    "        omega_0: bool,\n",
    "        dropout: float,\n",
    "        weight_dropout: float,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            in_channels,\n",
    "            hidden_channels,\n",
    "            num_blocks,\n",
    "            kernelnet_hidden_channels,\n",
    "            kernelnet_activation_function,\n",
    "            kernelnet_norm_type,\n",
    "            dim_linear,\n",
    "            bias,\n",
    "            omega_0,\n",
    "            dropout,\n",
    "            weight_dropout,\n",
    "        )\n",
    "\n",
    "        self.finallyr = torch.nn.Linear(\n",
    "            in_features=hidden_channels, out_features=out_channels\n",
    "        )\n",
    "        # Initialize finallyr\n",
    "        self.finallyr.weight.data.normal_(\n",
    "            mean=0.0,\n",
    "            std=0.01,\n",
    "        )\n",
    "        self.finallyr.bias.data.fill_(value=0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = self.finallyr(out[:, :, -1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "15575e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the test loss per epoch for train and validation\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "def testLoss(network,n_test,batch_size,X1_test,Y1_test ):\n",
    "    criterion = nn.MSELoss().to(device)    \n",
    "    running_test_loss=0.0\n",
    "    epoch_test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in np.arange(0,n_test,batch_size):\n",
    "\n",
    "            test_inputs = X1_test[i:i+batch_size].cuda()\n",
    "            test_true_val = Y1_test[i:i+batch_size].cuda()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            test_outputs = network(test_inputs).to(device)\n",
    "            test_loss = criterion(test_outputs.to(device), test_true_val.to(device))\n",
    "\n",
    "            running_test_loss += test_loss.item()            \n",
    "            if batch_size != len(test_inputs):\n",
    "                epoch_test_loss += running_test_loss* len(test_inputs)\n",
    "            else:                \n",
    "                epoch_test_loss += running_test_loss* batch_size\n",
    "            running_test_loss = 0.0\n",
    "    \n",
    "    return epoch_test_loss/n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b516101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelCkcnn(X1_train,Y1_train,X1_test,Y1_test,lr,units,hidden_units,batch,epochs = None, callback = False):\n",
    "    print(units)\n",
    "    print(hidden_units)\n",
    "    print(epochs)\n",
    "    # Construct network:\n",
    "    in_channels = 5\n",
    "    out_channels = 1\n",
    "    hidden_channels = units\n",
    "    num_blocks = 2\n",
    "    kernelnet_hidden_channels = hidden_units\n",
    "    kernelnet_activation_function = 'Sine'\n",
    "    kernelnet_norm_type = ''\n",
    "    dim_linear = 1\n",
    "    bias = True\n",
    "    omega_0 = 30.5\n",
    "    dropout = 0\n",
    "    weight_dropout = 0.0\n",
    "\n",
    "    network = CKCNN(in_channels,\n",
    "                    out_channels,\n",
    "                    hidden_channels,\n",
    "                    num_blocks,\n",
    "                    kernelnet_hidden_channels,\n",
    "                    kernelnet_activation_function,\n",
    "                    kernelnet_norm_type,\n",
    "                    dim_linear,\n",
    "                    bias,\n",
    "                    omega_0,\n",
    "                    dropout,\n",
    "                    weight_dropout,\n",
    "                   )\n",
    "    network.to(device)\n",
    "    \n",
    "    \n",
    "    loss = []\n",
    "    loss_change =[]\n",
    "    total_loss = []\n",
    "    total_val_loss = []\n",
    "    patience = 5\n",
    "    patience_change = patience\n",
    "    batch_size = batch\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    #optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    if epochs == None:\n",
    "        epochs =250\n",
    "    n_train = len(X1_train)\n",
    "    n_test = len(X1_test)\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        count = 0\n",
    "        \n",
    "        for i in np.arange(0,n_train,batch_size):\n",
    "            inputs = X1_train[i:i+batch_size].cuda()\n",
    "            true_val = Y1_train[i:i+batch_size].cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = network(inputs).to(device)\n",
    "            loss = criterion(outputs.cuda(), true_val.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if batch_size != len(inputs):\n",
    "                epoch_loss += running_loss * len(inputs)\n",
    "            else:\n",
    "                epoch_loss += running_loss * batch_size\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "        train_loss =   epoch_loss/n_train \n",
    "        total_loss.append(train_loss)\n",
    "        outputs = network(X1_test[:].cuda())\n",
    "        test_loss = testLoss(network,n_test,batch_size,X1_test,Y1_test )\n",
    "        total_val_loss.append(test_loss)\n",
    "\n",
    "        if callback == True:\n",
    "            loss_change.append(abs(train_loss - test_loss))\n",
    "            if len(loss_change)>patience:\n",
    "                if np.mean(loss_change[-patience:])> prev_mean:\n",
    "                    patience_change -= 1\n",
    "                    if patience_change==0:\n",
    "                        break\n",
    "                else:\n",
    "                    patience_change = patience\n",
    "            prev_mean = np.mean(loss_change[-patience:])\n",
    "        print(\"Epoch %d/%d: loss - %f, val loss - %f\" % (epoch+1, epochs, train_loss, test_loss) )\n",
    "    r = [total_loss,total_val_loss]\n",
    "\n",
    "    return r,network\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b8ba0",
   "metadata": {},
   "source": [
    "## Results and Prediction Generators <a name=\"7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "977587af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates the results for the tesorflow models, includes the following steps:\n",
    "# 1) preprecessing\n",
    "# 2) train/test splitting\n",
    "# 3) model training\n",
    "# 4) model validation \n",
    "# returns the test/train mse and the predictions\n",
    "def resultsGenerator(input_data, offset_list, m,lr,units,batch,epochs,callback):\n",
    "    \n",
    "    if callback == True:\n",
    "        epochs=250\n",
    "    extended_model_info  = pd.DataFrame()\n",
    "    \n",
    "    for target_offset in offset_list:        \n",
    "        model_dict = {}\n",
    "        model_dict[\"Target Step Offset\"] = target_offset\n",
    "        X, Y , X_unscaled, Y_unscaled, scaler_list = preprocessor(input_data,target_offset)\n",
    "        X_train,Y_train, X_test, Y_test, X_train_unscaled, Y_train_unscaled, X_test_unscaled, Y_test_unscaled = trainTestSplit(\n",
    "                                                                                        ratio ,X, Y , X_unscaled, Y_unscaled)                \n",
    "        if m == \"Attention\":\n",
    "            r,model = attentionGRU(epochs,X_train, Y_train , X_test, Y_test,lr=lr,units=units,\n",
    "                                   batch=batch,callback = callback,verbose = 1, plot_summary = False)        \n",
    "        elif m ==\"GRU\":\n",
    "            r,model = modelGRU(epochs,X_train, Y_train , X_test, Y_test,lr=lr,units=units,\n",
    "                                   batch=batch,callback = callback,verbose = 1, plot_summary = False)            \n",
    "        elif m ==\"LSTM\":\n",
    "            r,model = modelLSTM(epochs,X_train, Y_train , X_test, Y_test,lr=lr,units=units,\n",
    "                                   batch=batch,callback = callback,verbose = 1, plot_summary = False)            \n",
    "        else:\n",
    "            r,model = modelRNN(epochs,X_train, Y_train , X_test, Y_test,lr=lr,units=units,\n",
    "                                   batch=batch,callback = callback,verbose = 1, plot_summary = False)\n",
    "\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        outputs_test = model.predict(X_test)\n",
    "        outputs_train = model.predict(X_train)\n",
    "\n",
    "        model_dict[\"Train MSE\"] = float(mse(Y_train, outputs_train )  ) \n",
    "        model_dict[\"Test MSE\"] = float(mse(Y_test, outputs_test )  ) \n",
    "\n",
    "        model_dict[\"Learning Train MSE\"] = r.history['loss']\n",
    "        model_dict[\"Learning Test MSE\"] = r.history['val_loss']\n",
    "\n",
    "        train_length = len(X_train) \n",
    "        close_predictions = getPrediction(model, X_test, Y_test, Y_test_unscaled, scaler_list[train_length:])\n",
    "        model_dict[\"Test Predictions\"] = close_predictions        \n",
    "        model_dict[\"Test True Value\"] = Y_test_unscaled       \n",
    "        model_dict[\"Test Previous Day\"] = X_test_unscaled[:,-1,3]\n",
    "        close_predictions = getPrediction(model ,X_train, Y_train, Y_train_unscaled, scaler_list[:train_length])\n",
    "\n",
    "        model_dict[\"Train Predictions\"] = close_predictions\n",
    "        model_dict[\"Train True Value\"] = Y_train_unscaled\n",
    "        model_dict[\"Train Previous Day\"] = X_train_unscaled[:,-1,3]\n",
    "        model_dict[\"Train Length = \"] = train_length\n",
    "\n",
    "        extended_model_info = extended_model_info.append(model_dict, ignore_index=True)\n",
    "    return extended_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "65945612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate results for the ckcnn (pytorch)\n",
    "# 1) preprecessing\n",
    "# 2) train/test splitting\n",
    "# 3) model training\n",
    "# 4) model validation \n",
    "# returns the test/train mse and the predictions\n",
    "def resultsGenerator2 (input_data, offset_list,units,lr,hidden_units,batch,callback,epochs):\n",
    "\n",
    "    extended_model_info  = pd.DataFrame()\n",
    "    criterion = nn.MSELoss().to(device) \n",
    "    for target_offset in offset_list:\n",
    "        model_dict = {}\n",
    "        print(\"$$$$$$$$  pytorch $$$$$$$$$\")\n",
    "\n",
    "        model_dict[\"Target Step Offset\"] = target_offset\n",
    "\n",
    "\n",
    "        X, Y , X_unscaled, Y_unscaled, scaler_list = preprocessor(input_data,target_offset)\n",
    "        X_train,Y_train, X_test, Y_test, X_train_unscaled, Y_train_unscaled, X_test_unscaled, Y_test_unscaled = trainTestSplit(\n",
    "                                                                                        ratio ,X, Y , X_unscaled, Y_unscaled)\n",
    "        n_train = len(X_train)\n",
    "        X1_train = np.zeros((n_train,input_D, T))\n",
    "        Y1_train = np.zeros((n_train,output_D))\n",
    "        X1_train_unscaled = np.zeros((n_train,input_D, T))\n",
    "        Y1_train_unscaled  = np.zeros((n_train,output_D))\n",
    "\n",
    "\n",
    "        n_test = len(X_test)\n",
    "        X1_test = np.zeros((n_test,input_D, T))\n",
    "        Y1_test = np.zeros((n_test,output_D))\n",
    "        X1_test_unscaled = np.zeros((n_test,input_D, T))\n",
    "        Y1_test_unscaled  = np.zeros((n_test,output_D))\n",
    "\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            if i <n_train:\n",
    "                X1_train[i]= X_train[i].T\n",
    "                Y1_train[i]= Y_train[i]\n",
    "                X1_train_unscaled[i] = X_train_unscaled[i].T\n",
    "                Y1_train_unscaled[i] = Y_train_unscaled[i]\n",
    "                \n",
    "                \n",
    "            if i < n_test:\n",
    "                X1_test[i]= X_test[i].T\n",
    "                Y1_test[i]= Y_test[i]\n",
    "                X1_test_unscaled[i] = X_test_unscaled[i].T\n",
    "                Y1_test_unscaled[i] = Y_test_unscaled[i]\n",
    "                \n",
    "\n",
    "\n",
    "        X1_train =torch.tensor( X1_train).float()\n",
    "        Y1_train = torch.tensor(Y1_train).float()\n",
    "\n",
    "        X1_test = torch.tensor(X1_test).float()\n",
    "        Y1_test = torch.tensor(Y1_test).float()\n",
    "       \n",
    "        r,model = modelCkcnn(X1_train,Y1_train,X1_test,Y1_test,lr,units,\n",
    "                             hidden_units,batch,epochs, callback )\n",
    "        X1_train = X1_train.to(device)\n",
    "        Y1_train = Y1_train.to(device)\n",
    "        X1_test = X1_test.to(device)\n",
    "        Y1_test = Y1_test.to(device)\n",
    "        \n",
    "        outputs_test = model(X1_test)\n",
    "        outputs_train = model(X1_train)\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        model_dict[\"Train MSE\"] =  criterion(outputs_train.to(device), Y1_train).item()\n",
    "        model_dict[\"Test MSE\"] =  criterion(outputs_test.to(device),  Y1_test).item()\n",
    "\n",
    "\n",
    "        model_dict[\"Learning Train MSE\"] = r[0]\n",
    "        model_dict[\"Learning Test MSE\"] = r[1]\n",
    "        \n",
    "        close_predictions = getPrediction2(model, X1_test, Y1_test, Y1_test_unscaled, scaler_list[n_train:])\n",
    "\n",
    "\n",
    "\n",
    "        model_dict[\"Test Predictions\"] = close_predictions\n",
    "        print(\"Test Predictions\")\n",
    "        print(close_predictions.shape)\n",
    "        model_dict[\"Test True Value\"] = Y1_test_unscaled\n",
    "        print(\"Test True Value\")\n",
    "        print(Y_test_unscaled.shape)\n",
    "        model_dict[\"Test Previous Day\"] = X1_test_unscaled[:,3,-1]\n",
    "        print(\"Test Previous Day\")\n",
    "        print(X_test_unscaled.shape)\n",
    "\n",
    "\n",
    "\n",
    "        close_predictions = getPrediction2(model ,X1_train, Y1_train, Y1_train_unscaled, scaler_list[:n_train])\n",
    "\n",
    "        model_dict[\"Train Predictions\"] = close_predictions\n",
    "        model_dict[\"Train True Value\"] = Y1_train_unscaled\n",
    "        model_dict[\"Train Previous Day\"] = X1_train_unscaled[:,-3,-1]\n",
    "        model_dict[\"Train Length = \"] = n_train\n",
    "\n",
    "\n",
    "        extended_model_info = extended_model_info.append(model_dict, ignore_index=True)\n",
    "\n",
    "    return extended_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4a7b76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the prediction for the tensorflow models\n",
    "def getPrediction(model , X,Y, Y_unscaled, scaler_list):\n",
    "    predictions = model.predict(X)\n",
    "    unscaled_predictions = np.zeros(len(predictions))\n",
    "    temp =  np.zeros((T,input_D))\n",
    "\n",
    "    for k in range(len(predictions)):\n",
    "        temp[-1,3:4] = predictions[k]\n",
    "        unscaled_temp=scaler_list[k].inverse_transform(temp)\n",
    "        unscaled_prediction = unscaled_temp[-1,3:4]\n",
    "        unscaled_predictions[k]=unscaled_prediction    \n",
    "        \n",
    "    return unscaled_predictions\n",
    "\n",
    "\n",
    "\n",
    "# gets the predictions for the ckcnn model (pytorch)\n",
    "def getPrediction2(model , X,Y, Y_unscaled, scaler_list):\n",
    "    predictions = model(X.to(device))\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    unscaled_predictions = np.zeros(len(predictions))\n",
    "    temp =  np.zeros((T,input_D))\n",
    "\n",
    "    for k in range(len(predictions)):\n",
    "        temp[-1,3:4] = predictions[k]        \n",
    "        unscaled_temp=scaler_list[k].inverse_transform(temp)\n",
    "        unscaled_prediction = unscaled_temp[-1,3:4]        \n",
    "        unscaled_predictions[k]=unscaled_prediction\n",
    "        \n",
    "    return unscaled_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "516ae3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the the percent profit of a single prediction for long trades\n",
    "def tradeLong(prediction, true_val, prev_close  ):\n",
    "    profit = 0\n",
    "    if prediction>prev_close:\n",
    "        if prediction<true_val:\n",
    "            profit = prediction - prev_close \n",
    "        else: \n",
    "            profit = true_val - prev_close\n",
    "    return round(profit/prev_close,4)\n",
    "\n",
    "# gets the the percent profit of a single prediction for short trades        \n",
    "def tradeShort(prediction, true_val, prev_close  ):\n",
    "    profit = 0\n",
    "    if prediction<prev_close:\n",
    "        if prediction>true_val:\n",
    "            profit = prediction-prev_close\n",
    "        else: \n",
    "            profit = prev_close - true_val\n",
    "    return round(profit/prev_close,4)\n",
    "\n",
    "# generates the performance of the predictions as well as the buy and hold benchmark\n",
    "def performanceGenerator(extended_model_info,offset_list):\n",
    "    for t in [\"Train \",\"Test \"]:\n",
    "        long_performance = []\n",
    "        short_performance = []\n",
    "        Total_performance = []\n",
    "\n",
    "        for target_offset in offset_list:\n",
    "            eval_df = pd.DataFrame()\n",
    "            eval_df[\"Prediction\"] = extended_model_info[extended_model_info[\"Target Step Offset\"]==target_offset][t+\"Predictions\"].values[0]\n",
    "            eval_df[\"True Value\"] =extended_model_info[extended_model_info[\"Target Step Offset\"]==target_offset][t+\"True Value\"].values[0]\n",
    "            eval_df[\"Previous Close\"] = extended_model_info[extended_model_info[\"Target Step Offset\"]==target_offset][t+\"Previous Day\"].values[0]\n",
    "            eval_df[\"Long Performance\"] = eval_df.apply(lambda x: tradeLong(x[\"Prediction\"],x[\"True Value\"]\n",
    "                                                                            , x[\"Previous Close\"]) ,axis = 1)\n",
    "            eval_df[\"Short Performance\"] = eval_df.apply(lambda x: tradeShort(x[\"Prediction\"],x[\"True Value\"]\n",
    "                                                                             , x[\"Previous Close\"]) ,axis = 1 )\n",
    "            long_performance.append(eval_df[\"Long Performance\"].mean()/target_offset)\n",
    "            short_performance.append(eval_df[\"Short Performance\"].mean()/target_offset)\n",
    "            Total_performance.append((eval_df[\"Short Performance\"]+eval_df[\"Long Performance\"]).mean()/target_offset)\n",
    "\n",
    "\n",
    "        extended_model_info[t+\"Average Long Performance\"] = np.array(long_performance)*100\n",
    "        extended_model_info[t+\"Average Short Performance\"] = np.array(short_performance)*100\n",
    "        extended_model_info[t+\"Average Performance\"] = np.array(Total_performance)*100\n",
    "\n",
    "        first_close_price = extended_model_info[extended_model_info[\"Target Step Offset\"]==offset_list[0]][t+\"True Value\"].values[0][0]\n",
    "        last_close_price = extended_model_info[extended_model_info[\"Target Step Offset\"]==offset_list[0]][t+\"True Value\"].values[0][-1]\n",
    "        \n",
    "        \n",
    "        extended_model_info[t+\"Buy and Hold\"] = 100*((last_close_price[0] - first_close_price[0])/first_close_price[0])/(len(eval_df[\"Prediction\"])-1)\n",
    "\n",
    "    return extended_model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03afb74d",
   "metadata": {},
   "source": [
    "## Data Learner <a name=\"8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "43bac388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learns the data on a given list of symbols\n",
    "# params: \n",
    "# symbols - a alist of stocks\n",
    "# model_parameters - a dataframe returns from the optimizer, includes the lr,batch,epochs, \n",
    "# callbacl -  true for stopping the learning with accordance to the test mse, false for no intervention\n",
    "def learner(symbols,model_parameters,callback):    \n",
    "    temp_m = np.array(model_parameters.index.get_level_values('Model'))\n",
    "    models = np.sort(np.unique(temp_m)).tolist()\n",
    "        \n",
    "    temp_o = np.array(model_parameters.index.get_level_values('Offset'),dtype = np.int32)\n",
    "    offset_list = np.sort(np.unique(temp_o)).tolist()\n",
    "    \n",
    "    reports = [\"Target Step Offset\",\"Train MSE\",\"Test MSE\",\"Train Average Performance\",\"Test Average Performance\",\n",
    "                    \"Train Average Long Performance\",\"Train Average Short Performance\",\n",
    "                    \"Test Average Long Performance\",\"Test Average Short Performance\",\n",
    "                                      \"Train Buy and Hold\",\"Test Buy and Hold\"]\n",
    "\n",
    "    extended_report = [\"Learning Train MSE\",\"Learning Test MSE\",\"Test Predictions\",\"Test True Value\",\n",
    "                       \"Test Previous Day\",\"Train Predictions\",\"Train True Value\",\"Train Previous Day\"]\n",
    "    reports_matrix = np.zeros((len(symbols),len(models),len(offset_list),len(reports)))\n",
    "\n",
    "    extended_reports_matrix =[]\n",
    "    symbol_models = dict.fromkeys(symbols)\n",
    "    extended_reports_symbol =[]\n",
    "    for symbol in symbols:\n",
    "        stock = df[df['symbol']==symbol]\n",
    "        stock = stock.sort_values(by = \"date\")\n",
    "        input_data = stock[['open', 'high', 'low', 'close', 'volume']].values\n",
    "        n = len(input_data)\n",
    "        extended_reports_model =[]\n",
    "        for model in models:\n",
    "            extended_reports_offset=[]\n",
    "            for offset in offset_list:\n",
    "                \n",
    "                # Parameters\n",
    "                lr = model_parameters.loc[model,offset][\"lr\"]\n",
    "                units = int(model_parameters.loc[model,offset][\"units\"])\n",
    "                batch = int(model_parameters.loc[model,offset][\"batch\"])\n",
    "                epochs = int(model_parameters.loc[model,offset][\"epochs\"])\n",
    "\n",
    "                if model!=\"CKCNN\":  \n",
    "                    model_info = resultsGenerator(input_data, [offset],m = model,callback = callback,\n",
    "                                                    units=units,lr=lr,batch= batch,epochs= epochs)\n",
    "                else:\n",
    "                    hidden_units =int( model_parameters.loc[model,offset][\"hidden units\"])\n",
    "                    model_info = resultsGenerator2(input_data, [offset],units=units,callback = callback,hidden_units=hidden_units,lr=lr,batch= batch,epochs= epochs)\n",
    "                    \n",
    "\n",
    "                extended_model_info = performanceGenerator(model_info,[offset])\n",
    "\n",
    "                critical_reports = extended_model_info[reports].to_numpy()\n",
    "                extended_critical_reports = extended_model_info[extended_report].to_numpy()\n",
    "\n",
    "                reports_matrix[symbols.index(symbol),\n",
    "                              models.index(model),\n",
    "                              offset_list.index(offset)]=critical_reports\n",
    "\n",
    "                extended_reports_offset.append(extended_critical_reports)\n",
    "            extended_reports_model.append(extended_reports_offset)\n",
    "        extended_reports_matrix.append(extended_reports_model)\n",
    "        \n",
    "    return [np.array(reports_matrix),np.array(extended_reports_matrix)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96e44b7",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b3982579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the hyper parameters: lr, units, and batch\n",
    "def optimizer(offset_list,models= [\"LSTM\",\"GRU\",\"RNN\",\"Attention\",\"CKCNN\"]):\n",
    "    \n",
    "    symbols =  [\"INTC\",\"MSFT\",\"DAL\",\"MMM\",\"JNJ\",\"PFE\",\"AIG\",\"JPM\",\"XOM\"] \n",
    "    \n",
    "    reports = [\"Target Step Offset\",\"Train MSE\",\"Test MSE\",\"Train Average Performance\",\"Test Average Performance\",\n",
    "                \"Train Average Long Performance\",\"Train Average Short Performance\",\n",
    "                \"Test Average Long Performance\",\"Test Average Short Performance\",\n",
    "                                  \"Train Buy and Hold\",\"Test Buy and Hold\"]\n",
    "\n",
    "    extended_report = [\"Learning Train MSE\",\"Learning Test MSE\",\"Test Predictions\",\"Test True Value\",\n",
    "                   \"Test Previous Day\",\"Train Predictions\",\"Train True Value\",\"Train Previous Day\"]\n",
    "    \n",
    "    \n",
    "    hyper_param =  pd.DataFrame()\n",
    "    units_list=[7,10,15,20,30]\n",
    "    lr_list = [0.1,0.05,0.01,0.005,0.001]\n",
    "    batch_list = [32]\n",
    "    \n",
    "    for offset in offset_list:\n",
    "        for units in units_list:\n",
    "            for lr in lr_list:\n",
    "                for batch in batch_list:\n",
    "                    for model in models:\n",
    "                        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "                        print([offset,units,lr,batch,model])\n",
    "                        model_p = pd.DataFrame()\n",
    "                        model_p = model_p.append({\"Model\":model,\"Offset\":offset,\"units\":units,\"hidden units\":units,\"lr\":lr\n",
    "                                        ,\"batch\":batch,\"epochs\":250},ignore_index=True)\n",
    "                        model_p = model_p.set_index(['Model','Offset'])\n",
    "                        output = learner(symbols,model_p,callback = True)\n",
    "                        reports_matrix = output[0]\n",
    "                        extended_reports_matrix = output[1]\n",
    "                    \n",
    "                        epochs = 0\n",
    "\n",
    "                        for i in range(len(symbols)):\n",
    "                            epochs+=len(extended_reports_matrix[:,0,0,0,extended_report.index(\"Learning Train MSE\")][0])  \n",
    "                        test_mse = np.mean(reports_matrix[:,0,0,reports.index(\"Test MSE\")])\n",
    "                        epochs = epochs/len(symbols)\n",
    "                        hyper_param = hyper_param.append({\"Model\":model,\"Offset\":offset,\"units\":units\n",
    "                                        ,\"hidden units\":units,\"lr\":lr,\"batch\":batch,\"epochs\":epochs\n",
    "                                        ,\"Test MSE\":test_mse},ignore_index=True)  \n",
    "                        \n",
    "    hyper_param.to_csv(\"all_parameters.csv\")  \n",
    "    return hyper_param\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ba4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "parameter_tables = optimizer( [1,2,3,4,5])\n",
    "\n",
    "all_params = pd.read_csv('all_parameters.csv')  \n",
    "best_params= all_params[['Model', 'Offset','Test MSE']].groupby(['Model', 'Offset']).min()\n",
    "best_params = best_params.merge(all_params,on = ['Test MSE'])\n",
    "best_params =best_params.set_index(['Model','Offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e9ed43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the hyper parameters\n",
    "all_params = pd.read_csv('all_parameters.csv')  \n",
    "best_params=all_params[['Model', 'Offset','Test MSE']].groupby(['Model', 'Offset']).min()\n",
    "best_params = best_params.merge(all_params,on = ['Test MSE'])\n",
    "best_params =best_params.set_index(['Model','Offset'])\n",
    "best_params.to_csv(\"best_params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "10af0a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1290 - val_loss: 0.1058\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1133 - val_loss: 0.0839\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0952 - val_loss: 0.0817\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0913 - val_loss: 0.0746\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0851 - val_loss: 0.0750\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0841 - val_loss: 0.0714\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0851 - val_loss: 0.0709\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0766 - val_loss: 0.0695\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0783 - val_loss: 0.0764\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0797 - val_loss: 0.0668\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0749 - val_loss: 0.0692\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0703 - val_loss: 0.0679\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0727 - val_loss: 0.0651\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0683 - val_loss: 0.0651\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0679 - val_loss: 0.0656\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0682 - val_loss: 0.0656\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0664 - val_loss: 0.0639\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0659 - val_loss: 0.0647\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0649 - val_loss: 0.0636\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0655 - val_loss: 0.0643\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0673 - val_loss: 0.0636\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.0651\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0634 - val_loss: 0.0647\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0629 - val_loss: 0.0637\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0627 - val_loss: 0.0632\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0630 - val_loss: 0.0631\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0629 - val_loss: 0.0634\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0603 - val_loss: 0.0627\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0624 - val_loss: 0.0631\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0608 - val_loss: 0.0663\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0608 - val_loss: 0.0630\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0608 - val_loss: 0.0637\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0610 - val_loss: 0.0649\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0629 - val_loss: 0.0669\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0603 - val_loss: 0.0627\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0582 - val_loss: 0.0628\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0584 - val_loss: 0.0642\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0591 - val_loss: 0.0653\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0618 - val_loss: 0.0640\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0595 - val_loss: 0.0628\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0577 - val_loss: 0.0631\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0582 - val_loss: 0.0661\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0641 - val_loss: 0.0660\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0606 - val_loss: 0.0634\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0581 - val_loss: 0.0639\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0570 - val_loss: 0.0632\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0572 - val_loss: 0.0638\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.2562 - val_loss: 0.2054\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1635 - val_loss: 0.1540\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1260 - val_loss: 0.1170\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1102 - val_loss: 0.0981\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0999 - val_loss: 0.0895\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0958 - val_loss: 0.0852\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0957 - val_loss: 0.0835\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0897 - val_loss: 0.0814\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0888 - val_loss: 0.0824\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0915 - val_loss: 0.0785\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0909 - val_loss: 0.0826\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0871 - val_loss: 0.0764\n",
      "Epoch 13/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0872 - val_loss: 0.0786\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0850 - val_loss: 0.0748\n",
      "Epoch 15/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0880 - val_loss: 0.0779\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0893 - val_loss: 0.0795\n",
      "Epoch 17/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0837 - val_loss: 0.0742\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0838 - val_loss: 0.0741\n",
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0836 - val_loss: 0.0749\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0854 - val_loss: 0.0743\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0824 - val_loss: 0.0743\n",
      "Epoch 22/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0827 - val_loss: 0.0756\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0863 - val_loss: 0.0748\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0836 - val_loss: 0.0765\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0834 - val_loss: 0.0751\n",
      "Epoch 26/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0846 - val_loss: 0.0750\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0856 - val_loss: 0.0765\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0802 - val_loss: 0.0766\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0825 - val_loss: 0.0754\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0808 - val_loss: 0.0776\n",
      "Epoch 31/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0797 - val_loss: 0.0758\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0800 - val_loss: 0.0765\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0827 - val_loss: 0.0767\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0820 - val_loss: 0.0779\n",
      "Epoch 35/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0799 - val_loss: 0.0766\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0785 - val_loss: 0.0768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0787 - val_loss: 0.0758\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0812 - val_loss: 0.0811\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0823 - val_loss: 0.0763\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0796 - val_loss: 0.0767\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0799 - val_loss: 0.0767\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0819 - val_loss: 0.0775\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0802 - val_loss: 0.0774\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0785 - val_loss: 0.0785\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1652 - val_loss: 0.1255\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1290 - val_loss: 0.1078\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1149 - val_loss: 0.1032\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1014 - val_loss: 0.0900\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0970 - val_loss: 0.0889\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0973 - val_loss: 0.0846\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0954 - val_loss: 0.0885\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0918 - val_loss: 0.0846\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0967 - val_loss: 0.0854\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0949 - val_loss: 0.0830\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0909 - val_loss: 0.0821\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0886 - val_loss: 0.0801\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0898 - val_loss: 0.0801\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0888 - val_loss: 0.0797\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0879 - val_loss: 0.0835\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0916 - val_loss: 0.0840\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0901 - val_loss: 0.0818\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0929 - val_loss: 0.0813\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0871 - val_loss: 0.0804\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0859 - val_loss: 0.0801\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0866 - val_loss: 0.0802\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0848 - val_loss: 0.0810\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0863 - val_loss: 0.0798\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3255 - val_loss: 0.1410\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1327 - val_loss: 0.1275\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1232 - val_loss: 0.1212\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1159 - val_loss: 0.1137\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1110 - val_loss: 0.1074\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1087 - val_loss: 0.1041\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1046 - val_loss: 0.0996\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1014 - val_loss: 0.0969\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0997 - val_loss: 0.0943\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0971 - val_loss: 0.0927\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0953 - val_loss: 0.0913\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0936 - val_loss: 0.0897\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0945 - val_loss: 0.0890\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0939 - val_loss: 0.0881\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0932 - val_loss: 0.0897\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0953 - val_loss: 0.0870\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0915 - val_loss: 0.0866\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0923 - val_loss: 0.0862\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0897 - val_loss: 0.0855\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0889 - val_loss: 0.0851\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0895 - val_loss: 0.0866\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0890 - val_loss: 0.0856\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0901 - val_loss: 0.0844\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2798 - val_loss: 0.2086\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1815 - val_loss: 0.1923\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1538 - val_loss: 0.1553\n",
      "Epoch 4/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1353 - val_loss: 0.1402\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1231 - val_loss: 0.1278\n",
      "Epoch 6/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1128 - val_loss: 0.1162\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1074 - val_loss: 0.1158\n",
      "Epoch 8/31\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1040 - val_loss: 0.1065\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0984 - val_loss: 0.1038\n",
      "Epoch 10/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0981 - val_loss: 0.1058\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0958 - val_loss: 0.1000\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0950 - val_loss: 0.0993\n",
      "Epoch 13/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0934 - val_loss: 0.0996\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0942 - val_loss: 0.1025\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0916 - val_loss: 0.1009\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0899 - val_loss: 0.0991\n",
      "Epoch 17/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0909 - val_loss: 0.0992\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0894 - val_loss: 0.1008\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0905 - val_loss: 0.0987\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0898 - val_loss: 0.0988\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0878 - val_loss: 0.1010\n",
      "Epoch 22/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0879 - val_loss: 0.0994\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0885 - val_loss: 0.0982\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0864 - val_loss: 0.0980\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0892 - val_loss: 0.0978\n",
      "Epoch 26/31\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0916 - val_loss: 0.0992\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0903 - val_loss: 0.1046\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0863 - val_loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0876 - val_loss: 0.0983\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0870 - val_loss: 0.0982\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0880 - val_loss: 0.0978\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 0.842594, val loss - 0.136894\n",
      "Epoch 2/15: loss - 0.194887, val loss - 0.099302\n",
      "Epoch 3/15: loss - 0.150352, val loss - 0.073706\n",
      "Epoch 4/15: loss - 0.086379, val loss - 0.087800\n",
      "Epoch 5/15: loss - 0.083232, val loss - 0.081822\n",
      "Epoch 6/15: loss - 0.080340, val loss - 0.069874\n",
      "Epoch 7/15: loss - 0.075947, val loss - 0.068366\n",
      "Epoch 8/15: loss - 0.073807, val loss - 0.065466\n",
      "Epoch 9/15: loss - 0.070452, val loss - 0.064932\n",
      "Epoch 10/15: loss - 0.070734, val loss - 0.063398\n",
      "Epoch 11/15: loss - 0.068852, val loss - 0.063759\n",
      "Epoch 12/15: loss - 0.068492, val loss - 0.063013\n",
      "Epoch 13/15: loss - 0.065993, val loss - 0.063290\n",
      "Epoch 14/15: loss - 0.065019, val loss - 0.064583\n",
      "Epoch 15/15: loss - 0.063694, val loss - 0.064424\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.260298, val loss - 0.292843\n",
      "Epoch 2/176: loss - 0.179270, val loss - 0.134416\n",
      "Epoch 3/176: loss - 0.132727, val loss - 0.117489\n",
      "Epoch 4/176: loss - 0.125571, val loss - 0.121426\n",
      "Epoch 5/176: loss - 0.124493, val loss - 0.112495\n",
      "Epoch 6/176: loss - 0.108517, val loss - 0.094609\n",
      "Epoch 7/176: loss - 0.101452, val loss - 0.093146\n",
      "Epoch 8/176: loss - 0.097688, val loss - 0.080292\n",
      "Epoch 9/176: loss - 0.101664, val loss - 0.104777\n",
      "Epoch 10/176: loss - 0.098907, val loss - 0.091506\n",
      "Epoch 11/176: loss - 0.098000, val loss - 0.087911\n",
      "Epoch 12/176: loss - 0.091187, val loss - 0.083824\n",
      "Epoch 13/176: loss - 0.089480, val loss - 0.079236\n",
      "Epoch 14/176: loss - 0.087857, val loss - 0.082885\n",
      "Epoch 15/176: loss - 0.082174, val loss - 0.082854\n",
      "Epoch 16/176: loss - 0.079848, val loss - 0.084613\n",
      "Epoch 17/176: loss - 0.070118, val loss - 0.082072\n",
      "Epoch 18/176: loss - 0.068287, val loss - 0.084965\n",
      "Epoch 19/176: loss - 0.068453, val loss - 0.087025\n",
      "Epoch 20/176: loss - 0.063664, val loss - 0.075151\n",
      "Epoch 21/176: loss - 0.072460, val loss - 0.082770\n",
      "Epoch 22/176: loss - 0.072050, val loss - 0.104556\n",
      "Epoch 23/176: loss - 0.078198, val loss - 0.075403\n",
      "Epoch 24/176: loss - 0.064263, val loss - 0.087255\n",
      "Epoch 25/176: loss - 0.066197, val loss - 0.087962\n",
      "Epoch 26/176: loss - 0.061778, val loss - 0.083066\n",
      "Epoch 27/176: loss - 0.061619, val loss - 0.073490\n",
      "Epoch 28/176: loss - 0.059890, val loss - 0.127429\n",
      "Epoch 29/176: loss - 0.069534, val loss - 0.118813\n",
      "Epoch 30/176: loss - 0.069609, val loss - 0.081818\n",
      "Epoch 31/176: loss - 0.059030, val loss - 0.089151\n",
      "Epoch 32/176: loss - 0.062640, val loss - 0.091740\n",
      "Epoch 33/176: loss - 0.062200, val loss - 0.101086\n",
      "Epoch 34/176: loss - 0.058977, val loss - 0.109258\n",
      "Epoch 35/176: loss - 0.062785, val loss - 0.085241\n",
      "Epoch 36/176: loss - 0.062274, val loss - 0.095647\n",
      "Epoch 37/176: loss - 0.069040, val loss - 0.102549\n",
      "Epoch 38/176: loss - 0.062296, val loss - 0.090399\n",
      "Epoch 39/176: loss - 0.063345, val loss - 0.084107\n",
      "Epoch 40/176: loss - 0.070128, val loss - 0.112731\n",
      "Epoch 41/176: loss - 0.068622, val loss - 0.085988\n",
      "Epoch 42/176: loss - 0.059137, val loss - 0.100675\n",
      "Epoch 43/176: loss - 0.068495, val loss - 0.110013\n",
      "Epoch 44/176: loss - 0.062803, val loss - 0.098697\n",
      "Epoch 45/176: loss - 0.059891, val loss - 0.104349\n",
      "Epoch 46/176: loss - 0.059446, val loss - 0.091741\n",
      "Epoch 47/176: loss - 0.061347, val loss - 0.114767\n",
      "Epoch 48/176: loss - 0.063206, val loss - 0.098974\n",
      "Epoch 49/176: loss - 0.057906, val loss - 0.096511\n",
      "Epoch 50/176: loss - 0.061582, val loss - 0.090638\n",
      "Epoch 51/176: loss - 0.057315, val loss - 0.133539\n",
      "Epoch 52/176: loss - 0.062282, val loss - 0.083005\n",
      "Epoch 53/176: loss - 0.057846, val loss - 0.100049\n",
      "Epoch 54/176: loss - 0.058623, val loss - 0.103548\n",
      "Epoch 55/176: loss - 0.056170, val loss - 0.091537\n",
      "Epoch 56/176: loss - 0.058180, val loss - 0.098159\n",
      "Epoch 57/176: loss - 0.056775, val loss - 0.107036\n",
      "Epoch 58/176: loss - 0.057209, val loss - 0.104491\n",
      "Epoch 59/176: loss - 0.057291, val loss - 0.112401\n",
      "Epoch 60/176: loss - 0.055366, val loss - 0.111681\n",
      "Epoch 61/176: loss - 0.059892, val loss - 0.097477\n",
      "Epoch 62/176: loss - 0.058793, val loss - 0.142111\n",
      "Epoch 63/176: loss - 0.068798, val loss - 0.085262\n",
      "Epoch 64/176: loss - 0.060072, val loss - 0.104753\n",
      "Epoch 65/176: loss - 0.061284, val loss - 0.098948\n",
      "Epoch 66/176: loss - 0.057069, val loss - 0.102204\n",
      "Epoch 67/176: loss - 0.053216, val loss - 0.105690\n",
      "Epoch 68/176: loss - 0.056314, val loss - 0.101950\n",
      "Epoch 69/176: loss - 0.056214, val loss - 0.112433\n",
      "Epoch 70/176: loss - 0.059950, val loss - 0.113313\n",
      "Epoch 71/176: loss - 0.061273, val loss - 0.108496\n",
      "Epoch 72/176: loss - 0.058167, val loss - 0.120326\n",
      "Epoch 73/176: loss - 0.058298, val loss - 0.104549\n",
      "Epoch 74/176: loss - 0.056945, val loss - 0.108393\n",
      "Epoch 75/176: loss - 0.063365, val loss - 0.103999\n",
      "Epoch 76/176: loss - 0.061045, val loss - 0.110453\n",
      "Epoch 77/176: loss - 0.058933, val loss - 0.119012\n",
      "Epoch 78/176: loss - 0.060822, val loss - 0.104307\n",
      "Epoch 79/176: loss - 0.063158, val loss - 0.124423\n",
      "Epoch 80/176: loss - 0.079048, val loss - 0.087420\n",
      "Epoch 81/176: loss - 0.058001, val loss - 0.109776\n",
      "Epoch 82/176: loss - 0.062014, val loss - 0.100188\n",
      "Epoch 83/176: loss - 0.058221, val loss - 0.116679\n",
      "Epoch 84/176: loss - 0.062284, val loss - 0.117527\n",
      "Epoch 85/176: loss - 0.062146, val loss - 0.130402\n",
      "Epoch 86/176: loss - 0.067754, val loss - 0.112449\n",
      "Epoch 87/176: loss - 0.062422, val loss - 0.119566\n",
      "Epoch 88/176: loss - 0.068391, val loss - 0.110249\n",
      "Epoch 89/176: loss - 0.064907, val loss - 0.131561\n",
      "Epoch 90/176: loss - 0.058870, val loss - 0.125099\n",
      "Epoch 91/176: loss - 0.068899, val loss - 0.151957\n",
      "Epoch 92/176: loss - 0.071912, val loss - 0.134197\n",
      "Epoch 93/176: loss - 0.069153, val loss - 0.135440\n",
      "Epoch 94/176: loss - 0.068541, val loss - 0.143519\n",
      "Epoch 95/176: loss - 0.076810, val loss - 0.152454\n",
      "Epoch 96/176: loss - 0.077127, val loss - 0.133342\n",
      "Epoch 97/176: loss - 0.069865, val loss - 0.138274\n",
      "Epoch 98/176: loss - 0.073477, val loss - 0.141829\n",
      "Epoch 99/176: loss - 0.076256, val loss - 0.145902\n",
      "Epoch 100/176: loss - 0.080380, val loss - 0.123048\n",
      "Epoch 101/176: loss - 0.073553, val loss - 0.101909\n",
      "Epoch 102/176: loss - 0.069057, val loss - 0.115018\n",
      "Epoch 103/176: loss - 0.068011, val loss - 0.125472\n",
      "Epoch 104/176: loss - 0.066321, val loss - 0.161728\n",
      "Epoch 105/176: loss - 0.071406, val loss - 0.124349\n",
      "Epoch 106/176: loss - 0.077601, val loss - 0.117733\n",
      "Epoch 107/176: loss - 0.070994, val loss - 0.090686\n",
      "Epoch 108/176: loss - 0.064928, val loss - 0.117862\n",
      "Epoch 109/176: loss - 0.067895, val loss - 0.140602\n",
      "Epoch 110/176: loss - 0.071485, val loss - 0.130605\n",
      "Epoch 111/176: loss - 0.067931, val loss - 0.133257\n",
      "Epoch 112/176: loss - 0.071471, val loss - 0.119491\n",
      "Epoch 113/176: loss - 0.072295, val loss - 0.121655\n",
      "Epoch 114/176: loss - 0.067716, val loss - 0.128065\n",
      "Epoch 115/176: loss - 0.069298, val loss - 0.132071\n",
      "Epoch 116/176: loss - 0.071365, val loss - 0.124822\n",
      "Epoch 117/176: loss - 0.073514, val loss - 0.138728\n",
      "Epoch 118/176: loss - 0.074421, val loss - 0.125291\n",
      "Epoch 119/176: loss - 0.075329, val loss - 0.107752\n",
      "Epoch 120/176: loss - 0.069869, val loss - 0.103205\n",
      "Epoch 121/176: loss - 0.069006, val loss - 0.112307\n",
      "Epoch 122/176: loss - 0.067276, val loss - 0.107152\n",
      "Epoch 123/176: loss - 0.068220, val loss - 0.106251\n",
      "Epoch 124/176: loss - 0.069443, val loss - 0.105633\n",
      "Epoch 125/176: loss - 0.066366, val loss - 0.115391\n",
      "Epoch 126/176: loss - 0.062638, val loss - 0.111864\n",
      "Epoch 127/176: loss - 0.062841, val loss - 0.115907\n",
      "Epoch 128/176: loss - 0.062349, val loss - 0.113083\n",
      "Epoch 129/176: loss - 0.065455, val loss - 0.128946\n",
      "Epoch 130/176: loss - 0.064291, val loss - 0.112011\n",
      "Epoch 131/176: loss - 0.064754, val loss - 0.118717\n",
      "Epoch 132/176: loss - 0.064974, val loss - 0.112368\n",
      "Epoch 133/176: loss - 0.064270, val loss - 0.113972\n",
      "Epoch 134/176: loss - 0.063322, val loss - 0.118436\n",
      "Epoch 135/176: loss - 0.062903, val loss - 0.122305\n",
      "Epoch 136/176: loss - 0.063166, val loss - 0.107696\n",
      "Epoch 137/176: loss - 0.066113, val loss - 0.102773\n",
      "Epoch 138/176: loss - 0.063286, val loss - 0.120498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/176: loss - 0.060577, val loss - 0.095867\n",
      "Epoch 140/176: loss - 0.059173, val loss - 0.122469\n",
      "Epoch 141/176: loss - 0.062099, val loss - 0.111742\n",
      "Epoch 142/176: loss - 0.065095, val loss - 0.120519\n",
      "Epoch 143/176: loss - 0.063205, val loss - 0.104821\n",
      "Epoch 144/176: loss - 0.059378, val loss - 0.100512\n",
      "Epoch 145/176: loss - 0.061639, val loss - 0.110854\n",
      "Epoch 146/176: loss - 0.062959, val loss - 0.110446\n",
      "Epoch 147/176: loss - 0.063791, val loss - 0.133408\n",
      "Epoch 148/176: loss - 0.061851, val loss - 0.105172\n",
      "Epoch 149/176: loss - 0.061564, val loss - 0.111064\n",
      "Epoch 150/176: loss - 0.061333, val loss - 0.120327\n",
      "Epoch 151/176: loss - 0.061578, val loss - 0.120027\n",
      "Epoch 152/176: loss - 0.062279, val loss - 0.102374\n",
      "Epoch 153/176: loss - 0.060878, val loss - 0.119819\n",
      "Epoch 154/176: loss - 0.064835, val loss - 0.130977\n",
      "Epoch 155/176: loss - 0.066450, val loss - 0.128795\n",
      "Epoch 156/176: loss - 0.065071, val loss - 0.113050\n",
      "Epoch 157/176: loss - 0.064475, val loss - 0.109927\n",
      "Epoch 158/176: loss - 0.065193, val loss - 0.093849\n",
      "Epoch 159/176: loss - 0.066044, val loss - 0.116199\n",
      "Epoch 160/176: loss - 0.068154, val loss - 0.090303\n",
      "Epoch 161/176: loss - 0.067319, val loss - 0.111740\n",
      "Epoch 162/176: loss - 0.063132, val loss - 0.108046\n",
      "Epoch 163/176: loss - 0.062889, val loss - 0.118753\n",
      "Epoch 164/176: loss - 0.062799, val loss - 0.110843\n",
      "Epoch 165/176: loss - 0.062299, val loss - 0.113831\n",
      "Epoch 166/176: loss - 0.061459, val loss - 0.102667\n",
      "Epoch 167/176: loss - 0.062081, val loss - 0.120337\n",
      "Epoch 168/176: loss - 0.062121, val loss - 0.113259\n",
      "Epoch 169/176: loss - 0.064984, val loss - 0.101211\n",
      "Epoch 170/176: loss - 0.065817, val loss - 0.110581\n",
      "Epoch 171/176: loss - 0.065215, val loss - 0.109063\n",
      "Epoch 172/176: loss - 0.062112, val loss - 0.104193\n",
      "Epoch 173/176: loss - 0.061919, val loss - 0.124544\n",
      "Epoch 174/176: loss - 0.064038, val loss - 0.122510\n",
      "Epoch 175/176: loss - 0.062558, val loss - 0.103054\n",
      "Epoch 176/176: loss - 0.061811, val loss - 0.104963\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.192104, val loss - 0.203835\n",
      "Epoch 2/24: loss - 0.154886, val loss - 0.135581\n",
      "Epoch 3/24: loss - 0.127955, val loss - 0.118425\n",
      "Epoch 4/24: loss - 0.128465, val loss - 0.105175\n",
      "Epoch 5/24: loss - 0.122820, val loss - 0.132862\n",
      "Epoch 6/24: loss - 0.119837, val loss - 0.101397\n",
      "Epoch 7/24: loss - 0.108394, val loss - 0.098063\n",
      "Epoch 8/24: loss - 0.094357, val loss - 0.102623\n",
      "Epoch 9/24: loss - 0.099438, val loss - 0.099897\n",
      "Epoch 10/24: loss - 0.095083, val loss - 0.096158\n",
      "Epoch 11/24: loss - 0.092563, val loss - 0.089307\n",
      "Epoch 12/24: loss - 0.091867, val loss - 0.096220\n",
      "Epoch 13/24: loss - 0.092890, val loss - 0.099822\n",
      "Epoch 14/24: loss - 0.089466, val loss - 0.088000\n",
      "Epoch 15/24: loss - 0.091587, val loss - 0.089364\n",
      "Epoch 16/24: loss - 0.091768, val loss - 0.095811\n",
      "Epoch 17/24: loss - 0.090681, val loss - 0.091879\n",
      "Epoch 18/24: loss - 0.087516, val loss - 0.094541\n",
      "Epoch 19/24: loss - 0.089379, val loss - 0.094107\n",
      "Epoch 20/24: loss - 0.090388, val loss - 0.096882\n",
      "Epoch 21/24: loss - 0.088764, val loss - 0.098267\n",
      "Epoch 22/24: loss - 0.088083, val loss - 0.093555\n",
      "Epoch 23/24: loss - 0.087023, val loss - 0.095245\n",
      "Epoch 24/24: loss - 0.085939, val loss - 0.094035\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.166835, val loss - 0.114384\n",
      "Epoch 2/66: loss - 0.113402, val loss - 0.107642\n",
      "Epoch 3/66: loss - 0.105539, val loss - 0.114186\n",
      "Epoch 4/66: loss - 0.112453, val loss - 0.109255\n",
      "Epoch 5/66: loss - 0.098630, val loss - 0.111197\n",
      "Epoch 6/66: loss - 0.109690, val loss - 0.106927\n",
      "Epoch 7/66: loss - 0.109152, val loss - 0.116549\n",
      "Epoch 8/66: loss - 0.108318, val loss - 0.115183\n",
      "Epoch 9/66: loss - 0.105415, val loss - 0.103155\n",
      "Epoch 10/66: loss - 0.104474, val loss - 0.110092\n",
      "Epoch 11/66: loss - 0.103783, val loss - 0.117912\n",
      "Epoch 12/66: loss - 0.100200, val loss - 0.107071\n",
      "Epoch 13/66: loss - 0.106385, val loss - 0.105172\n",
      "Epoch 14/66: loss - 0.098770, val loss - 0.105565\n",
      "Epoch 15/66: loss - 0.098247, val loss - 0.105039\n",
      "Epoch 16/66: loss - 0.102582, val loss - 0.100159\n",
      "Epoch 17/66: loss - 0.091709, val loss - 0.096819\n",
      "Epoch 18/66: loss - 0.098993, val loss - 0.098641\n",
      "Epoch 19/66: loss - 0.093416, val loss - 0.102961\n",
      "Epoch 20/66: loss - 0.094169, val loss - 0.098767\n",
      "Epoch 21/66: loss - 0.096531, val loss - 0.103345\n",
      "Epoch 22/66: loss - 0.091868, val loss - 0.095962\n",
      "Epoch 23/66: loss - 0.095047, val loss - 0.096911\n",
      "Epoch 24/66: loss - 0.090003, val loss - 0.095906\n",
      "Epoch 25/66: loss - 0.092361, val loss - 0.097853\n",
      "Epoch 26/66: loss - 0.097905, val loss - 0.096293\n",
      "Epoch 27/66: loss - 0.086036, val loss - 0.100781\n",
      "Epoch 28/66: loss - 0.096700, val loss - 0.096733\n",
      "Epoch 29/66: loss - 0.087455, val loss - 0.097818\n",
      "Epoch 30/66: loss - 0.088114, val loss - 0.093653\n",
      "Epoch 31/66: loss - 0.089760, val loss - 0.104963\n",
      "Epoch 32/66: loss - 0.089615, val loss - 0.101145\n",
      "Epoch 33/66: loss - 0.082784, val loss - 0.096095\n",
      "Epoch 34/66: loss - 0.082308, val loss - 0.097172\n",
      "Epoch 35/66: loss - 0.083920, val loss - 0.091047\n",
      "Epoch 36/66: loss - 0.087885, val loss - 0.100510\n",
      "Epoch 37/66: loss - 0.085236, val loss - 0.096020\n",
      "Epoch 38/66: loss - 0.088241, val loss - 0.104516\n",
      "Epoch 39/66: loss - 0.086167, val loss - 0.092898\n",
      "Epoch 40/66: loss - 0.085128, val loss - 0.097975\n",
      "Epoch 41/66: loss - 0.083492, val loss - 0.094938\n",
      "Epoch 42/66: loss - 0.083776, val loss - 0.093649\n",
      "Epoch 43/66: loss - 0.087448, val loss - 0.093674\n",
      "Epoch 44/66: loss - 0.083947, val loss - 0.093109\n",
      "Epoch 45/66: loss - 0.087394, val loss - 0.094177\n",
      "Epoch 46/66: loss - 0.088072, val loss - 0.100203\n",
      "Epoch 47/66: loss - 0.084711, val loss - 0.092362\n",
      "Epoch 48/66: loss - 0.087786, val loss - 0.092705\n",
      "Epoch 49/66: loss - 0.083421, val loss - 0.093986\n",
      "Epoch 50/66: loss - 0.085347, val loss - 0.099606\n",
      "Epoch 51/66: loss - 0.087740, val loss - 0.092747\n",
      "Epoch 52/66: loss - 0.089623, val loss - 0.093271\n",
      "Epoch 53/66: loss - 0.081102, val loss - 0.092681\n",
      "Epoch 54/66: loss - 0.082226, val loss - 0.096768\n",
      "Epoch 55/66: loss - 0.086499, val loss - 0.097053\n",
      "Epoch 56/66: loss - 0.088792, val loss - 0.100417\n",
      "Epoch 57/66: loss - 0.082172, val loss - 0.096525\n",
      "Epoch 58/66: loss - 0.080974, val loss - 0.096818\n",
      "Epoch 59/66: loss - 0.085657, val loss - 0.091075\n",
      "Epoch 60/66: loss - 0.082863, val loss - 0.095912\n",
      "Epoch 61/66: loss - 0.085331, val loss - 0.100816\n",
      "Epoch 62/66: loss - 0.086299, val loss - 0.099683\n",
      "Epoch 63/66: loss - 0.082207, val loss - 0.096516\n",
      "Epoch 64/66: loss - 0.083952, val loss - 0.094925\n",
      "Epoch 65/66: loss - 0.084596, val loss - 0.100527\n",
      "Epoch 66/66: loss - 0.088092, val loss - 0.094724\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.219979, val loss - 0.149083\n",
      "Epoch 2/24: loss - 0.131314, val loss - 0.160779\n",
      "Epoch 3/24: loss - 0.131796, val loss - 0.135733\n",
      "Epoch 4/24: loss - 0.123346, val loss - 0.137042\n",
      "Epoch 5/24: loss - 0.117363, val loss - 0.129565\n",
      "Epoch 6/24: loss - 0.114938, val loss - 0.126148\n",
      "Epoch 7/24: loss - 0.096184, val loss - 0.110622\n",
      "Epoch 8/24: loss - 0.097729, val loss - 0.144561\n",
      "Epoch 9/24: loss - 0.112075, val loss - 0.113953\n",
      "Epoch 10/24: loss - 0.103040, val loss - 0.103875\n",
      "Epoch 11/24: loss - 0.089845, val loss - 0.092915\n",
      "Epoch 12/24: loss - 0.093544, val loss - 0.096331\n",
      "Epoch 13/24: loss - 0.092741, val loss - 0.103504\n",
      "Epoch 14/24: loss - 0.095606, val loss - 0.097198\n",
      "Epoch 15/24: loss - 0.091262, val loss - 0.116819\n",
      "Epoch 16/24: loss - 0.101306, val loss - 0.110357\n",
      "Epoch 17/24: loss - 0.094935, val loss - 0.098501\n",
      "Epoch 18/24: loss - 0.087809, val loss - 0.095154\n",
      "Epoch 19/24: loss - 0.090469, val loss - 0.097444\n",
      "Epoch 20/24: loss - 0.093603, val loss - 0.105631\n",
      "Epoch 21/24: loss - 0.091577, val loss - 0.094979\n",
      "Epoch 22/24: loss - 0.090250, val loss - 0.107904\n",
      "Epoch 23/24: loss - 0.089592, val loss - 0.099727\n",
      "Epoch 24/24: loss - 0.085341, val loss - 0.097514\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1684 - val_loss: 0.0898\n",
      "Epoch 2/28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.0763\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0721\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0740\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0729\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0753\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0693\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0700\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0659\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0655\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0643\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0628\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0641\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0630\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0636\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0604\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0672\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0571\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0593\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0657\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0721\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0540\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0578\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0544\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0570\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0693\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0680\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0646\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1870 - val_loss: 0.1213\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.1033\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.0991\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0900\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0847\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0898\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0908\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0820\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0936\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0819\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0863\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0780\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.1025\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0876\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0794\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0769\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.1092\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0821\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0821\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0996\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0929\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0847\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0891\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0808\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0827\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0983\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.1441\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0837\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.1360\n",
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0933\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0887\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0986\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0999\n",
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.1367\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0966\n",
      "Epoch 1/29\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3202 - val_loss: 0.1786\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1199 - val_loss: 0.1134\n",
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.0922\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0958\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.1008\n",
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0852\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0805\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0848\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0846\n",
      "Epoch 10/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0826\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0918\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0951\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0822\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0865\n",
      "Epoch 15/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.1017\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0920\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0933\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0843\n",
      "Epoch 19/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0993\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0934\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.1168\n",
      "Epoch 22/29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.1091\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.1305\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0970\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.1252\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.1017\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0877\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0914\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.1261\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2351 - val_loss: 0.1420\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1200 - val_loss: 0.0992\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1117 - val_loss: 0.0938\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0987 - val_loss: 0.0884\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0993\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0878\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0848\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0842\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0870\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0791\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0946\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0998\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0829\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0832\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.1058\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0847\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0882\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0966\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0981\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0969\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.1106\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.1318\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.1326\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.1084\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.1098\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.1029\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0916\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.1143\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.1195\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.1106\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0996\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.1209\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0942\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0960\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2245 - val_loss: 0.1817\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1580 - val_loss: 0.1641\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1507 - val_loss: 0.1585\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1429 - val_loss: 0.1556\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1359 - val_loss: 0.1475\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1300 - val_loss: 0.1443\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1258 - val_loss: 0.1400\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1212 - val_loss: 0.1368\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1172 - val_loss: 0.1323\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1139 - val_loss: 0.1305\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1105 - val_loss: 0.1259\n",
      "Epoch 12/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1080 - val_loss: 0.1224\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1050 - val_loss: 0.1207\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1025 - val_loss: 0.1171\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0994 - val_loss: 0.1153\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0975 - val_loss: 0.1114\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0967 - val_loss: 0.1094\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0938 - val_loss: 0.1062\n",
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0926 - val_loss: 0.1037\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0905 - val_loss: 0.1020\n",
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0895 - val_loss: 0.1004\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0889 - val_loss: 0.0986\n",
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0878 - val_loss: 0.0975\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0866 - val_loss: 0.0959\n",
      "Epoch 25/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0874 - val_loss: 0.0945\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0858 - val_loss: 0.0942\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0859 - val_loss: 0.0940\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0849 - val_loss: 0.0941\n",
      "Epoch 29/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0850 - val_loss: 0.0925\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0922\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0921\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0915\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0834 - val_loss: 0.0914\n",
      "Epoch 34/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0837 - val_loss: 0.0909\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0914\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0911\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0830 - val_loss: 0.0911\n",
      "Epoch 38/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0829 - val_loss: 0.0917\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0928\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0820 - val_loss: 0.0913\n",
      "Epoch 41/108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0820 - val_loss: 0.0911\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0820 - val_loss: 0.0910\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0821 - val_loss: 0.0901\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0817 - val_loss: 0.0908\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0821 - val_loss: 0.0921\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0818 - val_loss: 0.0900\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0817 - val_loss: 0.0903\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0820 - val_loss: 0.0906\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0815 - val_loss: 0.0900\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0824 - val_loss: 0.0925\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0815 - val_loss: 0.0902\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0810 - val_loss: 0.0911\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0899\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0820 - val_loss: 0.0898\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0811 - val_loss: 0.0900\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0905\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0805 - val_loss: 0.0900\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0808 - val_loss: 0.0901\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0801 - val_loss: 0.0902\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0904\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0911\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0811 - val_loss: 0.0905\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0905\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0802 - val_loss: 0.0899\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.0900\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.0910\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0811 - val_loss: 0.0910\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0794 - val_loss: 0.0907\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0795 - val_loss: 0.0909\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0806 - val_loss: 0.0909\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0798 - val_loss: 0.0905\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0801 - val_loss: 0.0901\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0792 - val_loss: 0.0904\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0793 - val_loss: 0.0907\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0795 - val_loss: 0.0905\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0789 - val_loss: 0.0915\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0801 - val_loss: 0.0901\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0793 - val_loss: 0.0900\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0787 - val_loss: 0.0903\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0791 - val_loss: 0.0919\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0809 - val_loss: 0.0906\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0787 - val_loss: 0.0907\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0787 - val_loss: 0.0909\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0785 - val_loss: 0.0909\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0796 - val_loss: 0.0924\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0789 - val_loss: 0.0910\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0784 - val_loss: 0.0906\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0785 - val_loss: 0.0912\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0779 - val_loss: 0.0908\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0786 - val_loss: 0.0924\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0782 - val_loss: 0.0908\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0789 - val_loss: 0.0920\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0784 - val_loss: 0.0908\n",
      "Epoch 94/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0777 - val_loss: 0.0916\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0778 - val_loss: 0.0911\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0784 - val_loss: 0.0912\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0777 - val_loss: 0.0922\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0778 - val_loss: 0.0911\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0773 - val_loss: 0.0915\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0775 - val_loss: 0.0925\n",
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0786 - val_loss: 0.0918\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0786 - val_loss: 0.0914\n",
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0772 - val_loss: 0.0916\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0773 - val_loss: 0.0914\n",
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0774 - val_loss: 0.0915\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0776 - val_loss: 0.0920\n",
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0774 - val_loss: 0.0916\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0769 - val_loss: 0.0924\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1366 - val_loss: 0.0934\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0969 - val_loss: 0.0860\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0811\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0773\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0795\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0740\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0725\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0710\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0697\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0726\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0699\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0705\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0708\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0669\n",
      "Epoch 15/34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0663\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0715\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0657\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0667\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0658\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0650\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0666\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0660\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0688\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0668\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0639\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0646\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0644\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0670\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0666\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0632\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0630\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0631\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0669\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0659\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1573 - val_loss: 0.1249\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.0993\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.0969\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0926 - val_loss: 0.0927\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0911\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0877\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0917\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0845\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0874\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0840\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0842\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0840\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0821\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0868\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0840\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0844\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0820\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.0828\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0863\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0948\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0831\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0773 - val_loss: 0.0836\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0844\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0843\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0811\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0814\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0929\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0798\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0868\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0808\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0865\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0843\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0827\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0886\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0862\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0839\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1468 - val_loss: 0.1526\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1416 - val_loss: 0.1479\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1371 - val_loss: 0.1434\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1408\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 0.1350\n",
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 0.1315\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1252\n",
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.1196\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.1127\n",
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1072\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.1035\n",
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.1009\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0950 - val_loss: 0.1000\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.0991\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.0988\n",
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.0979\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0922 - val_loss: 0.0974\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0975\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0968\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0907 - val_loss: 0.0963\n",
      "Epoch 21/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.0962\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0965\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0960\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.0956\n",
      "Epoch 25/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0954\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0962\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0953\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.0956\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0955\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0955\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0942\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0944\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0944\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0942\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0936\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0948\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0942\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.0936\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.0937\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0939\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0934\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0936\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0937\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0941\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0938\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.0935\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.0937\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.0940\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0933\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0937\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.0934\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.0936\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0928\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.0937\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0935\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.0927\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0929\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.0927\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0932\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0935\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0922\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0943\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0932\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0929\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0927\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.0924\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0927\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0929\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.0924\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0830 - val_loss: 0.0924\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2609 - val_loss: 0.2247\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1635 - val_loss: 0.1717\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1482 - val_loss: 0.1633\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1398 - val_loss: 0.1557\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1282 - val_loss: 0.1426\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1158 - val_loss: 0.1274\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.1162\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.1114\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0964 - val_loss: 0.1073\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1065\n",
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0935 - val_loss: 0.1055\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.1023\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0916 - val_loss: 0.1026\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0909 - val_loss: 0.1003\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0906 - val_loss: 0.0995\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0987\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0993\n",
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0978\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0973\n",
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0881 - val_loss: 0.0975\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.0997\n",
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0961\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0959\n",
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0955\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0962\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0970\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0947\n",
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.0971\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.0942\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.0980\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0935\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0960\n",
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.0937\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0846 - val_loss: 0.0939\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0925\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0847 - val_loss: 0.0941\n",
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.0930\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0847 - val_loss: 0.0946\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.0929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0956\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.0934\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0935\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0935\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.0935\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0938\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0922\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0828 - val_loss: 0.0927\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0827 - val_loss: 0.0928\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0933\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.0926\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0936\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.0941\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0926\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0934\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.0939\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0942\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0935\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0931\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0965\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0934\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0935\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0934\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0933\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1731 - val_loss: 0.1803\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1249 - val_loss: 0.1258\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0924 - val_loss: 0.1014\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0887 - val_loss: 0.1077\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0889 - val_loss: 0.1014\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.1031\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0964\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.0980\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0887 - val_loss: 0.0952\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.0951\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0962\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0937\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0972\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0949\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0932\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0970\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.1018\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.0954\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0945\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.0957\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0955\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0938\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0930\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.0966\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.1162\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.1077\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2718 - val_loss: 0.1785\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1728 - val_loss: 0.1337\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1353 - val_loss: 0.1148\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1139 - val_loss: 0.1023\n",
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.0965\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.0905\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0874\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0856\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0828\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0825\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0813\n",
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0804\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0805\n",
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0793\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0823\n",
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0791\n",
      "Epoch 17/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0785\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0814\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0784\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0797\n",
      "Epoch 21/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0781\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0784\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0783\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0782\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0777\n",
      "Epoch 26/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0781\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0773\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0770\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0782\n",
      "Epoch 30/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0773\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0778\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0773\n",
      "Epoch 33/138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0767\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0767\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0768\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0771\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0768\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0770\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0764\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0779\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0771\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0773\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0772\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0772\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0767\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0771\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0780\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0772\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0765\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0773\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0777\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0761\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0766\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0768\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0769\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0769\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0761\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0769\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0765\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0772\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0800\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0762\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0760\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0769\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0766\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0769\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.0779\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.0762\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0765\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0768\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0773\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0787\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0795\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0759\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0773\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0775\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0768\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0770\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0778\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0781\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0776\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0763\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0771\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0763\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0775\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0769\n",
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0776\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0773\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0793\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0775\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0789\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0764\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0762\n",
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0771\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0770\n",
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0768\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0768\n",
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0763\n",
      "Epoch 99/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0765\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0758\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0766\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0803\n",
      "Epoch 103/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0758\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0765\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0769\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0762\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0765\n",
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0761\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0768\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0796\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0769\n",
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0765\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0789\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0763\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0762\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0773\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0765\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0782\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0758\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0765\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0774\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0764\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0767\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0766\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0768\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0779\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0772\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0764\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0771\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0765\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0764\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0765\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0801\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0770\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0771\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0777\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0770\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1973 - val_loss: 0.1683\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1680 - val_loss: 0.1525\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1566 - val_loss: 0.1435\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1355\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1302\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1372 - val_loss: 0.1259\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1335 - val_loss: 0.1231\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1314 - val_loss: 0.1212\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1286 - val_loss: 0.1184\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.1166\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1255 - val_loss: 0.1150\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1150\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1227 - val_loss: 0.1130\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1131\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1120\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1202 - val_loss: 0.1127\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 0.1107\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1115\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.1097\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.1094\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.1102\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.1090\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.1083\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.1086\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1084\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1075\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.1083\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1070\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1063\n",
      "Epoch 30/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.1066\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.1058\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.1058\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.1048\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1035\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1084 - val_loss: 0.1031\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1064 - val_loss: 0.1023\n",
      "Epoch 37/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.1004\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1029 - val_loss: 0.0993\n",
      "Epoch 39/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1032 - val_loss: 0.0979\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.0960\n",
      "Epoch 41/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.0956\n",
      "Epoch 42/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.0956\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0948\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.0944\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.0944\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.0960\n",
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.0934\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0945 - val_loss: 0.0941\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.0931\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0961 - val_loss: 0.0953\n",
      "Epoch 51/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 0.0930\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.0935\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0932\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.0931\n",
      "Epoch 55/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0924\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.0937\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.0922\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0923\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0919\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.0951\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.0930\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0927\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.0917\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0916\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0918\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0916\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0911\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0913\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0922\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0914\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 0.0911\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0913\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0909\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0907\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0910\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0911\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0905\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0907\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0911\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0906\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0905\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0909\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0901\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0899\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.0903\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0902\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0899\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0901\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0898\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0911\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.0898\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0896\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0903\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0890\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0898\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0921\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0893\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0886\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.0894\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0896\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0883\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0890\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0884\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0880\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0904\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.0884\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.0898\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0882\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0885\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0875\n",
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0873\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0872\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0897\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0874\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0904\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0871\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0881\n",
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0882\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0869\n",
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0868\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0864\n",
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0872\n",
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0867\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0867\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0873\n",
      "Epoch 128/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0888\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0896\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0869\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0885\n",
      "Epoch 132/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0873\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0859\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0870\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0860\n",
      "Epoch 136/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0863\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0879\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0857\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0882\n",
      "Epoch 140/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0861\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0874\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0868\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0859\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0870\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0872\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0869\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0862\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0865\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0872\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2937 - val_loss: 0.1793\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1658 - val_loss: 0.1499\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.1563\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1357 - val_loss: 0.1361\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1313 - val_loss: 0.1349\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1286 - val_loss: 0.1298\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1284 - val_loss: 0.1351\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.1305\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1277 - val_loss: 0.1283\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.1247\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1237 - val_loss: 0.1213\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1186 - val_loss: 0.1181\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1139 - val_loss: 0.1129\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1081 - val_loss: 0.1127\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1063\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1051 - val_loss: 0.1075\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.1065\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.1254\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 0.1069\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.1021\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.1081\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0972\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0963\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0965\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0990\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.1139\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.1021\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.1083\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.1060\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.1010\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.0974\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0989\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0986\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.1002\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0974\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.1045\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0983\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0987\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.1032\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0993\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.1058\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0975\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.1007\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.1012\n",
      "Epoch 45/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0990\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.1017\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.1041\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.1026\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.1036\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0990\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.1034\n",
      "Epoch 52/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.1000\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.1064\n",
      "Epoch 54/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.1024\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.1079\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.1026\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.8290 - val_loss: 0.4067\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.3386\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2555 - val_loss: 0.2774\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2134 - val_loss: 0.2337\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1825 - val_loss: 0.2048\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1623 - val_loss: 0.1874\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1728\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1404 - val_loss: 0.1625\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1552\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1288 - val_loss: 0.1505\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1260 - val_loss: 0.1452\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1428\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.1386\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.1382\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1349\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1302\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1102 - val_loss: 0.1265\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1088 - val_loss: 0.1245\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 0.1211\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.1205\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1217\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 0.1174\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.1151\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.1139\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.1146\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.1111\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.1104\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.1095\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.1151\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0980 - val_loss: 0.1070\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.1063\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.1064\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0926 - val_loss: 0.1058\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.1057\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.1048\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.1037\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.1043\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.1023\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.1035\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.1033\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.1019\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.1017\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.1020\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.1024\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0993\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.1000\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.1002\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.1003\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0990\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0993\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.1020\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0984\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0978\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.1018\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0980\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.1001\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0981\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.1007\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0977\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4284 - val_loss: 0.2790\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2284 - val_loss: 0.2327\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1897 - val_loss: 0.2088\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1707 - val_loss: 0.1968\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1855\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1534 - val_loss: 0.1802\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1741\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1693\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1632\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.1613\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1335 - val_loss: 0.1564\n",
      "Epoch 12/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 0.1521\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1503\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.1470\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.1446\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 0.1400\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 0.1376\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.1348\n",
      "Epoch 19/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1316\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1125 - val_loss: 0.1293\n",
      "Epoch 21/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.1267\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.1223\n",
      "Epoch 23/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.1213\n",
      "Epoch 24/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.1166\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.1147\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1126\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.1105\n",
      "Epoch 28/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.1097\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.1080\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.1072\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.1073\n",
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.1061\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0922 - val_loss: 0.1055\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.1059\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.1063\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.1042\n",
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.1053\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.1049\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.1052\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.1033\n",
      "Epoch 1/47\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.3756 - val_loss: 0.2928\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1788 - val_loss: 0.1261\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1276 - val_loss: 0.1080\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1028 - val_loss: 0.0868\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0884 - val_loss: 0.0788\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0827 - val_loss: 0.0759\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0793 - val_loss: 0.0743\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0774 - val_loss: 0.0733\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0753 - val_loss: 0.0709\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0721 - val_loss: 0.0703\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0700 - val_loss: 0.0694\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0692\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0692 - val_loss: 0.0693\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0681 - val_loss: 0.0686\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0674 - val_loss: 0.0694\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0701 - val_loss: 0.0686\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0667 - val_loss: 0.0693\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0652 - val_loss: 0.0682\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0654 - val_loss: 0.0703\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0670\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0700 - val_loss: 0.0662\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0672 - val_loss: 0.0678\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0644 - val_loss: 0.0663\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0643 - val_loss: 0.0658\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0638 - val_loss: 0.0663\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0635 - val_loss: 0.0659\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0686 - val_loss: 0.0660\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0656 - val_loss: 0.0650\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0658 - val_loss: 0.0647\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0623 - val_loss: 0.0696\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0646 - val_loss: 0.0635\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0622 - val_loss: 0.0635\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0622 - val_loss: 0.0635\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0640 - val_loss: 0.0645\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0654 - val_loss: 0.0678\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0652 - val_loss: 0.0627\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0656 - val_loss: 0.0620\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0613 - val_loss: 0.0672\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0623 - val_loss: 0.0632\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0610 - val_loss: 0.0644\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0605 - val_loss: 0.0611\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0598 - val_loss: 0.0621\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0595 - val_loss: 0.0609\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0595 - val_loss: 0.0609\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0596 - val_loss: 0.0625\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0622 - val_loss: 0.0633\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0623 - val_loss: 0.0605\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.2763 - val_loss: 0.2505\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1745 - val_loss: 0.1387\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1369 - val_loss: 0.1241\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1167 - val_loss: 0.1030\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1009 - val_loss: 0.0893\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0937 - val_loss: 0.0848\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0859 - val_loss: 0.0784\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0836 - val_loss: 0.0802\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0798 - val_loss: 0.0760\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0791 - val_loss: 0.0732\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0761 - val_loss: 0.0734\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0813 - val_loss: 0.0739\n",
      "Epoch 13/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0754 - val_loss: 0.0725\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0740 - val_loss: 0.0719\n",
      "Epoch 15/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0713\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0764 - val_loss: 0.0704\n",
      "Epoch 17/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0725 - val_loss: 0.0695\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0702 - val_loss: 0.0718\n",
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0708 - val_loss: 0.0701\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0743 - val_loss: 0.0695\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0725 - val_loss: 0.0684\n",
      "Epoch 22/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0707 - val_loss: 0.0697\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0685\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0703 - val_loss: 0.0690\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0680 - val_loss: 0.0696\n",
      "Epoch 26/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0684 - val_loss: 0.0699\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0764 - val_loss: 0.0707\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0709 - val_loss: 0.0681\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0699 - val_loss: 0.0729\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0669 - val_loss: 0.0700\n",
      "Epoch 31/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0685 - val_loss: 0.0699\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0696 - val_loss: 0.0674\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0661 - val_loss: 0.0777\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0694 - val_loss: 0.0669\n",
      "Epoch 35/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0687 - val_loss: 0.0690\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0736 - val_loss: 0.0694\n",
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0739\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0701 - val_loss: 0.0783\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0676 - val_loss: 0.0667\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0655 - val_loss: 0.0713\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0657 - val_loss: 0.0680\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0668 - val_loss: 0.0679\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0663 - val_loss: 0.0663\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0665 - val_loss: 0.0666\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0658 - val_loss: 0.0684\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3860 - val_loss: 0.2411\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1525 - val_loss: 0.1068\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1095 - val_loss: 0.0984\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0951 - val_loss: 0.0825\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0884 - val_loss: 0.0809\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0856 - val_loss: 0.0776\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0838 - val_loss: 0.0740\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0744 - val_loss: 0.0759\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0755 - val_loss: 0.0715\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0780 - val_loss: 0.0830\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0780 - val_loss: 0.0708\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0701\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0727\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0744 - val_loss: 0.0703\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0724 - val_loss: 0.0756\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0752 - val_loss: 0.0883\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0694\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0677 - val_loss: 0.0708\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0695 - val_loss: 0.0701\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0673 - val_loss: 0.0696\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0676 - val_loss: 0.0754\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0680 - val_loss: 0.0756\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0678 - val_loss: 0.0725\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2110 - val_loss: 0.2076\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1410 - val_loss: 0.1302\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1211 - val_loss: 0.1351\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1083 - val_loss: 0.1094\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0977 - val_loss: 0.1064\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0924 - val_loss: 0.1006\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0870 - val_loss: 0.0908\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0806 - val_loss: 0.0859\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0780 - val_loss: 0.0830\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0781 - val_loss: 0.0966\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0779 - val_loss: 0.0811\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0741 - val_loss: 0.0796\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0769 - val_loss: 0.0793\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0739 - val_loss: 0.0784\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0724 - val_loss: 0.0896\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0742 - val_loss: 0.0872\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0736 - val_loss: 0.0767\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0719 - val_loss: 0.0792\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0722 - val_loss: 0.0834\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0686 - val_loss: 0.0769\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0680 - val_loss: 0.0852\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0705 - val_loss: 0.0797\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0703 - val_loss: 0.0753\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.4207 - val_loss: 0.3279\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2450 - val_loss: 0.2455\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1767 - val_loss: 0.1640\n",
      "Epoch 4/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1404 - val_loss: 0.1388\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1096 - val_loss: 0.1073\n",
      "Epoch 6/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0964 - val_loss: 0.0993\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0876 - val_loss: 0.0925\n",
      "Epoch 8/31\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0897 - val_loss: 0.0901\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0858 - val_loss: 0.0862\n",
      "Epoch 10/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0828 - val_loss: 0.0848\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0799 - val_loss: 0.0897\n",
      "Epoch 13/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0809 - val_loss: 0.0954\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0784 - val_loss: 0.0884\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0774 - val_loss: 0.0833\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0832 - val_loss: 0.0927\n",
      "Epoch 17/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0773 - val_loss: 0.0885\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0738 - val_loss: 0.0817\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0702 - val_loss: 0.0885\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0728 - val_loss: 0.0809\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0732 - val_loss: 0.0951\n",
      "Epoch 22/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0734 - val_loss: 0.0917\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0747 - val_loss: 0.0803\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0705 - val_loss: 0.0812\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0734 - val_loss: 0.0993\n",
      "Epoch 26/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0754 - val_loss: 0.0828\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0701 - val_loss: 0.0819\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0693 - val_loss: 0.0836\n",
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0726 - val_loss: 0.0946\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0681 - val_loss: 0.0790\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0711 - val_loss: 0.0840\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 0.749269, val loss - 0.110897\n",
      "Epoch 2/15: loss - 0.124787, val loss - 0.083798\n",
      "Epoch 3/15: loss - 0.094656, val loss - 0.171815\n",
      "Epoch 4/15: loss - 0.103675, val loss - 0.089595\n",
      "Epoch 5/15: loss - 0.092571, val loss - 0.070920\n",
      "Epoch 6/15: loss - 0.083691, val loss - 0.069871\n",
      "Epoch 7/15: loss - 0.079887, val loss - 0.075749\n",
      "Epoch 8/15: loss - 0.074753, val loss - 0.066930\n",
      "Epoch 9/15: loss - 0.071351, val loss - 0.062822\n",
      "Epoch 10/15: loss - 0.070112, val loss - 0.061660\n",
      "Epoch 11/15: loss - 0.065993, val loss - 0.063186\n",
      "Epoch 12/15: loss - 0.065468, val loss - 0.057823\n",
      "Epoch 13/15: loss - 0.063263, val loss - 0.057051\n",
      "Epoch 14/15: loss - 0.063657, val loss - 0.056097\n",
      "Epoch 15/15: loss - 0.061490, val loss - 0.056019\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.301617, val loss - 0.110275\n",
      "Epoch 2/176: loss - 0.118581, val loss - 0.102702\n",
      "Epoch 3/176: loss - 0.105471, val loss - 0.099525\n",
      "Epoch 4/176: loss - 0.110827, val loss - 0.085373\n",
      "Epoch 5/176: loss - 0.102394, val loss - 0.156571\n",
      "Epoch 6/176: loss - 0.111569, val loss - 0.087093\n",
      "Epoch 7/176: loss - 0.091076, val loss - 0.091417\n",
      "Epoch 8/176: loss - 0.080793, val loss - 0.080263\n",
      "Epoch 9/176: loss - 0.094755, val loss - 0.093481\n",
      "Epoch 10/176: loss - 0.088287, val loss - 0.080286\n",
      "Epoch 11/176: loss - 0.081865, val loss - 0.093878\n",
      "Epoch 12/176: loss - 0.077817, val loss - 0.071579\n",
      "Epoch 13/176: loss - 0.071563, val loss - 0.078531\n",
      "Epoch 14/176: loss - 0.070756, val loss - 0.069146\n",
      "Epoch 15/176: loss - 0.068100, val loss - 0.086460\n",
      "Epoch 16/176: loss - 0.067476, val loss - 0.094196\n",
      "Epoch 17/176: loss - 0.066229, val loss - 0.088008\n",
      "Epoch 18/176: loss - 0.063646, val loss - 0.089906\n",
      "Epoch 19/176: loss - 0.063297, val loss - 0.094609\n",
      "Epoch 20/176: loss - 0.064254, val loss - 0.090741\n",
      "Epoch 21/176: loss - 0.064619, val loss - 0.084304\n",
      "Epoch 22/176: loss - 0.060393, val loss - 0.085375\n",
      "Epoch 23/176: loss - 0.065520, val loss - 0.086516\n",
      "Epoch 24/176: loss - 0.062256, val loss - 0.094836\n",
      "Epoch 25/176: loss - 0.065238, val loss - 0.084099\n",
      "Epoch 26/176: loss - 0.061428, val loss - 0.100936\n",
      "Epoch 27/176: loss - 0.066183, val loss - 0.078226\n",
      "Epoch 28/176: loss - 0.068224, val loss - 0.111166\n",
      "Epoch 29/176: loss - 0.063416, val loss - 0.071457\n",
      "Epoch 30/176: loss - 0.060070, val loss - 0.080634\n",
      "Epoch 31/176: loss - 0.059175, val loss - 0.073836\n",
      "Epoch 32/176: loss - 0.060195, val loss - 0.078107\n",
      "Epoch 33/176: loss - 0.064721, val loss - 0.094421\n",
      "Epoch 34/176: loss - 0.062536, val loss - 0.079752\n",
      "Epoch 35/176: loss - 0.056348, val loss - 0.075937\n",
      "Epoch 36/176: loss - 0.055868, val loss - 0.076256\n",
      "Epoch 37/176: loss - 0.061684, val loss - 0.080258\n",
      "Epoch 38/176: loss - 0.058903, val loss - 0.081299\n",
      "Epoch 39/176: loss - 0.057753, val loss - 0.098703\n",
      "Epoch 40/176: loss - 0.059082, val loss - 0.091414\n",
      "Epoch 41/176: loss - 0.058795, val loss - 0.076285\n",
      "Epoch 42/176: loss - 0.058000, val loss - 0.086112\n",
      "Epoch 43/176: loss - 0.061537, val loss - 0.088433\n",
      "Epoch 44/176: loss - 0.061233, val loss - 0.079274\n",
      "Epoch 45/176: loss - 0.060861, val loss - 0.096290\n",
      "Epoch 46/176: loss - 0.058690, val loss - 0.101328\n",
      "Epoch 47/176: loss - 0.064596, val loss - 0.082843\n",
      "Epoch 48/176: loss - 0.063660, val loss - 0.071475\n",
      "Epoch 49/176: loss - 0.056859, val loss - 0.085260\n",
      "Epoch 50/176: loss - 0.059229, val loss - 0.065650\n",
      "Epoch 51/176: loss - 0.058734, val loss - 0.067796\n",
      "Epoch 52/176: loss - 0.065588, val loss - 0.121991\n",
      "Epoch 53/176: loss - 0.063395, val loss - 0.075381\n",
      "Epoch 54/176: loss - 0.060041, val loss - 0.089477\n",
      "Epoch 55/176: loss - 0.062159, val loss - 0.082462\n",
      "Epoch 56/176: loss - 0.059825, val loss - 0.072103\n",
      "Epoch 57/176: loss - 0.056235, val loss - 0.066806\n",
      "Epoch 58/176: loss - 0.056637, val loss - 0.062637\n",
      "Epoch 59/176: loss - 0.056213, val loss - 0.075235\n",
      "Epoch 60/176: loss - 0.055168, val loss - 0.065082\n",
      "Epoch 61/176: loss - 0.053466, val loss - 0.064613\n",
      "Epoch 62/176: loss - 0.052716, val loss - 0.069568\n",
      "Epoch 63/176: loss - 0.052439, val loss - 0.077470\n",
      "Epoch 64/176: loss - 0.054548, val loss - 0.073148\n",
      "Epoch 65/176: loss - 0.058478, val loss - 0.082763\n",
      "Epoch 66/176: loss - 0.060685, val loss - 0.061905\n",
      "Epoch 67/176: loss - 0.061117, val loss - 0.073563\n",
      "Epoch 68/176: loss - 0.057412, val loss - 0.069270\n",
      "Epoch 69/176: loss - 0.057943, val loss - 0.065764\n",
      "Epoch 70/176: loss - 0.052755, val loss - 0.066939\n",
      "Epoch 71/176: loss - 0.053339, val loss - 0.065697\n",
      "Epoch 72/176: loss - 0.057984, val loss - 0.097830\n",
      "Epoch 73/176: loss - 0.061254, val loss - 0.077031\n",
      "Epoch 74/176: loss - 0.064045, val loss - 0.071377\n",
      "Epoch 75/176: loss - 0.059850, val loss - 0.082826\n",
      "Epoch 76/176: loss - 0.061450, val loss - 0.071070\n",
      "Epoch 77/176: loss - 0.052946, val loss - 0.070234\n",
      "Epoch 78/176: loss - 0.055383, val loss - 0.082920\n",
      "Epoch 79/176: loss - 0.065313, val loss - 0.080608\n",
      "Epoch 80/176: loss - 0.055838, val loss - 0.069258\n",
      "Epoch 81/176: loss - 0.054842, val loss - 0.080908\n",
      "Epoch 82/176: loss - 0.054407, val loss - 0.071003\n",
      "Epoch 83/176: loss - 0.054858, val loss - 0.074062\n",
      "Epoch 84/176: loss - 0.062821, val loss - 0.085874\n",
      "Epoch 85/176: loss - 0.058593, val loss - 0.083652\n",
      "Epoch 86/176: loss - 0.055629, val loss - 0.067756\n",
      "Epoch 87/176: loss - 0.059902, val loss - 0.074378\n",
      "Epoch 88/176: loss - 0.056686, val loss - 0.077241\n",
      "Epoch 89/176: loss - 0.058559, val loss - 0.090528\n",
      "Epoch 90/176: loss - 0.061988, val loss - 0.094219\n",
      "Epoch 91/176: loss - 0.066264, val loss - 0.082527\n",
      "Epoch 92/176: loss - 0.059131, val loss - 0.086901\n",
      "Epoch 93/176: loss - 0.057231, val loss - 0.098378\n",
      "Epoch 94/176: loss - 0.061138, val loss - 0.089873\n",
      "Epoch 95/176: loss - 0.061189, val loss - 0.088473\n",
      "Epoch 96/176: loss - 0.061202, val loss - 0.073108\n",
      "Epoch 97/176: loss - 0.065110, val loss - 0.075547\n",
      "Epoch 98/176: loss - 0.057095, val loss - 0.101542\n",
      "Epoch 99/176: loss - 0.055222, val loss - 0.072879\n",
      "Epoch 100/176: loss - 0.053734, val loss - 0.081474\n",
      "Epoch 101/176: loss - 0.054325, val loss - 0.066979\n",
      "Epoch 102/176: loss - 0.064415, val loss - 0.089047\n",
      "Epoch 103/176: loss - 0.056827, val loss - 0.075496\n",
      "Epoch 104/176: loss - 0.053316, val loss - 0.082432\n",
      "Epoch 105/176: loss - 0.054070, val loss - 0.079657\n",
      "Epoch 106/176: loss - 0.059673, val loss - 0.081837\n",
      "Epoch 107/176: loss - 0.057843, val loss - 0.075105\n",
      "Epoch 108/176: loss - 0.054171, val loss - 0.075465\n",
      "Epoch 109/176: loss - 0.061699, val loss - 0.074978\n",
      "Epoch 110/176: loss - 0.055205, val loss - 0.065299\n",
      "Epoch 111/176: loss - 0.052182, val loss - 0.075238\n",
      "Epoch 112/176: loss - 0.052795, val loss - 0.067480\n",
      "Epoch 113/176: loss - 0.053577, val loss - 0.072831\n",
      "Epoch 114/176: loss - 0.055441, val loss - 0.069442\n",
      "Epoch 115/176: loss - 0.054990, val loss - 0.074741\n",
      "Epoch 116/176: loss - 0.054881, val loss - 0.070202\n",
      "Epoch 117/176: loss - 0.053466, val loss - 0.069022\n",
      "Epoch 118/176: loss - 0.053101, val loss - 0.069512\n",
      "Epoch 119/176: loss - 0.053023, val loss - 0.065902\n",
      "Epoch 120/176: loss - 0.051055, val loss - 0.066921\n",
      "Epoch 121/176: loss - 0.049653, val loss - 0.065732\n",
      "Epoch 122/176: loss - 0.052673, val loss - 0.076337\n",
      "Epoch 123/176: loss - 0.055113, val loss - 0.070789\n",
      "Epoch 124/176: loss - 0.054116, val loss - 0.076289\n",
      "Epoch 125/176: loss - 0.054847, val loss - 0.075599\n",
      "Epoch 126/176: loss - 0.057963, val loss - 0.071731\n",
      "Epoch 127/176: loss - 0.065269, val loss - 0.071637\n",
      "Epoch 128/176: loss - 0.057664, val loss - 0.078858\n",
      "Epoch 129/176: loss - 0.052573, val loss - 0.067191\n",
      "Epoch 130/176: loss - 0.049929, val loss - 0.067942\n",
      "Epoch 131/176: loss - 0.051869, val loss - 0.072953\n",
      "Epoch 132/176: loss - 0.055261, val loss - 0.078166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/176: loss - 0.057474, val loss - 0.082740\n",
      "Epoch 134/176: loss - 0.052635, val loss - 0.072977\n",
      "Epoch 135/176: loss - 0.051565, val loss - 0.071455\n",
      "Epoch 136/176: loss - 0.052726, val loss - 0.074006\n",
      "Epoch 137/176: loss - 0.054143, val loss - 0.083315\n",
      "Epoch 138/176: loss - 0.057709, val loss - 0.068683\n",
      "Epoch 139/176: loss - 0.054671, val loss - 0.071196\n",
      "Epoch 140/176: loss - 0.055421, val loss - 0.079246\n",
      "Epoch 141/176: loss - 0.054772, val loss - 0.066150\n",
      "Epoch 142/176: loss - 0.051798, val loss - 0.072022\n",
      "Epoch 143/176: loss - 0.053760, val loss - 0.076782\n",
      "Epoch 144/176: loss - 0.058295, val loss - 0.075636\n",
      "Epoch 145/176: loss - 0.054628, val loss - 0.085871\n",
      "Epoch 146/176: loss - 0.054301, val loss - 0.073638\n",
      "Epoch 147/176: loss - 0.052435, val loss - 0.072855\n",
      "Epoch 148/176: loss - 0.053268, val loss - 0.081819\n",
      "Epoch 149/176: loss - 0.056590, val loss - 0.078595\n",
      "Epoch 150/176: loss - 0.054600, val loss - 0.072784\n",
      "Epoch 151/176: loss - 0.053552, val loss - 0.098981\n",
      "Epoch 152/176: loss - 0.051527, val loss - 0.081330\n",
      "Epoch 153/176: loss - 0.058157, val loss - 0.078906\n",
      "Epoch 154/176: loss - 0.058582, val loss - 0.071839\n",
      "Epoch 155/176: loss - 0.056099, val loss - 0.073908\n",
      "Epoch 156/176: loss - 0.056935, val loss - 0.067670\n",
      "Epoch 157/176: loss - 0.055238, val loss - 0.076183\n",
      "Epoch 158/176: loss - 0.056851, val loss - 0.082736\n",
      "Epoch 159/176: loss - 0.056137, val loss - 0.074480\n",
      "Epoch 160/176: loss - 0.059728, val loss - 0.090690\n",
      "Epoch 161/176: loss - 0.056997, val loss - 0.069275\n",
      "Epoch 162/176: loss - 0.064305, val loss - 0.076988\n",
      "Epoch 163/176: loss - 0.056453, val loss - 0.066884\n",
      "Epoch 164/176: loss - 0.054807, val loss - 0.079578\n",
      "Epoch 165/176: loss - 0.054546, val loss - 0.072928\n",
      "Epoch 166/176: loss - 0.056011, val loss - 0.077544\n",
      "Epoch 167/176: loss - 0.059452, val loss - 0.082388\n",
      "Epoch 168/176: loss - 0.057919, val loss - 0.089270\n",
      "Epoch 169/176: loss - 0.057771, val loss - 0.086779\n",
      "Epoch 170/176: loss - 0.056296, val loss - 0.088918\n",
      "Epoch 171/176: loss - 0.052748, val loss - 0.076901\n",
      "Epoch 172/176: loss - 0.054428, val loss - 0.072080\n",
      "Epoch 173/176: loss - 0.053801, val loss - 0.069629\n",
      "Epoch 174/176: loss - 0.056190, val loss - 0.099307\n",
      "Epoch 175/176: loss - 0.055611, val loss - 0.085748\n",
      "Epoch 176/176: loss - 0.057760, val loss - 0.074080\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.151941, val loss - 0.115585\n",
      "Epoch 2/24: loss - 0.128223, val loss - 0.146132\n",
      "Epoch 3/24: loss - 0.123472, val loss - 0.109771\n",
      "Epoch 4/24: loss - 0.110068, val loss - 0.109721\n",
      "Epoch 5/24: loss - 0.106661, val loss - 0.095209\n",
      "Epoch 6/24: loss - 0.093981, val loss - 0.088971\n",
      "Epoch 7/24: loss - 0.087209, val loss - 0.083312\n",
      "Epoch 8/24: loss - 0.095581, val loss - 0.099849\n",
      "Epoch 9/24: loss - 0.092839, val loss - 0.082543\n",
      "Epoch 10/24: loss - 0.076954, val loss - 0.079209\n",
      "Epoch 11/24: loss - 0.085474, val loss - 0.080731\n",
      "Epoch 12/24: loss - 0.079434, val loss - 0.078755\n",
      "Epoch 13/24: loss - 0.077789, val loss - 0.078132\n",
      "Epoch 14/24: loss - 0.074894, val loss - 0.078550\n",
      "Epoch 15/24: loss - 0.076021, val loss - 0.079205\n",
      "Epoch 16/24: loss - 0.076337, val loss - 0.075536\n",
      "Epoch 17/24: loss - 0.077790, val loss - 0.078385\n",
      "Epoch 18/24: loss - 0.075303, val loss - 0.087595\n",
      "Epoch 19/24: loss - 0.074409, val loss - 0.085659\n",
      "Epoch 20/24: loss - 0.073177, val loss - 0.079506\n",
      "Epoch 21/24: loss - 0.073483, val loss - 0.081290\n",
      "Epoch 22/24: loss - 0.074684, val loss - 0.080517\n",
      "Epoch 23/24: loss - 0.070860, val loss - 0.079939\n",
      "Epoch 24/24: loss - 0.073197, val loss - 0.090347\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.240726, val loss - 0.127886\n",
      "Epoch 2/66: loss - 0.112014, val loss - 0.114840\n",
      "Epoch 3/66: loss - 0.108116, val loss - 0.107803\n",
      "Epoch 4/66: loss - 0.098577, val loss - 0.091849\n",
      "Epoch 5/66: loss - 0.100993, val loss - 0.093845\n",
      "Epoch 6/66: loss - 0.091545, val loss - 0.097471\n",
      "Epoch 7/66: loss - 0.092250, val loss - 0.086674\n",
      "Epoch 8/66: loss - 0.088610, val loss - 0.090806\n",
      "Epoch 9/66: loss - 0.092746, val loss - 0.094087\n",
      "Epoch 10/66: loss - 0.085039, val loss - 0.092548\n",
      "Epoch 11/66: loss - 0.092627, val loss - 0.084555\n",
      "Epoch 12/66: loss - 0.080960, val loss - 0.095758\n",
      "Epoch 13/66: loss - 0.080362, val loss - 0.085905\n",
      "Epoch 14/66: loss - 0.091961, val loss - 0.097662\n",
      "Epoch 15/66: loss - 0.082785, val loss - 0.086513\n",
      "Epoch 16/66: loss - 0.083186, val loss - 0.090009\n",
      "Epoch 17/66: loss - 0.078101, val loss - 0.095186\n",
      "Epoch 18/66: loss - 0.085752, val loss - 0.084873\n",
      "Epoch 19/66: loss - 0.078003, val loss - 0.104920\n",
      "Epoch 20/66: loss - 0.078965, val loss - 0.090531\n",
      "Epoch 21/66: loss - 0.081451, val loss - 0.081819\n",
      "Epoch 22/66: loss - 0.078548, val loss - 0.089475\n",
      "Epoch 23/66: loss - 0.077793, val loss - 0.080191\n",
      "Epoch 24/66: loss - 0.072865, val loss - 0.081877\n",
      "Epoch 25/66: loss - 0.074316, val loss - 0.095302\n",
      "Epoch 26/66: loss - 0.079353, val loss - 0.088675\n",
      "Epoch 27/66: loss - 0.072327, val loss - 0.081947\n",
      "Epoch 28/66: loss - 0.069199, val loss - 0.085494\n",
      "Epoch 29/66: loss - 0.070394, val loss - 0.079012\n",
      "Epoch 30/66: loss - 0.072909, val loss - 0.077505\n",
      "Epoch 31/66: loss - 0.068894, val loss - 0.083506\n",
      "Epoch 32/66: loss - 0.067137, val loss - 0.080707\n",
      "Epoch 33/66: loss - 0.071259, val loss - 0.082197\n",
      "Epoch 34/66: loss - 0.067829, val loss - 0.079877\n",
      "Epoch 35/66: loss - 0.067621, val loss - 0.090379\n",
      "Epoch 36/66: loss - 0.068662, val loss - 0.077332\n",
      "Epoch 37/66: loss - 0.069755, val loss - 0.083694\n",
      "Epoch 38/66: loss - 0.067423, val loss - 0.080789\n",
      "Epoch 39/66: loss - 0.065826, val loss - 0.089075\n",
      "Epoch 40/66: loss - 0.065582, val loss - 0.095424\n",
      "Epoch 41/66: loss - 0.066015, val loss - 0.082271\n",
      "Epoch 42/66: loss - 0.065794, val loss - 0.084957\n",
      "Epoch 43/66: loss - 0.068313, val loss - 0.082591\n",
      "Epoch 44/66: loss - 0.066422, val loss - 0.081237\n",
      "Epoch 45/66: loss - 0.065017, val loss - 0.082834\n",
      "Epoch 46/66: loss - 0.066095, val loss - 0.084399\n",
      "Epoch 47/66: loss - 0.064982, val loss - 0.084902\n",
      "Epoch 48/66: loss - 0.064454, val loss - 0.076552\n",
      "Epoch 49/66: loss - 0.066836, val loss - 0.078954\n",
      "Epoch 50/66: loss - 0.062504, val loss - 0.088855\n",
      "Epoch 51/66: loss - 0.065074, val loss - 0.078248\n",
      "Epoch 52/66: loss - 0.065186, val loss - 0.088952\n",
      "Epoch 53/66: loss - 0.060444, val loss - 0.091781\n",
      "Epoch 54/66: loss - 0.065631, val loss - 0.080233\n",
      "Epoch 55/66: loss - 0.063856, val loss - 0.081949\n",
      "Epoch 56/66: loss - 0.062500, val loss - 0.092379\n",
      "Epoch 57/66: loss - 0.063040, val loss - 0.081799\n",
      "Epoch 58/66: loss - 0.064101, val loss - 0.084283\n",
      "Epoch 59/66: loss - 0.061092, val loss - 0.083179\n",
      "Epoch 60/66: loss - 0.064630, val loss - 0.088390\n",
      "Epoch 61/66: loss - 0.064052, val loss - 0.086974\n",
      "Epoch 62/66: loss - 0.062912, val loss - 0.079165\n",
      "Epoch 63/66: loss - 0.064293, val loss - 0.089714\n",
      "Epoch 64/66: loss - 0.062008, val loss - 0.077100\n",
      "Epoch 65/66: loss - 0.061498, val loss - 0.085084\n",
      "Epoch 66/66: loss - 0.060473, val loss - 0.088988\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.186120, val loss - 0.113779\n",
      "Epoch 2/24: loss - 0.123268, val loss - 0.112844\n",
      "Epoch 3/24: loss - 0.108728, val loss - 0.116679\n",
      "Epoch 4/24: loss - 0.101622, val loss - 0.107355\n",
      "Epoch 5/24: loss - 0.100053, val loss - 0.098386\n",
      "Epoch 6/24: loss - 0.086435, val loss - 0.101498\n",
      "Epoch 7/24: loss - 0.095759, val loss - 0.087542\n",
      "Epoch 8/24: loss - 0.089889, val loss - 0.114748\n",
      "Epoch 9/24: loss - 0.087300, val loss - 0.119791\n",
      "Epoch 10/24: loss - 0.096026, val loss - 0.110673\n",
      "Epoch 11/24: loss - 0.082661, val loss - 0.099531\n",
      "Epoch 12/24: loss - 0.079718, val loss - 0.088244\n",
      "Epoch 13/24: loss - 0.077770, val loss - 0.080807\n",
      "Epoch 14/24: loss - 0.070595, val loss - 0.082563\n",
      "Epoch 15/24: loss - 0.077339, val loss - 0.082991\n",
      "Epoch 16/24: loss - 0.074271, val loss - 0.089433\n",
      "Epoch 17/24: loss - 0.076850, val loss - 0.095760\n",
      "Epoch 18/24: loss - 0.068235, val loss - 0.084423\n",
      "Epoch 19/24: loss - 0.068405, val loss - 0.090451\n",
      "Epoch 20/24: loss - 0.078724, val loss - 0.082222\n",
      "Epoch 21/24: loss - 0.069469, val loss - 0.084876\n",
      "Epoch 22/24: loss - 0.070994, val loss - 0.086106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24: loss - 0.069548, val loss - 0.078877\n",
      "Epoch 24/24: loss - 0.070952, val loss - 0.088672\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1707 - val_loss: 0.1517\n",
      "Epoch 2/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.1042\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0784\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0730\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0668\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0622\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0596\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0746\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0653\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0605\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0565\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0651\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0560\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0619\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0521\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0498\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0567\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0510\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0610\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0511\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0529\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0565\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0545 - val_loss: 0.0518\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0502\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0531\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0535\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0532\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0496\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1527 - val_loss: 0.1159\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1049 - val_loss: 0.1321\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1023 - val_loss: 0.0911\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.1003\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0674 - val_loss: 0.0668\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.0701\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0643 - val_loss: 0.0670\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0809\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0657 - val_loss: 0.0641\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0643\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0643\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0748\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0664\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0606\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0609\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0672\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0614\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0562\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0789\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0560\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0692\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0588\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0589\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0610\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0692\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0645\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0635\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0596\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0599\n",
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0616\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0738\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0583\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0751\n",
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0638\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0608\n",
      "Epoch 1/29\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3994 - val_loss: 0.1256\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 0.1004\n",
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0892 - val_loss: 0.1165\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0677 - val_loss: 0.0821\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0675 - val_loss: 0.0732\n",
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0657 - val_loss: 0.0990\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0647 - val_loss: 0.0723\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0623 - val_loss: 0.0836\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0635 - val_loss: 0.0728\n",
      "Epoch 10/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0721\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0677\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0618 - val_loss: 0.0978\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0571 - val_loss: 0.0674\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0556 - val_loss: 0.0683\n",
      "Epoch 15/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0580 - val_loss: 0.0641\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0527 - val_loss: 0.0815\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0666\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0727\n",
      "Epoch 19/29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0580 - val_loss: 0.0631\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0508 - val_loss: 0.0674\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0516 - val_loss: 0.1183\n",
      "Epoch 22/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0922\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0551 - val_loss: 0.0681\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0481 - val_loss: 0.0737\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0492 - val_loss: 0.0836\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0530 - val_loss: 0.0809\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0501 - val_loss: 0.0690\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0498 - val_loss: 0.0701\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0535 - val_loss: 0.0790\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3614 - val_loss: 0.1190\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1259 - val_loss: 0.1071\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0849 - val_loss: 0.0820\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0926\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0792\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0687 - val_loss: 0.0787\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0803\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.0738\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0889\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0755\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0719\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0597 - val_loss: 0.0903\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0606 - val_loss: 0.0695\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0644 - val_loss: 0.0681\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0969\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.1012\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0673\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0811\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0671\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0662\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.1164\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0693\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0806\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0807\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0680\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0792\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0679\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0843\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0702\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0657\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0720\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0717\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0475 - val_loss: 0.0664\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0958\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2981 - val_loss: 0.2402\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2266 - val_loss: 0.2321\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2020 - val_loss: 0.2007\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1846 - val_loss: 0.1820\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1665 - val_loss: 0.1723\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1526 - val_loss: 0.1592\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1409 - val_loss: 0.1471\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1314 - val_loss: 0.1406\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1233 - val_loss: 0.1321\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1162 - val_loss: 0.1257\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1107 - val_loss: 0.1222\n",
      "Epoch 12/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.1161\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1013 - val_loss: 0.1123\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0975 - val_loss: 0.1096\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.1027\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0908 - val_loss: 0.1025\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.0991\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.0946\n",
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0914\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0906\n",
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0976\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0879\n",
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0871\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0864\n",
      "Epoch 25/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0886\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0869\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0851\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0849\n",
      "Epoch 29/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0867\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0823\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0806\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0994\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0792\n",
      "Epoch 34/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0906\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0674 - val_loss: 0.0822\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0804\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0823\n",
      "Epoch 38/108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0799\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0795\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0823\n",
      "Epoch 41/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0789\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0785\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0861\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0793\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0777\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0887\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0813\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0765\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0904\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0829\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0792\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0872\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0644 - val_loss: 0.0761\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0800\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0794\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0776\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0889\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0747\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0794\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0803\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0760\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0864\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0762\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0846\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0764\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0743\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0798\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0742\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0809\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0810\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0764\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0616 - val_loss: 0.0765\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0813\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0758\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0769\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0777\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0769\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0743\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0837\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 0.0769\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0734\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0810\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0777\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0780\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0859\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0753\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0798\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0831\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0756\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0744\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0788\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0774\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0605 - val_loss: 0.0833\n",
      "Epoch 94/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0764\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0763\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0775\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0865\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0826\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0728\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0799\n",
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0728\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0858\n",
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0736\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0759\n",
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0857\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0770\n",
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0753\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0782\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1370 - val_loss: 0.0913\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0787\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0693\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0725\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0652\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0591\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0595\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0595\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0615\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0577\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0588\n",
      "Epoch 12/34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0571\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0567\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0567\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0570\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0564\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0609\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0606\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0647\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0655\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0579\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0626\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0586\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0562\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0637\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0562\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0554\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0575\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0630\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0681\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0594\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0556\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0601\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0539\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1385 - val_loss: 0.1480\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.1140\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1062 - val_loss: 0.0895\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.0858\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0806\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0729\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.0711\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0733\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0703\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0787\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0702\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0692\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0721\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0708\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0685\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0699\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0767\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0758\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0779\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0776\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0643 - val_loss: 0.0766\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0694\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0673\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0700\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0643 - val_loss: 0.0779\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0672\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0679\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0664\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0770\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0869\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0646 - val_loss: 0.0712\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0684\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0936\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0657 - val_loss: 0.0686\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0687\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0656\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3584 - val_loss: 0.1684\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1678 - val_loss: 0.1717\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 0.1705\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1513\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1473\n",
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1308 - val_loss: 0.1434\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.1412\n",
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.1322\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.1268\n",
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.1142\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1000 - val_loss: 0.1056\n",
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0920 - val_loss: 0.0949\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0873\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0827\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0864\n",
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.0827\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0786\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0822\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0787\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0824\n",
      "Epoch 21/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0782\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0795\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0761\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0801\n",
      "Epoch 25/71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0770\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0844\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0757\n",
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0805\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0761\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0824\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0719 - val_loss: 0.0778\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0777\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0769\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0769\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0716 - val_loss: 0.0793\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0744\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.0798\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0765\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0793\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0746\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0783\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0773\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0760\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0758\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0778\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0761\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0798\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0736\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0830\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0744\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0752\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0785\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0766\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0735\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0758\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0782\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0674 - val_loss: 0.0751\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0773\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0749\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0758\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0775\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0765\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0764\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0732\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0773\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0674 - val_loss: 0.0798\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0725\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0809\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0727\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0787\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0770\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6639 - val_loss: 0.3376\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3509 - val_loss: 0.1799\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1926 - val_loss: 0.1471\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1486 - val_loss: 0.1597\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1555\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1433\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1307 - val_loss: 0.1370\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1321\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.1257\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1132 - val_loss: 0.1173\n",
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 0.1116\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1066\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.1044\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0938 - val_loss: 0.0982\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.0955\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0967\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0946\n",
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0902\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0910\n",
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0916\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0870\n",
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0900\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0851\n",
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0850\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0871\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0849\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0849\n",
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0834\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0829\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0835\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0819\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0823\n",
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0828\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0800\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0805\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0786\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0802\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0807\n",
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0759\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0834\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0788\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0801\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0772\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0782\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0813\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0788\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0750\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0828\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0734\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0805\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0765\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0794\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0752\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0772\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0766\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0797\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0755\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0765\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0755\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0776\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0783\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0783\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1872 - val_loss: 0.1461\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1366 - val_loss: 0.1682\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 0.1336\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1382\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0931 - val_loss: 0.0952\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0829\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0859\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0831\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0832\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.1049\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0832\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0781\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0769\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0898\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0807\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0856\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0950\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0772\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0764\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0655 - val_loss: 0.0769\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0791\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0630 - val_loss: 0.0774\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0812\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0809\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0777\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0875\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.1624\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1242\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1248 - val_loss: 0.1067\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.1152\n",
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1012 - val_loss: 0.0865\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.0881\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0849\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0731\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0726\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0716\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0695\n",
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0708\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0680\n",
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0643\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0637\n",
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0633\n",
      "Epoch 17/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0654\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0633\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0696\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0665\n",
      "Epoch 21/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0637\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0609\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0622\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0614\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0683\n",
      "Epoch 26/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0634\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0596\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0612\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0645\n",
      "Epoch 30/138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0717\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0620\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0605\n",
      "Epoch 33/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0624\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0586\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0582\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0579\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0581\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0616\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0601\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0587\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0580\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0591\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0594\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0590\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0638\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0648\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0602\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0604\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0636\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0575\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0572\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0583\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0581\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0573\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0584\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0596\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0595\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0574\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0611\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0578\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0579\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0577\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0573\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0579\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0588\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0622\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0626\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0600\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0578\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0610\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0593\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0612\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0588\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0624\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0580\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0580\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0623\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0615\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0579\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0644\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0599\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0616\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0613\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0592\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0596\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0588\n",
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0584\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0600\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0585\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0653\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0594\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0583\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0603\n",
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0582\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0628\n",
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0647\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0590\n",
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0585\n",
      "Epoch 99/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0590\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0611\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0636\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0609\n",
      "Epoch 103/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0584\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0586\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0629\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0592\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0598\n",
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0596\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0587\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0616\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0588\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0607\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0600\n",
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0596\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0588\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0634\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0609\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0601\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0595\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0590\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0634\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0591\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0592\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0619\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0605\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0624\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0610\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0640\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0599\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0621\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0597\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0617\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0600\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0608\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0605\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0631\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0658\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.6345 - val_loss: 2.4480\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.4145 - val_loss: 1.4758\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4145 - val_loss: 0.7441\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6643 - val_loss: 0.3066\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2832 - val_loss: 0.2043\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1888 - val_loss: 0.1934\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1674 - val_loss: 0.1902\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1584 - val_loss: 0.1839\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1770\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1698\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1432 - val_loss: 0.1649\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1398 - val_loss: 0.1608\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1580\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1557\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1321 - val_loss: 0.1526\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1500\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1462\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.1452\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.1422\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.1412\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1228 - val_loss: 0.1390\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1379\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1206 - val_loss: 0.1367\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1197 - val_loss: 0.1353\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1189 - val_loss: 0.1330\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.1335\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.1332\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.1301\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.1282\n",
      "Epoch 30/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.1287\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1286\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1263\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.1250\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.1250\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1130 - val_loss: 0.1254\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.1246\n",
      "Epoch 37/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1124 - val_loss: 0.1224\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.1224\n",
      "Epoch 39/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.1229\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.1229\n",
      "Epoch 41/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.1211\n",
      "Epoch 42/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1201\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.1207\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1102 - val_loss: 0.1198\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.1199\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.1184\n",
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.1182\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1173\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1090 - val_loss: 0.1185\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1090 - val_loss: 0.1179\n",
      "Epoch 51/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.1170\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.1152\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.1148\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1083 - val_loss: 0.1168\n",
      "Epoch 55/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.1150\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1156\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1081 - val_loss: 0.1133\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1151\n",
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.1162\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.1121\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 0.1133\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1134\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1071 - val_loss: 0.1125\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.1134\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.1106\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.1114\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.1117\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.1120\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.1098\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1061 - val_loss: 0.1106\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1060 - val_loss: 0.1127\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.1086\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1056 - val_loss: 0.1095\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1052 - val_loss: 0.1084\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1052 - val_loss: 0.1080\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.1072\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.1072\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.1073\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1062\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.1049\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1030\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.1025\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1007\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.1017\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.0995\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0982 - val_loss: 0.0970\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.0983\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.0939\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.0942\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0938 - val_loss: 0.0912\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0922 - val_loss: 0.0923\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0899\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0883\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0887\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0856\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0876\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0834\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0830\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0837\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0814\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0812\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.0809\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0801\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0819\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0783\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0800\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0785\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0783\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0789\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0775\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0770\n",
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0802\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0757\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0777\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0762\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0779\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0761\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0768\n",
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0793\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0769\n",
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0757\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0768\n",
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0773\n",
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0748\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0773\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0756\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0777\n",
      "Epoch 128/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0765\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0756\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0763\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0763\n",
      "Epoch 132/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0758\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0761\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0754\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0762\n",
      "Epoch 136/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0775\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0748\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0781\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0752\n",
      "Epoch 140/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0774\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0763\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0762\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0751\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0769\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0751\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0747\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0765\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0729\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0757\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4557 - val_loss: 0.2394\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1553 - val_loss: 0.1437\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1640\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1297 - val_loss: 0.1367\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1272 - val_loss: 0.1486\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1396\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1367\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1422\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.1334\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1402\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1165 - val_loss: 0.1286\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1338\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1230\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.1322\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1455\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.1333\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1158\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.1323\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.1179\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.1154\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1188\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.1093\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 0.1191\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.1077\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.1148\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.1076\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0840\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0845\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0832\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0814\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0942\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0956\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0802\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0804\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0882\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0802\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0827\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0757\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0875\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0784\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0854\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0835\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0738\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0808\n",
      "Epoch 45/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0974\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0785\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0739\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0752\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0927\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0755\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0894\n",
      "Epoch 52/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0743\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0870\n",
      "Epoch 54/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0910\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0770\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0724\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.8911 - val_loss: 1.1386\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8402 - val_loss: 0.2984\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2432 - val_loss: 0.2302\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.2439\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1706 - val_loss: 0.2139\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1610 - val_loss: 0.1984\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1896\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1880\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1460 - val_loss: 0.1786\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1420 - val_loss: 0.1742\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1663\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1352 - val_loss: 0.1627\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1507\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1265 - val_loss: 0.1451\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1445\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1371\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1294\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.1274\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1081 - val_loss: 0.1242\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1056 - val_loss: 0.1181\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.1182\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.1117\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.1114\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.1100\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.1095\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.1069\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.1068\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.1041\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.1051\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.1029\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.1016\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.1021\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0995\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0997\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0985\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0965\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0974\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0968\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0946\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0961\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0948\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0952\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0922\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0927\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0932\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0921\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0899\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0928\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0883\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0901\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0890\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0905\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0866\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0893\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0870\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0888\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0854\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0865\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0866\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.2737 - val_loss: 0.3872\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2805 - val_loss: 0.2416\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.2252\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1719 - val_loss: 0.1770\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1528 - val_loss: 0.1654\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1581\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1320 - val_loss: 0.1513\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1247 - val_loss: 0.1447\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1398\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1133 - val_loss: 0.1337\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.1328\n",
      "Epoch 12/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1039 - val_loss: 0.1244\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1231\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.1195\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.1156\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0907 - val_loss: 0.1109\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.1119\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.1046\n",
      "Epoch 19/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.1030\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0998\n",
      "Epoch 21/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1039\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0936\n",
      "Epoch 23/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0943\n",
      "Epoch 24/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0954\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0946\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0897\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0898\n",
      "Epoch 28/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0893\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0914\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0847\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0888\n",
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0936\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0811\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0920\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0810\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0826\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0847\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0817\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0857\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0807\n",
      "Epoch 1/47\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.3021 - val_loss: 0.1272\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1431 - val_loss: 0.1061\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1085 - val_loss: 0.0873\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0923 - val_loss: 0.0765\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0845 - val_loss: 0.0717\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0802 - val_loss: 0.0685\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0745 - val_loss: 0.0654\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0725 - val_loss: 0.0639\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0707 - val_loss: 0.0631\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0705 - val_loss: 0.0622\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0665 - val_loss: 0.0625\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0672 - val_loss: 0.0607\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0646 - val_loss: 0.0609\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0626 - val_loss: 0.0599\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0621 - val_loss: 0.0596\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0638 - val_loss: 0.0612\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0639 - val_loss: 0.0618\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0602 - val_loss: 0.0586\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0581 - val_loss: 0.0586\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0597 - val_loss: 0.0589\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0609 - val_loss: 0.0577\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0572 - val_loss: 0.0594\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0604 - val_loss: 0.0588\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0574 - val_loss: 0.0569\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0559 - val_loss: 0.0582\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0577 - val_loss: 0.0582\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0579 - val_loss: 0.0619\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0596 - val_loss: 0.0575\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0594 - val_loss: 0.0563\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0554 - val_loss: 0.0561\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0557 - val_loss: 0.0571\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0553 - val_loss: 0.0575\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0556 - val_loss: 0.0556\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0539 - val_loss: 0.0555\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0546 - val_loss: 0.0562\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0533 - val_loss: 0.0552\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0566 - val_loss: 0.0550\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0542 - val_loss: 0.0551\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0542 - val_loss: 0.0560\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0536 - val_loss: 0.0558\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0568 - val_loss: 0.0550\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0534 - val_loss: 0.0567\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0549 - val_loss: 0.0579\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0536 - val_loss: 0.0567\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0547 - val_loss: 0.0556\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0533 - val_loss: 0.0551\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0521 - val_loss: 0.0552\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.4217 - val_loss: 0.1785\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2061 - val_loss: 0.1594\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1655 - val_loss: 0.1482\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1399 - val_loss: 0.1198\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1246 - val_loss: 0.1117\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1144 - val_loss: 0.0986\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1018 - val_loss: 0.0878\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0961 - val_loss: 0.0850\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0871 - val_loss: 0.0733\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0870 - val_loss: 0.0712\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0809 - val_loss: 0.0740\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0817 - val_loss: 0.0686\n",
      "Epoch 13/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0785 - val_loss: 0.0677\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0767 - val_loss: 0.0672\n",
      "Epoch 15/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0740 - val_loss: 0.0674\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0751 - val_loss: 0.0698\n",
      "Epoch 17/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0734 - val_loss: 0.0664\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0740 - val_loss: 0.0664\n",
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0704 - val_loss: 0.0683\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0712 - val_loss: 0.0693\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0727 - val_loss: 0.0674\n",
      "Epoch 22/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0683 - val_loss: 0.0670\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0691 - val_loss: 0.0681\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0700 - val_loss: 0.0714\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0689 - val_loss: 0.0687\n",
      "Epoch 26/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0669 - val_loss: 0.0676\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0700 - val_loss: 0.0679\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0695 - val_loss: 0.0721\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0733 - val_loss: 0.0674\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0643 - val_loss: 0.0681\n",
      "Epoch 31/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0662 - val_loss: 0.0691\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0652 - val_loss: 0.0686\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0678 - val_loss: 0.0713\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0674 - val_loss: 0.0697\n",
      "Epoch 35/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0665 - val_loss: 0.0693\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0667 - val_loss: 0.0684\n",
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0675 - val_loss: 0.0703\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0682 - val_loss: 0.0690\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0654 - val_loss: 0.0708\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0639 - val_loss: 0.0683\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0643 - val_loss: 0.0692\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0634 - val_loss: 0.0692\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0650 - val_loss: 0.0722\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0638 - val_loss: 0.0691\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0629 - val_loss: 0.0755\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.2429 - val_loss: 0.1328\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1364 - val_loss: 0.1026\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1021 - val_loss: 0.0804\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0903 - val_loss: 0.0746\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0819 - val_loss: 0.0691\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0808 - val_loss: 0.0701\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0811 - val_loss: 0.0688\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0805 - val_loss: 0.0672\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0777 - val_loss: 0.0694\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0786 - val_loss: 0.0666\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0741 - val_loss: 0.0664\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0721 - val_loss: 0.0735\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0768 - val_loss: 0.0690\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0727 - val_loss: 0.0688\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0717 - val_loss: 0.0681\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0732 - val_loss: 0.0692\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0701 - val_loss: 0.0693\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0681 - val_loss: 0.0694\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0684 - val_loss: 0.0697\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0676 - val_loss: 0.0697\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0690 - val_loss: 0.0712\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0683 - val_loss: 0.0707\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0661 - val_loss: 0.0744\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.5394 - val_loss: 0.1769\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1530 - val_loss: 0.1362\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1447 - val_loss: 0.1423\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1351 - val_loss: 0.1379\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1281 - val_loss: 0.1218\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1228 - val_loss: 0.1209\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1149 - val_loss: 0.1119\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1097 - val_loss: 0.1053\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1045 - val_loss: 0.1008\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0993 - val_loss: 0.0949\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0969 - val_loss: 0.0884\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0917 - val_loss: 0.0861\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0915 - val_loss: 0.0829\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0874 - val_loss: 0.0812\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0864 - val_loss: 0.0827\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0873 - val_loss: 0.0766\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0856 - val_loss: 0.0802\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0838 - val_loss: 0.0749\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0818 - val_loss: 0.0764\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0818 - val_loss: 0.0739\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0811 - val_loss: 0.0734\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0805 - val_loss: 0.0746\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0803 - val_loss: 0.0737\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1751 - val_loss: 0.1637\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1365 - val_loss: 0.1155\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1159 - val_loss: 0.1062\n",
      "Epoch 4/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1037 - val_loss: 0.0901\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0977 - val_loss: 0.0854\n",
      "Epoch 6/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0928 - val_loss: 0.0854\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0912 - val_loss: 0.0800\n",
      "Epoch 8/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0916 - val_loss: 0.0941\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0893 - val_loss: 0.0776\n",
      "Epoch 10/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0770\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0866 - val_loss: 0.0842\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0823 - val_loss: 0.0775\n",
      "Epoch 13/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0826 - val_loss: 0.0756\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0822 - val_loss: 0.0758\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0828 - val_loss: 0.0752\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0822 - val_loss: 0.0745\n",
      "Epoch 17/31\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0809 - val_loss: 0.0747\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0811 - val_loss: 0.0796\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0776 - val_loss: 0.0745\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0772 - val_loss: 0.0753\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0776 - val_loss: 0.0743\n",
      "Epoch 22/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0769 - val_loss: 0.0759\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0776 - val_loss: 0.0759\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0788 - val_loss: 0.0798\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0772 - val_loss: 0.0751\n",
      "Epoch 26/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0758 - val_loss: 0.0773\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0756 - val_loss: 0.0768\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0749 - val_loss: 0.0748\n",
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0802 - val_loss: 0.0756\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0736 - val_loss: 0.0748\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0740 - val_loss: 0.0755\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 0.891748, val loss - 0.101887\n",
      "Epoch 2/15: loss - 0.250213, val loss - 0.118462\n",
      "Epoch 3/15: loss - 0.122702, val loss - 0.090244\n",
      "Epoch 4/15: loss - 0.099521, val loss - 0.070817\n",
      "Epoch 5/15: loss - 0.097373, val loss - 0.076780\n",
      "Epoch 6/15: loss - 0.091459, val loss - 0.069749\n",
      "Epoch 7/15: loss - 0.077461, val loss - 0.082069\n",
      "Epoch 8/15: loss - 0.078986, val loss - 0.071472\n",
      "Epoch 9/15: loss - 0.073000, val loss - 0.070681\n",
      "Epoch 10/15: loss - 0.070672, val loss - 0.076700\n",
      "Epoch 11/15: loss - 0.069515, val loss - 0.063986\n",
      "Epoch 12/15: loss - 0.069541, val loss - 0.070421\n",
      "Epoch 13/15: loss - 0.068766, val loss - 0.062108\n",
      "Epoch 14/15: loss - 0.067305, val loss - 0.065697\n",
      "Epoch 15/15: loss - 0.069355, val loss - 0.063578\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.314419, val loss - 0.190882\n",
      "Epoch 2/176: loss - 0.139934, val loss - 0.119021\n",
      "Epoch 3/176: loss - 0.112946, val loss - 0.107561\n",
      "Epoch 4/176: loss - 0.106397, val loss - 0.099200\n",
      "Epoch 5/176: loss - 0.107935, val loss - 0.088995\n",
      "Epoch 6/176: loss - 0.105524, val loss - 0.101383\n",
      "Epoch 7/176: loss - 0.099701, val loss - 0.101150\n",
      "Epoch 8/176: loss - 0.101521, val loss - 0.093071\n",
      "Epoch 9/176: loss - 0.096837, val loss - 0.086733\n",
      "Epoch 10/176: loss - 0.087658, val loss - 0.080406\n",
      "Epoch 11/176: loss - 0.087394, val loss - 0.134886\n",
      "Epoch 12/176: loss - 0.100393, val loss - 0.082114\n",
      "Epoch 13/176: loss - 0.085675, val loss - 0.078482\n",
      "Epoch 14/176: loss - 0.082423, val loss - 0.092103\n",
      "Epoch 15/176: loss - 0.088157, val loss - 0.077948\n",
      "Epoch 16/176: loss - 0.091519, val loss - 0.089966\n",
      "Epoch 17/176: loss - 0.086122, val loss - 0.080376\n",
      "Epoch 18/176: loss - 0.078964, val loss - 0.074566\n",
      "Epoch 19/176: loss - 0.080392, val loss - 0.076913\n",
      "Epoch 20/176: loss - 0.079851, val loss - 0.077528\n",
      "Epoch 21/176: loss - 0.077446, val loss - 0.077543\n",
      "Epoch 22/176: loss - 0.081436, val loss - 0.076169\n",
      "Epoch 23/176: loss - 0.079809, val loss - 0.081160\n",
      "Epoch 24/176: loss - 0.077813, val loss - 0.084875\n",
      "Epoch 25/176: loss - 0.081134, val loss - 0.089970\n",
      "Epoch 26/176: loss - 0.085954, val loss - 0.077547\n",
      "Epoch 27/176: loss - 0.083104, val loss - 0.108904\n",
      "Epoch 28/176: loss - 0.094602, val loss - 0.082820\n",
      "Epoch 29/176: loss - 0.084009, val loss - 0.078717\n",
      "Epoch 30/176: loss - 0.081565, val loss - 0.082600\n",
      "Epoch 31/176: loss - 0.081227, val loss - 0.082375\n",
      "Epoch 32/176: loss - 0.082592, val loss - 0.125988\n",
      "Epoch 33/176: loss - 0.100049, val loss - 0.115176\n",
      "Epoch 34/176: loss - 0.097365, val loss - 0.086578\n",
      "Epoch 35/176: loss - 0.081305, val loss - 0.091558\n",
      "Epoch 36/176: loss - 0.083727, val loss - 0.085556\n",
      "Epoch 37/176: loss - 0.079026, val loss - 0.086057\n",
      "Epoch 38/176: loss - 0.079176, val loss - 0.136896\n",
      "Epoch 39/176: loss - 0.088704, val loss - 0.100274\n",
      "Epoch 40/176: loss - 0.080480, val loss - 0.075406\n",
      "Epoch 41/176: loss - 0.070211, val loss - 0.092354\n",
      "Epoch 42/176: loss - 0.080796, val loss - 0.077034\n",
      "Epoch 43/176: loss - 0.072777, val loss - 0.073986\n",
      "Epoch 44/176: loss - 0.067680, val loss - 0.077232\n",
      "Epoch 45/176: loss - 0.076028, val loss - 0.075698\n",
      "Epoch 46/176: loss - 0.075234, val loss - 0.078303\n",
      "Epoch 47/176: loss - 0.075710, val loss - 0.081361\n",
      "Epoch 48/176: loss - 0.071066, val loss - 0.075096\n",
      "Epoch 49/176: loss - 0.070882, val loss - 0.088509\n",
      "Epoch 50/176: loss - 0.074359, val loss - 0.078116\n",
      "Epoch 51/176: loss - 0.070895, val loss - 0.093656\n",
      "Epoch 52/176: loss - 0.072299, val loss - 0.079043\n",
      "Epoch 53/176: loss - 0.068773, val loss - 0.089241\n",
      "Epoch 54/176: loss - 0.070312, val loss - 0.082624\n",
      "Epoch 55/176: loss - 0.072032, val loss - 0.085792\n",
      "Epoch 56/176: loss - 0.069020, val loss - 0.085408\n",
      "Epoch 57/176: loss - 0.069461, val loss - 0.082497\n",
      "Epoch 58/176: loss - 0.072766, val loss - 0.097943\n",
      "Epoch 59/176: loss - 0.073603, val loss - 0.094707\n",
      "Epoch 60/176: loss - 0.071329, val loss - 0.078223\n",
      "Epoch 61/176: loss - 0.069605, val loss - 0.077377\n",
      "Epoch 62/176: loss - 0.068782, val loss - 0.116854\n",
      "Epoch 63/176: loss - 0.075342, val loss - 0.083831\n",
      "Epoch 64/176: loss - 0.073230, val loss - 0.074746\n",
      "Epoch 65/176: loss - 0.065147, val loss - 0.080084\n",
      "Epoch 66/176: loss - 0.069704, val loss - 0.088898\n",
      "Epoch 67/176: loss - 0.069559, val loss - 0.079985\n",
      "Epoch 68/176: loss - 0.080280, val loss - 0.079529\n",
      "Epoch 69/176: loss - 0.067751, val loss - 0.075643\n",
      "Epoch 70/176: loss - 0.067327, val loss - 0.082155\n",
      "Epoch 71/176: loss - 0.068655, val loss - 0.087341\n",
      "Epoch 72/176: loss - 0.069205, val loss - 0.084630\n",
      "Epoch 73/176: loss - 0.069116, val loss - 0.084240\n",
      "Epoch 74/176: loss - 0.066862, val loss - 0.090848\n",
      "Epoch 75/176: loss - 0.068664, val loss - 0.081853\n",
      "Epoch 76/176: loss - 0.067661, val loss - 0.090454\n",
      "Epoch 77/176: loss - 0.066116, val loss - 0.076891\n",
      "Epoch 78/176: loss - 0.063241, val loss - 0.086414\n",
      "Epoch 79/176: loss - 0.068846, val loss - 0.082881\n",
      "Epoch 80/176: loss - 0.068952, val loss - 0.085873\n",
      "Epoch 81/176: loss - 0.066172, val loss - 0.095024\n",
      "Epoch 82/176: loss - 0.068449, val loss - 0.084094\n",
      "Epoch 83/176: loss - 0.072067, val loss - 0.103195\n",
      "Epoch 84/176: loss - 0.074552, val loss - 0.088845\n",
      "Epoch 85/176: loss - 0.069174, val loss - 0.085538\n",
      "Epoch 86/176: loss - 0.072915, val loss - 0.082612\n",
      "Epoch 87/176: loss - 0.066717, val loss - 0.078826\n",
      "Epoch 88/176: loss - 0.064429, val loss - 0.085817\n",
      "Epoch 89/176: loss - 0.070662, val loss - 0.088633\n",
      "Epoch 90/176: loss - 0.069628, val loss - 0.084769\n",
      "Epoch 91/176: loss - 0.064493, val loss - 0.087847\n",
      "Epoch 92/176: loss - 0.066745, val loss - 0.093899\n",
      "Epoch 93/176: loss - 0.065713, val loss - 0.084777\n",
      "Epoch 94/176: loss - 0.067328, val loss - 0.095978\n",
      "Epoch 95/176: loss - 0.066163, val loss - 0.089880\n",
      "Epoch 96/176: loss - 0.068413, val loss - 0.084968\n",
      "Epoch 97/176: loss - 0.063487, val loss - 0.087771\n",
      "Epoch 98/176: loss - 0.068171, val loss - 0.083697\n",
      "Epoch 99/176: loss - 0.063062, val loss - 0.096618\n",
      "Epoch 100/176: loss - 0.068407, val loss - 0.086948\n",
      "Epoch 101/176: loss - 0.063715, val loss - 0.083476\n",
      "Epoch 102/176: loss - 0.062260, val loss - 0.091343\n",
      "Epoch 103/176: loss - 0.068519, val loss - 0.093663\n",
      "Epoch 104/176: loss - 0.064099, val loss - 0.096244\n",
      "Epoch 105/176: loss - 0.072585, val loss - 0.077762\n",
      "Epoch 106/176: loss - 0.064879, val loss - 0.084957\n",
      "Epoch 107/176: loss - 0.068613, val loss - 0.087421\n",
      "Epoch 108/176: loss - 0.065374, val loss - 0.092093\n",
      "Epoch 109/176: loss - 0.064196, val loss - 0.097343\n",
      "Epoch 110/176: loss - 0.065912, val loss - 0.084197\n",
      "Epoch 111/176: loss - 0.063701, val loss - 0.102146\n",
      "Epoch 112/176: loss - 0.065566, val loss - 0.109863\n",
      "Epoch 113/176: loss - 0.073754, val loss - 0.097033\n",
      "Epoch 114/176: loss - 0.063915, val loss - 0.091647\n",
      "Epoch 115/176: loss - 0.064242, val loss - 0.123134\n",
      "Epoch 116/176: loss - 0.067522, val loss - 0.100737\n",
      "Epoch 117/176: loss - 0.076713, val loss - 0.100064\n",
      "Epoch 118/176: loss - 0.070792, val loss - 0.083819\n",
      "Epoch 119/176: loss - 0.068358, val loss - 0.092134\n",
      "Epoch 120/176: loss - 0.067615, val loss - 0.092353\n",
      "Epoch 121/176: loss - 0.065862, val loss - 0.081245\n",
      "Epoch 122/176: loss - 0.064295, val loss - 0.109912\n",
      "Epoch 123/176: loss - 0.067925, val loss - 0.104716\n",
      "Epoch 124/176: loss - 0.069159, val loss - 0.107597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/176: loss - 0.069175, val loss - 0.098858\n",
      "Epoch 126/176: loss - 0.065152, val loss - 0.095995\n",
      "Epoch 127/176: loss - 0.068950, val loss - 0.084021\n",
      "Epoch 128/176: loss - 0.067932, val loss - 0.079289\n",
      "Epoch 129/176: loss - 0.061400, val loss - 0.091279\n",
      "Epoch 130/176: loss - 0.063609, val loss - 0.104327\n",
      "Epoch 131/176: loss - 0.069190, val loss - 0.076230\n",
      "Epoch 132/176: loss - 0.060521, val loss - 0.113744\n",
      "Epoch 133/176: loss - 0.068379, val loss - 0.082633\n",
      "Epoch 134/176: loss - 0.061100, val loss - 0.093806\n",
      "Epoch 135/176: loss - 0.066881, val loss - 0.084979\n",
      "Epoch 136/176: loss - 0.063328, val loss - 0.118298\n",
      "Epoch 137/176: loss - 0.065414, val loss - 0.087137\n",
      "Epoch 138/176: loss - 0.065684, val loss - 0.082098\n",
      "Epoch 139/176: loss - 0.060960, val loss - 0.092686\n",
      "Epoch 140/176: loss - 0.079399, val loss - 0.107732\n",
      "Epoch 141/176: loss - 0.073659, val loss - 0.088008\n",
      "Epoch 142/176: loss - 0.067037, val loss - 0.118277\n",
      "Epoch 143/176: loss - 0.067888, val loss - 0.086706\n",
      "Epoch 144/176: loss - 0.063375, val loss - 0.086182\n",
      "Epoch 145/176: loss - 0.057999, val loss - 0.105408\n",
      "Epoch 146/176: loss - 0.081430, val loss - 0.083937\n",
      "Epoch 147/176: loss - 0.066519, val loss - 0.083935\n",
      "Epoch 148/176: loss - 0.063173, val loss - 0.087106\n",
      "Epoch 149/176: loss - 0.064216, val loss - 0.085674\n",
      "Epoch 150/176: loss - 0.066062, val loss - 0.102172\n",
      "Epoch 151/176: loss - 0.064704, val loss - 0.097344\n",
      "Epoch 152/176: loss - 0.066398, val loss - 0.106147\n",
      "Epoch 153/176: loss - 0.066095, val loss - 0.095913\n",
      "Epoch 154/176: loss - 0.062626, val loss - 0.102550\n",
      "Epoch 155/176: loss - 0.066068, val loss - 0.089659\n",
      "Epoch 156/176: loss - 0.065332, val loss - 0.096422\n",
      "Epoch 157/176: loss - 0.064469, val loss - 0.083101\n",
      "Epoch 158/176: loss - 0.059415, val loss - 0.095589\n",
      "Epoch 159/176: loss - 0.061086, val loss - 0.093886\n",
      "Epoch 160/176: loss - 0.071321, val loss - 0.089749\n",
      "Epoch 161/176: loss - 0.062280, val loss - 0.085816\n",
      "Epoch 162/176: loss - 0.063011, val loss - 0.084440\n",
      "Epoch 163/176: loss - 0.063459, val loss - 0.108791\n",
      "Epoch 164/176: loss - 0.065473, val loss - 0.089688\n",
      "Epoch 165/176: loss - 0.064519, val loss - 0.089121\n",
      "Epoch 166/176: loss - 0.063140, val loss - 0.107727\n",
      "Epoch 167/176: loss - 0.067409, val loss - 0.095648\n",
      "Epoch 168/176: loss - 0.067510, val loss - 0.084633\n",
      "Epoch 169/176: loss - 0.064375, val loss - 0.100358\n",
      "Epoch 170/176: loss - 0.069320, val loss - 0.092374\n",
      "Epoch 171/176: loss - 0.064835, val loss - 0.097388\n",
      "Epoch 172/176: loss - 0.069114, val loss - 0.121603\n",
      "Epoch 173/176: loss - 0.073774, val loss - 0.096329\n",
      "Epoch 174/176: loss - 0.066832, val loss - 0.092327\n",
      "Epoch 175/176: loss - 0.067660, val loss - 0.106225\n",
      "Epoch 176/176: loss - 0.065601, val loss - 0.085842\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.171224, val loss - 0.162328\n",
      "Epoch 2/24: loss - 0.120548, val loss - 0.104313\n",
      "Epoch 3/24: loss - 0.137456, val loss - 0.128563\n",
      "Epoch 4/24: loss - 0.121286, val loss - 0.119459\n",
      "Epoch 5/24: loss - 0.110479, val loss - 0.170554\n",
      "Epoch 6/24: loss - 0.116288, val loss - 0.092240\n",
      "Epoch 7/24: loss - 0.100824, val loss - 0.091883\n",
      "Epoch 8/24: loss - 0.094084, val loss - 0.086210\n",
      "Epoch 9/24: loss - 0.086760, val loss - 0.092624\n",
      "Epoch 10/24: loss - 0.094248, val loss - 0.090623\n",
      "Epoch 11/24: loss - 0.080585, val loss - 0.086520\n",
      "Epoch 12/24: loss - 0.091210, val loss - 0.082708\n",
      "Epoch 13/24: loss - 0.083007, val loss - 0.087653\n",
      "Epoch 14/24: loss - 0.089715, val loss - 0.083837\n",
      "Epoch 15/24: loss - 0.087941, val loss - 0.083901\n",
      "Epoch 16/24: loss - 0.080038, val loss - 0.081476\n",
      "Epoch 17/24: loss - 0.088215, val loss - 0.088524\n",
      "Epoch 18/24: loss - 0.086365, val loss - 0.077759\n",
      "Epoch 19/24: loss - 0.080590, val loss - 0.079891\n",
      "Epoch 20/24: loss - 0.077959, val loss - 0.081837\n",
      "Epoch 21/24: loss - 0.075970, val loss - 0.073714\n",
      "Epoch 22/24: loss - 0.077681, val loss - 0.076566\n",
      "Epoch 23/24: loss - 0.078493, val loss - 0.078665\n",
      "Epoch 24/24: loss - 0.071046, val loss - 0.081370\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.151101, val loss - 0.118743\n",
      "Epoch 2/66: loss - 0.130717, val loss - 0.115397\n",
      "Epoch 3/66: loss - 0.121945, val loss - 0.108737\n",
      "Epoch 4/66: loss - 0.122638, val loss - 0.101099\n",
      "Epoch 5/66: loss - 0.117688, val loss - 0.098188\n",
      "Epoch 6/66: loss - 0.113911, val loss - 0.118729\n",
      "Epoch 7/66: loss - 0.114327, val loss - 0.107617\n",
      "Epoch 8/66: loss - 0.106868, val loss - 0.091760\n",
      "Epoch 9/66: loss - 0.100625, val loss - 0.095586\n",
      "Epoch 10/66: loss - 0.103514, val loss - 0.088779\n",
      "Epoch 11/66: loss - 0.108604, val loss - 0.087044\n",
      "Epoch 12/66: loss - 0.095670, val loss - 0.087131\n",
      "Epoch 13/66: loss - 0.103480, val loss - 0.088510\n",
      "Epoch 14/66: loss - 0.104416, val loss - 0.087167\n",
      "Epoch 15/66: loss - 0.097515, val loss - 0.082850\n",
      "Epoch 16/66: loss - 0.095849, val loss - 0.095154\n",
      "Epoch 17/66: loss - 0.103909, val loss - 0.085306\n",
      "Epoch 18/66: loss - 0.087421, val loss - 0.087402\n",
      "Epoch 19/66: loss - 0.099659, val loss - 0.089659\n",
      "Epoch 20/66: loss - 0.090356, val loss - 0.103603\n",
      "Epoch 21/66: loss - 0.099573, val loss - 0.088251\n",
      "Epoch 22/66: loss - 0.090738, val loss - 0.078834\n",
      "Epoch 23/66: loss - 0.088483, val loss - 0.079251\n",
      "Epoch 24/66: loss - 0.092177, val loss - 0.085429\n",
      "Epoch 25/66: loss - 0.087309, val loss - 0.095443\n",
      "Epoch 26/66: loss - 0.086310, val loss - 0.082472\n",
      "Epoch 27/66: loss - 0.084617, val loss - 0.089494\n",
      "Epoch 28/66: loss - 0.086723, val loss - 0.078134\n",
      "Epoch 29/66: loss - 0.080232, val loss - 0.099900\n",
      "Epoch 30/66: loss - 0.085520, val loss - 0.074672\n",
      "Epoch 31/66: loss - 0.079159, val loss - 0.077731\n",
      "Epoch 32/66: loss - 0.079512, val loss - 0.075963\n",
      "Epoch 33/66: loss - 0.077099, val loss - 0.081530\n",
      "Epoch 34/66: loss - 0.074324, val loss - 0.081539\n",
      "Epoch 35/66: loss - 0.077503, val loss - 0.080723\n",
      "Epoch 36/66: loss - 0.079864, val loss - 0.081926\n",
      "Epoch 37/66: loss - 0.080745, val loss - 0.083887\n",
      "Epoch 38/66: loss - 0.073989, val loss - 0.084052\n",
      "Epoch 39/66: loss - 0.075388, val loss - 0.085327\n",
      "Epoch 40/66: loss - 0.079285, val loss - 0.095502\n",
      "Epoch 41/66: loss - 0.082190, val loss - 0.078893\n",
      "Epoch 42/66: loss - 0.078611, val loss - 0.087949\n",
      "Epoch 43/66: loss - 0.080319, val loss - 0.076939\n",
      "Epoch 44/66: loss - 0.073848, val loss - 0.073855\n",
      "Epoch 45/66: loss - 0.069952, val loss - 0.087117\n",
      "Epoch 46/66: loss - 0.075710, val loss - 0.092535\n",
      "Epoch 47/66: loss - 0.077035, val loss - 0.100256\n",
      "Epoch 48/66: loss - 0.074631, val loss - 0.080193\n",
      "Epoch 49/66: loss - 0.075340, val loss - 0.093989\n",
      "Epoch 50/66: loss - 0.071666, val loss - 0.095946\n",
      "Epoch 51/66: loss - 0.071168, val loss - 0.084652\n",
      "Epoch 52/66: loss - 0.073135, val loss - 0.079540\n",
      "Epoch 53/66: loss - 0.074102, val loss - 0.084068\n",
      "Epoch 54/66: loss - 0.074470, val loss - 0.095599\n",
      "Epoch 55/66: loss - 0.068841, val loss - 0.083685\n",
      "Epoch 56/66: loss - 0.071654, val loss - 0.078686\n",
      "Epoch 57/66: loss - 0.075836, val loss - 0.089575\n",
      "Epoch 58/66: loss - 0.068551, val loss - 0.083092\n",
      "Epoch 59/66: loss - 0.071022, val loss - 0.097355\n",
      "Epoch 60/66: loss - 0.072663, val loss - 0.084990\n",
      "Epoch 61/66: loss - 0.066642, val loss - 0.092177\n",
      "Epoch 62/66: loss - 0.068611, val loss - 0.080894\n",
      "Epoch 63/66: loss - 0.071363, val loss - 0.080350\n",
      "Epoch 64/66: loss - 0.063882, val loss - 0.095697\n",
      "Epoch 65/66: loss - 0.073423, val loss - 0.079063\n",
      "Epoch 66/66: loss - 0.069866, val loss - 0.086359\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.177663, val loss - 0.121045\n",
      "Epoch 2/24: loss - 0.134008, val loss - 0.102166\n",
      "Epoch 3/24: loss - 0.126350, val loss - 0.098094\n",
      "Epoch 4/24: loss - 0.118552, val loss - 0.112121\n",
      "Epoch 5/24: loss - 0.101847, val loss - 0.102871\n",
      "Epoch 6/24: loss - 0.109230, val loss - 0.103539\n",
      "Epoch 7/24: loss - 0.111813, val loss - 0.106005\n",
      "Epoch 8/24: loss - 0.112481, val loss - 0.086786\n",
      "Epoch 9/24: loss - 0.098944, val loss - 0.088266\n",
      "Epoch 10/24: loss - 0.087535, val loss - 0.106017\n",
      "Epoch 11/24: loss - 0.101618, val loss - 0.091518\n",
      "Epoch 12/24: loss - 0.101055, val loss - 0.084181\n",
      "Epoch 13/24: loss - 0.093485, val loss - 0.082866\n",
      "Epoch 14/24: loss - 0.090239, val loss - 0.097989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24: loss - 0.098567, val loss - 0.157116\n",
      "Epoch 16/24: loss - 0.104644, val loss - 0.084985\n",
      "Epoch 17/24: loss - 0.089680, val loss - 0.087258\n",
      "Epoch 18/24: loss - 0.091709, val loss - 0.082939\n",
      "Epoch 19/24: loss - 0.090968, val loss - 0.089642\n",
      "Epoch 20/24: loss - 0.089835, val loss - 0.092419\n",
      "Epoch 21/24: loss - 0.092475, val loss - 0.085040\n",
      "Epoch 22/24: loss - 0.094002, val loss - 0.084554\n",
      "Epoch 23/24: loss - 0.088387, val loss - 0.098826\n",
      "Epoch 24/24: loss - 0.099798, val loss - 0.083951\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1275 - val_loss: 0.0852\n",
      "Epoch 2/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0711\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0665\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0744\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.0861\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0624\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0587\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0628\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0544\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0549\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0552\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0500\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0503\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.0568\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0496\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0548\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0465\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0545\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0689\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0562\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0483\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0489\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0497\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0499\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0481\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0547\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0508\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0493\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2152 - val_loss: 0.1379\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1194 - val_loss: 0.1050\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1075 - val_loss: 0.0966\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0987 - val_loss: 0.0883\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0929 - val_loss: 0.0858\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0730\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0782\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.1027\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0966 - val_loss: 0.0727\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0707\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0649\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0658\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0635\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0806\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0624\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0615\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0649\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.0653\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0677\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0595\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0627\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0606\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0741\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0643\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0612\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0728\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0642\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0566\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0672\n",
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0563\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0587\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0637\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0600\n",
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0576\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0597\n",
      "Epoch 1/29\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2550 - val_loss: 0.1407\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.1061\n",
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1051 - val_loss: 0.0748\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.0896\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.0703\n",
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0752\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0702\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0822\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0701\n",
      "Epoch 10/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0636\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0695\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0621\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0665\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0677\n",
      "Epoch 15/29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0768\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0762\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0648\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0670\n",
      "Epoch 19/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0649\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0666\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0670\n",
      "Epoch 22/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0666\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0693\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0715\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0655\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0694\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0738\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0669\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0765\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2141 - val_loss: 0.1114\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 0.0928\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0931 - val_loss: 0.0768\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.0711\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0713\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0713 - val_loss: 0.0769\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0658\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0659\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0750\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0642\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0730\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0748\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0637\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0699\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0685\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0684\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0734\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0932\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0734\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0777\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0704\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0656\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0651\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0742\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0716\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0690\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0712\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0799\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0758\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0823\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0990\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0800\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0753\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0743\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4212 - val_loss: 0.3088\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1932 - val_loss: 0.1571\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1440 - val_loss: 0.1337\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1413 - val_loss: 0.1337\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1373 - val_loss: 0.1359\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1351 - val_loss: 0.1308\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1299\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1304 - val_loss: 0.1259\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1280 - val_loss: 0.1252\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.1221\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1235 - val_loss: 0.1206\n",
      "Epoch 12/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.1186\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 0.1154\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.1116\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.1107\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1115 - val_loss: 0.1097\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1085 - val_loss: 0.1067\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.1035\n",
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.1011\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1004 - val_loss: 0.0994\n",
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.0960\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.0961\n",
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.0952\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0926 - val_loss: 0.0945\n",
      "Epoch 25/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0909 - val_loss: 0.0920\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.0918\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.0901\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0878 - val_loss: 0.0901\n",
      "Epoch 29/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0891\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.0901\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.0881\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0847 - val_loss: 0.0880\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0842 - val_loss: 0.0885\n",
      "Epoch 34/108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0866\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0828 - val_loss: 0.0918\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0859\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.0900\n",
      "Epoch 38/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0853\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0877\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0863\n",
      "Epoch 41/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0858\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.0850\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0797 - val_loss: 0.0843\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.0844\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0839\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.0846\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0840\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0844\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0834\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0773 - val_loss: 0.0833\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0832\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0773 - val_loss: 0.0831\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0837\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0833\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0826\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0826\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0847\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.0828\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0820\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0861\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0832\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0829\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0816\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.0815\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0852\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0812\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.0812\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.0835\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0813\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0827\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0826\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0839\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0832\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0811\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.0822\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0807\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0807\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0835\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0807\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0807\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0805\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0803\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0814\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0811\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0827\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0810\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0820\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0805\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0809\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0820\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0826\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0818\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0814\n",
      "Epoch 94/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0805\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0803\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0864\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0804\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0804\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0806\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0805\n",
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0803\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0869\n",
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0804\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0805\n",
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0657 - val_loss: 0.0814\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0837\n",
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0810\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0823\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1417 - val_loss: 0.0965\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.0870\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0792\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0693\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0630\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0596\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0687\n",
      "Epoch 8/34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0715\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0609\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0571\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0592\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0572\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0597\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0602\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0580\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0579\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0621\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0559\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0584\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0562\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0608\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0631\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0595\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0557\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0584\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0594\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0556\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0585\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0564\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0591\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0571\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0581\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0547\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0601\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2098 - val_loss: 0.1246\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 0.1229\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1129 - val_loss: 0.1080\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.1073\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1060 - val_loss: 0.1072\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1000 - val_loss: 0.0941\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0905 - val_loss: 0.0830\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.0820\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0832\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.0759\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0773\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0739\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0735\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.0754\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0734 - val_loss: 0.0722\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0729\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0822\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0716\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0749\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0730\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0735\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0778\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0646 - val_loss: 0.0774\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0733\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0751\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0812\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0722\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0809\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0740\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0845\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0782\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0828\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0799\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0740\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0795\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0730\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2501 - val_loss: 0.1940\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1406\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1454 - val_loss: 0.1316\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1348 - val_loss: 0.1292\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1256 - val_loss: 0.1162\n",
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.1106\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1092 - val_loss: 0.1036\n",
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.0988\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.0959\n",
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0969 - val_loss: 0.0952\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.0909\n",
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0912\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.0894\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0905 - val_loss: 0.0879\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.0878\n",
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0852\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0861\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.0839\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.0861\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0821\n",
      "Epoch 21/71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0822\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0814\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0810\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0803\n",
      "Epoch 25/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0796\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.0788\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0788\n",
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0781\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0780\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0774\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0779\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0769\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0767\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0814\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0762\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0772\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0777\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.0758\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0759\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0776\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0756\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0753\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0751\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0752\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0750\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0758\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0764\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0779\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0747\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0767\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0749\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0770\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.0745\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0747\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0743\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0743\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0746\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0744\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0770\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0745\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0746\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0747\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0751\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0748\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0757\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0741\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0742\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0743\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.0740\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0751\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0755\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.9841 - val_loss: 0.7423\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.3792\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2370 - val_loss: 0.1874\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1396\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1369 - val_loss: 0.1311\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1281 - val_loss: 0.1281\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1157\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1061 - val_loss: 0.1020\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0929\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0884\n",
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0855\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0852\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0829\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0832\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0814\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0808\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0799\n",
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0789\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0786\n",
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0774\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0769\n",
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0764\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0765\n",
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0759\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0762\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0756\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0755\n",
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0755\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0751\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0766\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0759\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0765\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0757\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0759\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0757\n",
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0759\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0761\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0762\n",
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0762\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0764\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0773\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0763\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0777\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0763\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0763\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0767\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0823\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0766\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0766\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0784\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0773\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0781\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0761\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0769\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0764\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0765\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0769\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0771\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0770\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0763\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0761\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0762\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2079 - val_loss: 0.1810\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1398 - val_loss: 0.1195\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.0997\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.0876\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.0848\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.0828\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0809\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0807\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0787\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0837\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0817\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0819\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0800\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0800\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0776\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0786\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.1030\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0805\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0788\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0797\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0877\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0769\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0802\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0800\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0802\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0862\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2908 - val_loss: 0.1482\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.1079\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0823\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0796\n",
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0771\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0744\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0714\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0729\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0701\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0679\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0677\n",
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0668\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0651\n",
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0644\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0642\n",
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0670\n",
      "Epoch 17/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0640\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0651\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0623\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0625\n",
      "Epoch 21/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0625\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0629\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0625\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0631\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0617\n",
      "Epoch 26/138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0626\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0612\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0611\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0616\n",
      "Epoch 30/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0615\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0613\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0687\n",
      "Epoch 33/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0623\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0618\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0612\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0611\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0620\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0615\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0620\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0612\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0625\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0621\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0704\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0616\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0644\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0617\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0616\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0616\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0614\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0628\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0636\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0627\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0668\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0622\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0625\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0618\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0632\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0624\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0626\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0618\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0645\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0619\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0622\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0623\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0624\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0626\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0622\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0616\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0620\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0621\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0618\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0628\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0642\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0623\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0623\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0623\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0617\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0622\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0619\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0618\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0631\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0622\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0622\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0630\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0629\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0628\n",
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0623\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0629\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0652\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0620\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0634\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0630\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0626\n",
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0623\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0632\n",
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0629\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0647\n",
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0624\n",
      "Epoch 99/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0633\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0628\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0621\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0643\n",
      "Epoch 103/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0620\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0634\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0622\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0644\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0655\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0626\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0630\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0639\n",
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0652\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0631\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0632\n",
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0625\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0625\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0627\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0645\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0632\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0626\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0628\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0635\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0642\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0638\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0640\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0683\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0676\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0637\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0654\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0635\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0642\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0637\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0650\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0664\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0632\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0638\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0637\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0641\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2087 - val_loss: 0.1408\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1391\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1372 - val_loss: 0.1298\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1288 - val_loss: 0.1228\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1231 - val_loss: 0.1179\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.1158\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.1091\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.1068\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1006\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0991\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0959\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0953\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0929\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0917\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0903\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0904\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0876\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0879\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0846\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0839\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0859\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0836\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0827\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0833\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0819\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0815\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0829\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0808\n",
      "Epoch 30/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0803\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0800\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0800\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0803\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0799\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0795\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0795\n",
      "Epoch 37/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0798\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0805\n",
      "Epoch 39/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0807\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0799\n",
      "Epoch 41/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0796\n",
      "Epoch 42/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0796\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0820\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0797\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0864\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0796\n",
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0793\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0796\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0793\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0828\n",
      "Epoch 51/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0795\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0794\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0795\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0797\n",
      "Epoch 55/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0810\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0791\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0795\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0803\n",
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0794\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0800\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0794\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0816\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0808\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0801\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0796\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0794\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0797\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0794\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0798\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0796\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0800\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0797\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0798\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0852\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0796\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0797\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0798\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0838\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0810\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0804\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0793\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0796\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0825\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0802\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0798\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0803\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0800\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0813\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0809\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0808\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0801\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0816\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0806\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0810\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0804\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0842\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0813\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0836\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0812\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0808\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0808\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0808\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0809\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0820\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0810\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0837\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0824\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0813\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0826\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0814\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0847\n",
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0818\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0814\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0852\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0815\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0817\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0820\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0820\n",
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0819\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0824\n",
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0821\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0823\n",
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0833\n",
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0825\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0827\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0830\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0857\n",
      "Epoch 128/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0824\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0834\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0825\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0837\n",
      "Epoch 132/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0828\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0830\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0842\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0848\n",
      "Epoch 136/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0867\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0825\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0825\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0826\n",
      "Epoch 140/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0865\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0831\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0831\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0828\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0840\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0874\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0828\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0839\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0830\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0831\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2451 - val_loss: 0.1505\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1540 - val_loss: 0.1337\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1460 - val_loss: 0.1472\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1311\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1289 - val_loss: 0.1322\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1217\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1261\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1217 - val_loss: 0.1251\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1184 - val_loss: 0.1275\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.1188\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.1198\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1126 - val_loss: 0.1149\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1121 - val_loss: 0.1207\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.1099\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1128\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 0.1011\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.0975\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0911 - val_loss: 0.0916\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 0.0933\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0859\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.0854\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0824\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0950\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0818\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0830\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0789\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0848\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0872\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0809\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0780\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0786\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0822\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0846\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0870\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0847\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0791\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0791\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0777\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0816\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0808\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0791\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0775\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0765\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0771\n",
      "Epoch 45/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0773\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0854\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0786\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0794\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0771\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0771\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0807\n",
      "Epoch 52/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0781\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0776\n",
      "Epoch 54/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0781\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0761\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0784\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2000 - val_loss: 0.1734\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1431 - val_loss: 0.1428\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1230\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1044 - val_loss: 0.1095\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.1077\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.0994\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0963\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.0940\n",
      "Epoch 9/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0945\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0937\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0899\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0925\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.1020\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0921\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0962\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0851\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0899\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0841\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0841\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0851\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0840\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0840\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0868\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0892\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0847\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0860\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0829\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0846\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0812\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0821\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0817\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0814\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0807\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0806\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0810\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0807\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0807\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0808\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0802\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0811\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0816\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0799\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0807\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0802\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0798\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0876\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0826\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0832\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0791\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0803\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0792\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0811\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0799\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0797\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0803\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0799\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0816\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0813\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0790\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0795\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2261 - val_loss: 0.1914\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1753 - val_loss: 0.1659\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1554 - val_loss: 0.1482\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1443 - val_loss: 0.1416\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1373 - val_loss: 0.1359\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1333 - val_loss: 0.1322\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1311 - val_loss: 0.1321\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1275\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1257 - val_loss: 0.1268\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1244 - val_loss: 0.1250\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1231 - val_loss: 0.1266\n",
      "Epoch 12/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.1212\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1189 - val_loss: 0.1200\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.1175\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1216\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1117\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.1170\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1051 - val_loss: 0.1074\n",
      "Epoch 19/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.1008\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.0996\n",
      "Epoch 21/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0951\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0897\n",
      "Epoch 23/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0889\n",
      "Epoch 24/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0952\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0886\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0853\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0846\n",
      "Epoch 28/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0840\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0841\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0833\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0829\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0856\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0853\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0914\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0815\n",
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0846\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0807\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0809\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0814\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0809\n",
      "Epoch 1/47\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.4301 - val_loss: 0.1847\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2046 - val_loss: 0.1475\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1479 - val_loss: 0.1288\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1239 - val_loss: 0.0998\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1090 - val_loss: 0.0903\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1035 - val_loss: 0.0832\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0959 - val_loss: 0.0804\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0901 - val_loss: 0.0784\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0904 - val_loss: 0.0771\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0888 - val_loss: 0.0789\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0867 - val_loss: 0.0747\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0825 - val_loss: 0.0759\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0835 - val_loss: 0.0730\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0795 - val_loss: 0.0725\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0841 - val_loss: 0.0735\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0849 - val_loss: 0.0875\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0799 - val_loss: 0.0716\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0783 - val_loss: 0.0687\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0770 - val_loss: 0.0684\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0811 - val_loss: 0.0692\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0735 - val_loss: 0.0670\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0727 - val_loss: 0.0666\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0717 - val_loss: 0.0681\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0711 - val_loss: 0.0664\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0720 - val_loss: 0.0652\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0722 - val_loss: 0.0679\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0724 - val_loss: 0.0668\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0712 - val_loss: 0.0666\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0705 - val_loss: 0.0676\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0713 - val_loss: 0.0636\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0700 - val_loss: 0.0632\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0683 - val_loss: 0.0630\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0685 - val_loss: 0.0631\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0685 - val_loss: 0.0655\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0689 - val_loss: 0.0640\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0685 - val_loss: 0.0654\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0665 - val_loss: 0.0625\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0678 - val_loss: 0.0648\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0662 - val_loss: 0.0634\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0658 - val_loss: 0.0629\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0652 - val_loss: 0.0630\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0653 - val_loss: 0.0622\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0647 - val_loss: 0.0663\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0658 - val_loss: 0.0625\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0633 - val_loss: 0.0646\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0657 - val_loss: 0.0626\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0640 - val_loss: 0.0628\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.4877 - val_loss: 0.1357\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1785 - val_loss: 0.1226\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1336 - val_loss: 0.1223\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1241 - val_loss: 0.1026\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1151 - val_loss: 0.0979\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1079 - val_loss: 0.0897\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1012 - val_loss: 0.0860\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0941 - val_loss: 0.0823\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0948 - val_loss: 0.0807\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0917 - val_loss: 0.0813\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0886 - val_loss: 0.0797\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0870 - val_loss: 0.0833\n",
      "Epoch 13/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0887 - val_loss: 0.0800\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0865 - val_loss: 0.0804\n",
      "Epoch 15/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0899 - val_loss: 0.0809\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0928 - val_loss: 0.0952\n",
      "Epoch 17/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0860 - val_loss: 0.0804\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0854 - val_loss: 0.0797\n",
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0864 - val_loss: 0.0857\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0913 - val_loss: 0.0812\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0838 - val_loss: 0.0811\n",
      "Epoch 22/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0862 - val_loss: 0.0802\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0844 - val_loss: 0.0826\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0831 - val_loss: 0.0809\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0845 - val_loss: 0.0813\n",
      "Epoch 26/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0841 - val_loss: 0.0851\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0838 - val_loss: 0.0875\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0880 - val_loss: 0.0804\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0840 - val_loss: 0.0837\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0824 - val_loss: 0.0806\n",
      "Epoch 31/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0805 - val_loss: 0.0804\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0821 - val_loss: 0.0807\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0830 - val_loss: 0.0807\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0828 - val_loss: 0.0806\n",
      "Epoch 35/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0815 - val_loss: 0.0834\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0789 - val_loss: 0.0816\n",
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0806 - val_loss: 0.0813\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0787 - val_loss: 0.0819\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0787 - val_loss: 0.0814\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0786 - val_loss: 0.0857\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0780 - val_loss: 0.0838\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0781 - val_loss: 0.0814\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0796 - val_loss: 0.0854\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0802 - val_loss: 0.0870\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0761 - val_loss: 0.0816\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2522 - val_loss: 0.1561\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1593 - val_loss: 0.1464\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1245 - val_loss: 0.1093\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1074 - val_loss: 0.0990\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1024 - val_loss: 0.0946\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0970 - val_loss: 0.0913\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0937 - val_loss: 0.0940\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0899 - val_loss: 0.0891\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0910 - val_loss: 0.0918\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0894 - val_loss: 0.0882\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0859 - val_loss: 0.0900\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0851 - val_loss: 0.0879\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0853 - val_loss: 0.0874\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0824 - val_loss: 0.0884\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0841 - val_loss: 0.0897\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0906 - val_loss: 0.0896\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0849 - val_loss: 0.0892\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0846 - val_loss: 0.0972\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0819 - val_loss: 0.0887\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0809 - val_loss: 0.0893\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0904 - val_loss: 0.0900\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0803 - val_loss: 0.0894\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1778 - val_loss: 0.1837\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1361 - val_loss: 0.1441\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1137 - val_loss: 0.1286\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0995 - val_loss: 0.1077\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0965 - val_loss: 0.1011\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0934 - val_loss: 0.0975\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0910 - val_loss: 0.0980\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0898 - val_loss: 0.0957\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0904 - val_loss: 0.0960\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0858 - val_loss: 0.0959\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0854 - val_loss: 0.0944\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0865 - val_loss: 0.0935\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0862 - val_loss: 0.0947\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0853 - val_loss: 0.0977\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0884 - val_loss: 0.1003\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0861 - val_loss: 0.1019\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0825 - val_loss: 0.0960\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0834 - val_loss: 0.1040\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0826 - val_loss: 0.0950\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0829 - val_loss: 0.0945\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0838 - val_loss: 0.0954\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0882 - val_loss: 0.0968\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0827 - val_loss: 0.0950\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.0080 - val_loss: 0.7057\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2993 - val_loss: 0.3267\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2218 - val_loss: 0.2798\n",
      "Epoch 4/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2037 - val_loss: 0.2712\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1833 - val_loss: 0.2541\n",
      "Epoch 6/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1678 - val_loss: 0.2285\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1543 - val_loss: 0.2091\n",
      "Epoch 8/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1431 - val_loss: 0.1876\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1313 - val_loss: 0.1745\n",
      "Epoch 10/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1200 - val_loss: 0.1570\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1111 - val_loss: 0.1490\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1049 - val_loss: 0.1274\n",
      "Epoch 13/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0984 - val_loss: 0.1240\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0944 - val_loss: 0.1150\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0918 - val_loss: 0.1130\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0894 - val_loss: 0.1071\n",
      "Epoch 17/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0904 - val_loss: 0.1147\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0886 - val_loss: 0.1057\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0882 - val_loss: 0.1072\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0889 - val_loss: 0.1044\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0852 - val_loss: 0.1090\n",
      "Epoch 22/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0892 - val_loss: 0.1036\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0851 - val_loss: 0.1125\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0839 - val_loss: 0.1052\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0874 - val_loss: 0.1195\n",
      "Epoch 26/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0857 - val_loss: 0.1033\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0862 - val_loss: 0.1054\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0849 - val_loss: 0.1025\n",
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0855 - val_loss: 0.1044\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0855 - val_loss: 0.1083\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0849 - val_loss: 0.1096\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 0.711711, val loss - 0.135222\n",
      "Epoch 2/15: loss - 0.193286, val loss - 0.121665\n",
      "Epoch 3/15: loss - 0.111431, val loss - 0.077558\n",
      "Epoch 4/15: loss - 0.085402, val loss - 0.076759\n",
      "Epoch 5/15: loss - 0.081891, val loss - 0.076460\n",
      "Epoch 6/15: loss - 0.082262, val loss - 0.077988\n",
      "Epoch 7/15: loss - 0.079041, val loss - 0.072594\n",
      "Epoch 8/15: loss - 0.078522, val loss - 0.073116\n",
      "Epoch 9/15: loss - 0.077534, val loss - 0.072567\n",
      "Epoch 10/15: loss - 0.077915, val loss - 0.071956\n",
      "Epoch 11/15: loss - 0.076525, val loss - 0.070991\n",
      "Epoch 12/15: loss - 0.076068, val loss - 0.070301\n",
      "Epoch 13/15: loss - 0.073120, val loss - 0.067432\n",
      "Epoch 14/15: loss - 0.071127, val loss - 0.066410\n",
      "Epoch 15/15: loss - 0.070299, val loss - 0.064051\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.229859, val loss - 0.124822\n",
      "Epoch 2/176: loss - 0.272554, val loss - 0.271026\n",
      "Epoch 3/176: loss - 0.187600, val loss - 0.189624\n",
      "Epoch 4/176: loss - 0.143651, val loss - 0.109185\n",
      "Epoch 5/176: loss - 0.113203, val loss - 0.109841\n",
      "Epoch 6/176: loss - 0.097942, val loss - 0.093389\n",
      "Epoch 7/176: loss - 0.095601, val loss - 0.109366\n",
      "Epoch 8/176: loss - 0.103072, val loss - 0.126532\n",
      "Epoch 9/176: loss - 0.097931, val loss - 0.099922\n",
      "Epoch 10/176: loss - 0.088418, val loss - 0.094900\n",
      "Epoch 11/176: loss - 0.086584, val loss - 0.089794\n",
      "Epoch 12/176: loss - 0.087889, val loss - 0.089358\n",
      "Epoch 13/176: loss - 0.080354, val loss - 0.089643\n",
      "Epoch 14/176: loss - 0.083813, val loss - 0.086864\n",
      "Epoch 15/176: loss - 0.080062, val loss - 0.091524\n",
      "Epoch 16/176: loss - 0.080101, val loss - 0.092702\n",
      "Epoch 17/176: loss - 0.072142, val loss - 0.088802\n",
      "Epoch 18/176: loss - 0.077025, val loss - 0.104000\n",
      "Epoch 19/176: loss - 0.088202, val loss - 0.108967\n",
      "Epoch 20/176: loss - 0.101195, val loss - 0.165737\n",
      "Epoch 21/176: loss - 0.125887, val loss - 0.107963\n",
      "Epoch 22/176: loss - 0.092216, val loss - 0.092019\n",
      "Epoch 23/176: loss - 0.074763, val loss - 0.091375\n",
      "Epoch 24/176: loss - 0.071527, val loss - 0.087224\n",
      "Epoch 25/176: loss - 0.072407, val loss - 0.090122\n",
      "Epoch 26/176: loss - 0.088375, val loss - 0.141144\n",
      "Epoch 27/176: loss - 0.103659, val loss - 0.128935\n",
      "Epoch 28/176: loss - 0.091407, val loss - 0.090449\n",
      "Epoch 29/176: loss - 0.080709, val loss - 0.087716\n",
      "Epoch 30/176: loss - 0.091844, val loss - 0.127666\n",
      "Epoch 31/176: loss - 0.096584, val loss - 0.093339\n",
      "Epoch 32/176: loss - 0.073551, val loss - 0.094523\n",
      "Epoch 33/176: loss - 0.072696, val loss - 0.104017\n",
      "Epoch 34/176: loss - 0.073596, val loss - 0.101856\n",
      "Epoch 35/176: loss - 0.073007, val loss - 0.096348\n",
      "Epoch 36/176: loss - 0.081959, val loss - 0.107032\n",
      "Epoch 37/176: loss - 0.082992, val loss - 0.120037\n",
      "Epoch 38/176: loss - 0.090986, val loss - 0.089108\n",
      "Epoch 39/176: loss - 0.087948, val loss - 0.121886\n",
      "Epoch 40/176: loss - 0.098149, val loss - 0.111658\n",
      "Epoch 41/176: loss - 0.080711, val loss - 0.088706\n",
      "Epoch 42/176: loss - 0.064426, val loss - 0.088246\n",
      "Epoch 43/176: loss - 0.074116, val loss - 0.101177\n",
      "Epoch 44/176: loss - 0.077974, val loss - 0.088467\n",
      "Epoch 45/176: loss - 0.092301, val loss - 0.163667\n",
      "Epoch 46/176: loss - 0.114216, val loss - 0.106301\n",
      "Epoch 47/176: loss - 0.086411, val loss - 0.127766\n",
      "Epoch 48/176: loss - 0.097480, val loss - 0.117258\n",
      "Epoch 49/176: loss - 0.086092, val loss - 0.083335\n",
      "Epoch 50/176: loss - 0.071682, val loss - 0.087730\n",
      "Epoch 51/176: loss - 0.085343, val loss - 0.113879\n",
      "Epoch 52/176: loss - 0.104212, val loss - 0.121130\n",
      "Epoch 53/176: loss - 0.085238, val loss - 0.095278\n",
      "Epoch 54/176: loss - 0.068347, val loss - 0.105184\n",
      "Epoch 55/176: loss - 0.067594, val loss - 0.087624\n",
      "Epoch 56/176: loss - 0.064446, val loss - 0.116592\n",
      "Epoch 57/176: loss - 0.080552, val loss - 0.090692\n",
      "Epoch 58/176: loss - 0.083604, val loss - 0.123689\n",
      "Epoch 59/176: loss - 0.092841, val loss - 0.145382\n",
      "Epoch 60/176: loss - 0.096217, val loss - 0.095693\n",
      "Epoch 61/176: loss - 0.067582, val loss - 0.080058\n",
      "Epoch 62/176: loss - 0.068098, val loss - 0.082440\n",
      "Epoch 63/176: loss - 0.076114, val loss - 0.102751\n",
      "Epoch 64/176: loss - 0.077056, val loss - 0.097636\n",
      "Epoch 65/176: loss - 0.077165, val loss - 0.100010\n",
      "Epoch 66/176: loss - 0.076314, val loss - 0.103575\n",
      "Epoch 67/176: loss - 0.082362, val loss - 0.094895\n",
      "Epoch 68/176: loss - 0.074261, val loss - 0.115916\n",
      "Epoch 69/176: loss - 0.078075, val loss - 0.104311\n",
      "Epoch 70/176: loss - 0.072134, val loss - 0.081759\n",
      "Epoch 71/176: loss - 0.064948, val loss - 0.094617\n",
      "Epoch 72/176: loss - 0.077906, val loss - 0.097437\n",
      "Epoch 73/176: loss - 0.080880, val loss - 0.108341\n",
      "Epoch 74/176: loss - 0.074740, val loss - 0.090877\n",
      "Epoch 75/176: loss - 0.077442, val loss - 0.086180\n",
      "Epoch 76/176: loss - 0.073509, val loss - 0.104824\n",
      "Epoch 77/176: loss - 0.086283, val loss - 0.129958\n",
      "Epoch 78/176: loss - 0.088783, val loss - 0.113355\n",
      "Epoch 79/176: loss - 0.080222, val loss - 0.091506\n",
      "Epoch 80/176: loss - 0.075017, val loss - 0.096892\n",
      "Epoch 81/176: loss - 0.073726, val loss - 0.104152\n",
      "Epoch 82/176: loss - 0.078969, val loss - 0.099641\n",
      "Epoch 83/176: loss - 0.073556, val loss - 0.091160\n",
      "Epoch 84/176: loss - 0.064529, val loss - 0.079775\n",
      "Epoch 85/176: loss - 0.065506, val loss - 0.096329\n",
      "Epoch 86/176: loss - 0.069324, val loss - 0.093413\n",
      "Epoch 87/176: loss - 0.066072, val loss - 0.105178\n",
      "Epoch 88/176: loss - 0.077373, val loss - 0.102881\n",
      "Epoch 89/176: loss - 0.080255, val loss - 0.110802\n",
      "Epoch 90/176: loss - 0.083095, val loss - 0.105440\n",
      "Epoch 91/176: loss - 0.080981, val loss - 0.106338\n",
      "Epoch 92/176: loss - 0.086412, val loss - 0.100109\n",
      "Epoch 93/176: loss - 0.087853, val loss - 0.123532\n",
      "Epoch 94/176: loss - 0.108071, val loss - 0.178061\n",
      "Epoch 95/176: loss - 0.114435, val loss - 0.087345\n",
      "Epoch 96/176: loss - 0.079761, val loss - 0.085507\n",
      "Epoch 97/176: loss - 0.082787, val loss - 0.105031\n",
      "Epoch 98/176: loss - 0.080544, val loss - 0.100227\n",
      "Epoch 99/176: loss - 0.070625, val loss - 0.086959\n",
      "Epoch 100/176: loss - 0.068254, val loss - 0.084327\n",
      "Epoch 101/176: loss - 0.073795, val loss - 0.093510\n",
      "Epoch 102/176: loss - 0.083518, val loss - 0.127651\n",
      "Epoch 103/176: loss - 0.090062, val loss - 0.098544\n",
      "Epoch 104/176: loss - 0.078423, val loss - 0.105587\n",
      "Epoch 105/176: loss - 0.078134, val loss - 0.099392\n",
      "Epoch 106/176: loss - 0.073057, val loss - 0.085425\n",
      "Epoch 107/176: loss - 0.063840, val loss - 0.078548\n",
      "Epoch 108/176: loss - 0.062305, val loss - 0.077212\n",
      "Epoch 109/176: loss - 0.065999, val loss - 0.075416\n",
      "Epoch 110/176: loss - 0.068230, val loss - 0.084270\n",
      "Epoch 111/176: loss - 0.066674, val loss - 0.082989\n",
      "Epoch 112/176: loss - 0.062919, val loss - 0.077727\n",
      "Epoch 113/176: loss - 0.061977, val loss - 0.079178\n",
      "Epoch 114/176: loss - 0.065242, val loss - 0.078276\n",
      "Epoch 115/176: loss - 0.069559, val loss - 0.088251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/176: loss - 0.076589, val loss - 0.116491\n",
      "Epoch 117/176: loss - 0.075318, val loss - 0.089802\n",
      "Epoch 118/176: loss - 0.065879, val loss - 0.076573\n",
      "Epoch 119/176: loss - 0.064307, val loss - 0.080063\n",
      "Epoch 120/176: loss - 0.062601, val loss - 0.079920\n",
      "Epoch 121/176: loss - 0.066129, val loss - 0.078123\n",
      "Epoch 122/176: loss - 0.066853, val loss - 0.079670\n",
      "Epoch 123/176: loss - 0.074618, val loss - 0.088090\n",
      "Epoch 124/176: loss - 0.080711, val loss - 0.105479\n",
      "Epoch 125/176: loss - 0.081023, val loss - 0.097739\n",
      "Epoch 126/176: loss - 0.073074, val loss - 0.086926\n",
      "Epoch 127/176: loss - 0.077534, val loss - 0.098227\n",
      "Epoch 128/176: loss - 0.081218, val loss - 0.107314\n",
      "Epoch 129/176: loss - 0.088607, val loss - 0.131532\n",
      "Epoch 130/176: loss - 0.086205, val loss - 0.112828\n",
      "Epoch 131/176: loss - 0.077443, val loss - 0.097405\n",
      "Epoch 132/176: loss - 0.072160, val loss - 0.084205\n",
      "Epoch 133/176: loss - 0.065898, val loss - 0.078240\n",
      "Epoch 134/176: loss - 0.066344, val loss - 0.082537\n",
      "Epoch 135/176: loss - 0.078477, val loss - 0.113159\n",
      "Epoch 136/176: loss - 0.095886, val loss - 0.125111\n",
      "Epoch 137/176: loss - 0.079729, val loss - 0.083850\n",
      "Epoch 138/176: loss - 0.062165, val loss - 0.076259\n",
      "Epoch 139/176: loss - 0.062841, val loss - 0.078740\n",
      "Epoch 140/176: loss - 0.062061, val loss - 0.079823\n",
      "Epoch 141/176: loss - 0.073557, val loss - 0.091864\n",
      "Epoch 142/176: loss - 0.078329, val loss - 0.101345\n",
      "Epoch 143/176: loss - 0.081782, val loss - 0.106626\n",
      "Epoch 144/176: loss - 0.085392, val loss - 0.113452\n",
      "Epoch 145/176: loss - 0.091780, val loss - 0.136725\n",
      "Epoch 146/176: loss - 0.100475, val loss - 0.113959\n",
      "Epoch 147/176: loss - 0.083323, val loss - 0.115070\n",
      "Epoch 148/176: loss - 0.073788, val loss - 0.100693\n",
      "Epoch 149/176: loss - 0.075375, val loss - 0.097678\n",
      "Epoch 150/176: loss - 0.070328, val loss - 0.092122\n",
      "Epoch 151/176: loss - 0.072879, val loss - 0.110630\n",
      "Epoch 152/176: loss - 0.072172, val loss - 0.088538\n",
      "Epoch 153/176: loss - 0.065285, val loss - 0.083576\n",
      "Epoch 154/176: loss - 0.070356, val loss - 0.096386\n",
      "Epoch 155/176: loss - 0.068998, val loss - 0.085329\n",
      "Epoch 156/176: loss - 0.064683, val loss - 0.079988\n",
      "Epoch 157/176: loss - 0.059297, val loss - 0.079172\n",
      "Epoch 158/176: loss - 0.065466, val loss - 0.079452\n",
      "Epoch 159/176: loss - 0.063889, val loss - 0.080786\n",
      "Epoch 160/176: loss - 0.067719, val loss - 0.082515\n",
      "Epoch 161/176: loss - 0.071721, val loss - 0.094856\n",
      "Epoch 162/176: loss - 0.074837, val loss - 0.105433\n",
      "Epoch 163/176: loss - 0.080528, val loss - 0.105885\n",
      "Epoch 164/176: loss - 0.077804, val loss - 0.100623\n",
      "Epoch 165/176: loss - 0.074104, val loss - 0.091523\n",
      "Epoch 166/176: loss - 0.073703, val loss - 0.106665\n",
      "Epoch 167/176: loss - 0.081571, val loss - 0.110891\n",
      "Epoch 168/176: loss - 0.084276, val loss - 0.122170\n",
      "Epoch 169/176: loss - 0.076468, val loss - 0.090408\n",
      "Epoch 170/176: loss - 0.061674, val loss - 0.082841\n",
      "Epoch 171/176: loss - 0.058003, val loss - 0.081800\n",
      "Epoch 172/176: loss - 0.060299, val loss - 0.081515\n",
      "Epoch 173/176: loss - 0.058564, val loss - 0.085098\n",
      "Epoch 174/176: loss - 0.058868, val loss - 0.083891\n",
      "Epoch 175/176: loss - 0.061070, val loss - 0.082423\n",
      "Epoch 176/176: loss - 0.059270, val loss - 0.089774\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.206114, val loss - 0.173514\n",
      "Epoch 2/24: loss - 0.144796, val loss - 0.130248\n",
      "Epoch 3/24: loss - 0.126467, val loss - 0.140056\n",
      "Epoch 4/24: loss - 0.118532, val loss - 0.180961\n",
      "Epoch 5/24: loss - 0.113127, val loss - 0.109021\n",
      "Epoch 6/24: loss - 0.117020, val loss - 0.142342\n",
      "Epoch 7/24: loss - 0.104114, val loss - 0.107594\n",
      "Epoch 8/24: loss - 0.101237, val loss - 0.119659\n",
      "Epoch 9/24: loss - 0.098649, val loss - 0.098586\n",
      "Epoch 10/24: loss - 0.092724, val loss - 0.106747\n",
      "Epoch 11/24: loss - 0.088195, val loss - 0.103801\n",
      "Epoch 12/24: loss - 0.098032, val loss - 0.099354\n",
      "Epoch 13/24: loss - 0.094524, val loss - 0.101011\n",
      "Epoch 14/24: loss - 0.091390, val loss - 0.098879\n",
      "Epoch 15/24: loss - 0.104758, val loss - 0.104507\n",
      "Epoch 16/24: loss - 0.104391, val loss - 0.123202\n",
      "Epoch 17/24: loss - 0.090180, val loss - 0.096899\n",
      "Epoch 18/24: loss - 0.088300, val loss - 0.095084\n",
      "Epoch 19/24: loss - 0.089397, val loss - 0.097659\n",
      "Epoch 20/24: loss - 0.095059, val loss - 0.104347\n",
      "Epoch 21/24: loss - 0.084141, val loss - 0.111181\n",
      "Epoch 22/24: loss - 0.094220, val loss - 0.103392\n",
      "Epoch 23/24: loss - 0.087841, val loss - 0.104203\n",
      "Epoch 24/24: loss - 0.087909, val loss - 0.102761\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.178123, val loss - 0.136731\n",
      "Epoch 2/66: loss - 0.117500, val loss - 0.123337\n",
      "Epoch 3/66: loss - 0.105452, val loss - 0.113138\n",
      "Epoch 4/66: loss - 0.109706, val loss - 0.106107\n",
      "Epoch 5/66: loss - 0.105470, val loss - 0.111309\n",
      "Epoch 6/66: loss - 0.103413, val loss - 0.114445\n",
      "Epoch 7/66: loss - 0.090681, val loss - 0.104989\n",
      "Epoch 8/66: loss - 0.099558, val loss - 0.110078\n",
      "Epoch 9/66: loss - 0.089579, val loss - 0.124926\n",
      "Epoch 10/66: loss - 0.093081, val loss - 0.108033\n",
      "Epoch 11/66: loss - 0.090703, val loss - 0.116996\n",
      "Epoch 12/66: loss - 0.095975, val loss - 0.110458\n",
      "Epoch 13/66: loss - 0.092982, val loss - 0.105268\n",
      "Epoch 14/66: loss - 0.087537, val loss - 0.109639\n",
      "Epoch 15/66: loss - 0.085469, val loss - 0.114693\n",
      "Epoch 16/66: loss - 0.093041, val loss - 0.108216\n",
      "Epoch 17/66: loss - 0.092406, val loss - 0.104536\n",
      "Epoch 18/66: loss - 0.088429, val loss - 0.109644\n",
      "Epoch 19/66: loss - 0.087179, val loss - 0.105341\n",
      "Epoch 20/66: loss - 0.087523, val loss - 0.109546\n",
      "Epoch 21/66: loss - 0.092044, val loss - 0.112492\n",
      "Epoch 22/66: loss - 0.084874, val loss - 0.107294\n",
      "Epoch 23/66: loss - 0.086232, val loss - 0.107897\n",
      "Epoch 24/66: loss - 0.092166, val loss - 0.103909\n",
      "Epoch 25/66: loss - 0.086690, val loss - 0.105384\n",
      "Epoch 26/66: loss - 0.087002, val loss - 0.105071\n",
      "Epoch 27/66: loss - 0.087264, val loss - 0.105807\n",
      "Epoch 28/66: loss - 0.086795, val loss - 0.109525\n",
      "Epoch 29/66: loss - 0.085458, val loss - 0.106812\n",
      "Epoch 30/66: loss - 0.081329, val loss - 0.108332\n",
      "Epoch 31/66: loss - 0.081376, val loss - 0.106787\n",
      "Epoch 32/66: loss - 0.090636, val loss - 0.105733\n",
      "Epoch 33/66: loss - 0.087712, val loss - 0.106901\n",
      "Epoch 34/66: loss - 0.086086, val loss - 0.108553\n",
      "Epoch 35/66: loss - 0.083286, val loss - 0.105535\n",
      "Epoch 36/66: loss - 0.088199, val loss - 0.110473\n",
      "Epoch 37/66: loss - 0.089415, val loss - 0.104416\n",
      "Epoch 38/66: loss - 0.084162, val loss - 0.106568\n",
      "Epoch 39/66: loss - 0.081787, val loss - 0.112981\n",
      "Epoch 40/66: loss - 0.088459, val loss - 0.107813\n",
      "Epoch 41/66: loss - 0.084631, val loss - 0.107322\n",
      "Epoch 42/66: loss - 0.081612, val loss - 0.106909\n",
      "Epoch 43/66: loss - 0.082575, val loss - 0.110527\n",
      "Epoch 44/66: loss - 0.083883, val loss - 0.109171\n",
      "Epoch 45/66: loss - 0.085911, val loss - 0.107378\n",
      "Epoch 46/66: loss - 0.083004, val loss - 0.108396\n",
      "Epoch 47/66: loss - 0.078610, val loss - 0.118009\n",
      "Epoch 48/66: loss - 0.081049, val loss - 0.110843\n",
      "Epoch 49/66: loss - 0.079395, val loss - 0.129062\n",
      "Epoch 50/66: loss - 0.079362, val loss - 0.106725\n",
      "Epoch 51/66: loss - 0.083435, val loss - 0.106158\n",
      "Epoch 52/66: loss - 0.082636, val loss - 0.107845\n",
      "Epoch 53/66: loss - 0.087539, val loss - 0.111602\n",
      "Epoch 54/66: loss - 0.079315, val loss - 0.110693\n",
      "Epoch 55/66: loss - 0.079575, val loss - 0.106403\n",
      "Epoch 56/66: loss - 0.079912, val loss - 0.105440\n",
      "Epoch 57/66: loss - 0.079404, val loss - 0.110992\n",
      "Epoch 58/66: loss - 0.076938, val loss - 0.118246\n",
      "Epoch 59/66: loss - 0.075641, val loss - 0.113342\n",
      "Epoch 60/66: loss - 0.078001, val loss - 0.118439\n",
      "Epoch 61/66: loss - 0.080869, val loss - 0.116017\n",
      "Epoch 62/66: loss - 0.087148, val loss - 0.109639\n",
      "Epoch 63/66: loss - 0.080175, val loss - 0.109676\n",
      "Epoch 64/66: loss - 0.082170, val loss - 0.110449\n",
      "Epoch 65/66: loss - 0.083896, val loss - 0.119117\n",
      "Epoch 66/66: loss - 0.082223, val loss - 0.112402\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.197843, val loss - 0.164373\n",
      "Epoch 2/24: loss - 0.125185, val loss - 0.125691\n",
      "Epoch 3/24: loss - 0.124262, val loss - 0.172356\n",
      "Epoch 4/24: loss - 0.121586, val loss - 0.123632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24: loss - 0.111098, val loss - 0.117160\n",
      "Epoch 6/24: loss - 0.098719, val loss - 0.097077\n",
      "Epoch 7/24: loss - 0.110385, val loss - 0.121455\n",
      "Epoch 8/24: loss - 0.105453, val loss - 0.107728\n",
      "Epoch 9/24: loss - 0.089859, val loss - 0.102220\n",
      "Epoch 10/24: loss - 0.096675, val loss - 0.106458\n",
      "Epoch 11/24: loss - 0.098058, val loss - 0.102291\n",
      "Epoch 12/24: loss - 0.092078, val loss - 0.104763\n",
      "Epoch 13/24: loss - 0.099169, val loss - 0.109900\n",
      "Epoch 14/24: loss - 0.090103, val loss - 0.098391\n",
      "Epoch 15/24: loss - 0.095551, val loss - 0.109910\n",
      "Epoch 16/24: loss - 0.093207, val loss - 0.105936\n",
      "Epoch 17/24: loss - 0.083753, val loss - 0.122895\n",
      "Epoch 18/24: loss - 0.087703, val loss - 0.099204\n",
      "Epoch 19/24: loss - 0.087727, val loss - 0.102446\n",
      "Epoch 20/24: loss - 0.084828, val loss - 0.094859\n",
      "Epoch 21/24: loss - 0.084903, val loss - 0.097725\n",
      "Epoch 22/24: loss - 0.083045, val loss - 0.097685\n",
      "Epoch 23/24: loss - 0.086988, val loss - 0.104242\n",
      "Epoch 24/24: loss - 0.087011, val loss - 0.120026\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1351 - val_loss: 0.0761\n",
      "Epoch 2/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.0881\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0888\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0713 - val_loss: 0.0668\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0656\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0744\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0635\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0646 - val_loss: 0.0641\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0635\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0629\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0644\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0710\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0605\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0591\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0631\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0608\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0739\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0710\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0727\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0594\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0573\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0576\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.0572\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0592\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0607\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0782\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0603\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0575\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1676 - val_loss: 0.1179\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 0.1026\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.1065\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.0884\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0895\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0931\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.1032\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0806\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0804\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0849\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0713 - val_loss: 0.0762\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0925\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0712\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0887\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0748\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0711\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0878\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0822\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0714\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0752\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0931\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0668\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0700\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0732\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0779\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0755\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0697\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0751\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0699\n",
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0713\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0725\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0775\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0728\n",
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0679\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0786\n",
      "Epoch 1/29\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6784 - val_loss: 0.2316\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1506 - val_loss: 0.1292\n",
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1244 - val_loss: 0.1228\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1112 - val_loss: 0.1075\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0937\n",
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0913\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0885\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0898\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0939\n",
      "Epoch 10/29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.1039\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0839\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0841\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0821\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0854\n",
      "Epoch 15/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0961\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.1215\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0908\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0806\n",
      "Epoch 19/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0883\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0856\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0814\n",
      "Epoch 22/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.1165\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0944\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0843\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0920\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0889\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.1267\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0928\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0880\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2929 - val_loss: 0.1795\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1352 - val_loss: 0.1296\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1094 - val_loss: 0.0931\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0823\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0951\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.1002\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0851 - val_loss: 0.0863\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.0961\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0796\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0879\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0790 - val_loss: 0.0917\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0790\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0930\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.0846\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0811\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.1001\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0734 - val_loss: 0.1034\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0828 - val_loss: 0.0829\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.1176\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0879\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0902\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0880\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0912\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0852\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.1029\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.1289\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0788\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0893\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.1750\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0874\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0868\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.1137\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1756 - val_loss: 0.1771\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1568 - val_loss: 0.1712\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1439 - val_loss: 0.1581\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1333 - val_loss: 0.1517\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1237 - val_loss: 0.1477\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1355\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.1319\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1048 - val_loss: 0.1254\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.1168\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0993 - val_loss: 0.1218\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.1196\n",
      "Epoch 12/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.1061\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.1091\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0926 - val_loss: 0.1058\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0903 - val_loss: 0.1064\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.1024\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.1070\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0875 - val_loss: 0.1025\n",
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.1071\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.0979\n",
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.1035\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0849 - val_loss: 0.1000\n",
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.1062\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.1006\n",
      "Epoch 25/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.1122\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0977\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.1006\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.0988\n",
      "Epoch 29/108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0988\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.1035\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.1061\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0978\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.1009\n",
      "Epoch 34/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.1081\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0966\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.1059\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.1043\n",
      "Epoch 38/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0989\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.1034\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.1006\n",
      "Epoch 41/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.1013\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.1008\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.1012\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.1026\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.1006\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.1013\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.1030\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.1059\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.0981\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.1033\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0970\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.1025\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.1044\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0964\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.1006\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0978\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.1008\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0977\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.1009\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.1082\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.1017\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.1010\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.1013\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0997\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.1015\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.1026\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.1018\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0992\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.1028\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.0981\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.1110\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.1020\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.1035\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0992\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.1010\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.1013\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.1059\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.1023\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.1057\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0985\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.1070\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.1084\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.1006\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.1049\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0995\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.1018\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0747 - val_loss: 0.1067\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0990\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.1083\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.1025\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.1018\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.1004\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.1125\n",
      "Epoch 94/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.1004\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.1049\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.1074\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.1043\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.1046\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.1106\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0723 - val_loss: 0.1039\n",
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.1043\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.1097\n",
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.1000\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.1103\n",
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0995\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.1101\n",
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.1057\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.1069\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1986 - val_loss: 0.1214\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.0896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.0896\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0741\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0727\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0735\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0696\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0678\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0719\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0670\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0797\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0797\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0679\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0667\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0655\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0691\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0702\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0699\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0661\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0658\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0709\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0653\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0683\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0645\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0669\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0677\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0642\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0738\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0633\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0674\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0637\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0639\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0646\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1773 - val_loss: 0.1450\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.1280\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.1180\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1276\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1115\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.1173\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.1126\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0953 - val_loss: 0.1041\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0997\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0969\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.1073\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0946\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0950\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.1068\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0940\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.1075\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.1121\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.1133\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0972\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.1077\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.1103\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0975\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0928\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0961\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.1035\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.1092\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0931\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.1036\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0914\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0966\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0954\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0929\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0912\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0940\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0925\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2807 - val_loss: 0.2983\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1934 - val_loss: 0.2154\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1568 - val_loss: 0.1762\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.1654\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1439 - val_loss: 0.1631\n",
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1410 - val_loss: 0.1616\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1380 - val_loss: 0.1598\n",
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1352 - val_loss: 0.1569\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1320 - val_loss: 0.1527\n",
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1493\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1244 - val_loss: 0.1472\n",
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1196 - val_loss: 0.1412\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1333\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1069 - val_loss: 0.1275\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.1221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.1203\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.1147\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0919 - val_loss: 0.1176\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.1098\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.1157\n",
      "Epoch 21/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.1086\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.1117\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.1097\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.1110\n",
      "Epoch 25/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.1076\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.1101\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.1064\n",
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.1093\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.1057\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.1079\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.1072\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.1052\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.1078\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.1059\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.1063\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.1091\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.1050\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.1080\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.1057\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.1056\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.1074\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.1044\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.1062\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.1050\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.1058\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.1066\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.1102\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.1019\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.1077\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1049\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1084\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.1034\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.1058\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.1042\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.1060\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.1029\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.1114\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.1043\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.1057\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.1033\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.1078\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.1045\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.1066\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.1055\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.1048\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.1037\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.1085\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.1029\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.1064\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.1037\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.1035\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1996 - val_loss: 0.1986\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1733 - val_loss: 0.1772\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1628 - val_loss: 0.1710\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1668\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1466 - val_loss: 0.1598\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1391 - val_loss: 0.1550\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1297 - val_loss: 0.1428\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.1258\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.1064\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.1109\n",
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.1028\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.1022\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.1052\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.1094\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.1061\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.1075\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.1056\n",
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.1104\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.1026\n",
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.1087\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.1060\n",
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.1027\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.1076\n",
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1078\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.1050\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.1114\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.1067\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.1075\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.1072\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.1041\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.1054\n",
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.1076\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.1101\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.1046\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.1056\n",
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.1106\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.1050\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.1197\n",
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.1036\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.1080\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1119\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.1044\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.1081\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.1058\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.1145\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.1120\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.1042\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1067\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.1115\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.1077\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.1076\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.1088\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.1078\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.1074\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.1110\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.1112\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.1141\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.1078\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.1072\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.1166\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.1062\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.1091\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1673 - val_loss: 0.1910\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1244 - val_loss: 0.1463\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.1244\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1201\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.1263\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 0.1101\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.1027\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.1056\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.1021\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.1004\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.1004\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.1034\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.1027\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.1003\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.1005\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.1025\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.1052\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.1043\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.1178\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.1081\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.1046\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.1240\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.1286\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0999\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0996\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0990\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1732 - val_loss: 0.1411\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.1109\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.1045\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0914\n",
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.0877\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0835\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0799\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0778\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0767\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0774\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0773\n",
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0875\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0750\n",
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0729\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0723\n",
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0804\n",
      "Epoch 17/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0726\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0710\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0712\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0719\n",
      "Epoch 21/138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0708\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0716\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0704\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0718\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0725\n",
      "Epoch 26/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0809\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0722\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0713\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0730\n",
      "Epoch 30/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0713\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0714\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0732\n",
      "Epoch 33/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0709\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0714\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0725\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0722\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0729\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0714\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0719\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0726\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0733\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0722\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0796\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0728\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0732\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0732\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0737\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0743\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0731\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0778\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0741\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0737\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0760\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0742\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0742\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0748\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0748\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0761\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0757\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0800\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0748\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0772\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0761\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0763\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0854\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0783\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0763\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0821\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0752\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0757\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0766\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0760\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0775\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0796\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0842\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0818\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0757\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0759\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0757\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0780\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0762\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0786\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0794\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0767\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0769\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0759\n",
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0797\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0773\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0767\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0797\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0780\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0766\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0766\n",
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0771\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0778\n",
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0792\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0795\n",
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0770\n",
      "Epoch 99/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0799\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0773\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0774\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0779\n",
      "Epoch 103/138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0779\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0784\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0778\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0778\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0796\n",
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0780\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0839\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0791\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0787\n",
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0782\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0808\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0805\n",
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0798\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0786\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0783\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0788\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0792\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0801\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0796\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0812\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0832\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0798\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0810\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0798\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0803\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0798\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0793\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0812\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0796\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0812\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0813\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0831\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0826\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0818\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0808\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0812\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.5240 - val_loss: 2.4300\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.7170 - val_loss: 1.6373\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1179 - val_loss: 1.0721\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7175 - val_loss: 0.6841\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.4476\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3261\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2885 - val_loss: 0.2638\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2568 - val_loss: 0.2322\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2354 - val_loss: 0.2088\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2173 - val_loss: 0.1952\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2021 - val_loss: 0.1803\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1901 - val_loss: 0.1675\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1794 - val_loss: 0.1601\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1709 - val_loss: 0.1536\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1462\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1577 - val_loss: 0.1416\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1374\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.1358\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1319\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1402 - val_loss: 0.1301\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1268\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1339 - val_loss: 0.1251\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1313 - val_loss: 0.1241\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1290 - val_loss: 0.1222\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.1208\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1199\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1211\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1186\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 0.1166\n",
      "Epoch 30/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1197 - val_loss: 0.1180\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1173\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.1173\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.1167\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1162 - val_loss: 0.1158\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.1151\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1158\n",
      "Epoch 37/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1153\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1139 - val_loss: 0.1157\n",
      "Epoch 39/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1134 - val_loss: 0.1153\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1131 - val_loss: 0.1154\n",
      "Epoch 41/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.1159\n",
      "Epoch 42/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1125 - val_loss: 0.1167\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1116 - val_loss: 0.1146\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1123 - val_loss: 0.1133\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1115 - val_loss: 0.1170\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.1158\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.1156\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.1158\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.1148\n",
      "Epoch 51/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1158\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1153\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.1151\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1084 - val_loss: 0.1154\n",
      "Epoch 55/149\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1081 - val_loss: 0.1151\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1078 - val_loss: 0.1157\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.1171\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1071 - val_loss: 0.1146\n",
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 0.1144\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.1166\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.1158\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.1148\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1061 - val_loss: 0.1159\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.1162\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.1153\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.1159\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1052 - val_loss: 0.1145\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1049 - val_loss: 0.1156\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.1157\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 0.1155\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 0.1137\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.1157\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1036 - val_loss: 0.1148\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.1144\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.1165\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1141\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.1140\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.1141\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.1124\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.1136\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1128\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.1124\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.1122\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.1107\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0977 - val_loss: 0.1108\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.1096\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1079\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.1081\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.1072\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0925 - val_loss: 0.1051\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.1037\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.1025\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.1008\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0992\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0957\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0951\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0938\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0924\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0920\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0907\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0896\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0883\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0903\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0897\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0909\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0884\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0951\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0882\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0931\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0887\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0953\n",
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0906\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0923\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0914\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0896\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0918\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0916\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0919\n",
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0897\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0897\n",
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0905\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0900\n",
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0926\n",
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0893\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0905\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0912\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0929\n",
      "Epoch 128/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0901\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0914\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0905\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0897\n",
      "Epoch 132/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0911\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0887\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0909\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0947\n",
      "Epoch 136/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0891\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0910\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0892\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0905\n",
      "Epoch 140/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0913\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0875\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0900\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0921\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0900\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0966\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0891\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0924\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0940\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0884\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3704 - val_loss: 0.2032\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1668 - val_loss: 0.1897\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1502\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1323 - val_loss: 0.1512\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1279 - val_loss: 0.1448\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1249 - val_loss: 0.1513\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1421\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1205 - val_loss: 0.1385\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.1409\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.1364\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1014 - val_loss: 0.1144\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.1047\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.1062\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.1130\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.1088\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.1030\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.1025\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.1129\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.1045\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.1179\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.1066\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.1275\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.1064\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.1063\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.1091\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1035\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.1038\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.1118\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.1060\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.1182\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.1113\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.1092\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.1203\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.1392\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.1044\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.1055\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.1083\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.1076\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.1079\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.1052\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.1057\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.1193\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1085\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.1211\n",
      "Epoch 45/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.1072\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.1133\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.1084\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.1043\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.1035\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.1088\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.1188\n",
      "Epoch 52/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.1085\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.1114\n",
      "Epoch 54/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.1241\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.1089\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.1038\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2861 - val_loss: 0.1907\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1739 - val_loss: 0.1653\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1459 - val_loss: 0.1594\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1352 - val_loss: 0.1514\n",
      "Epoch 5/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.1478\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1440\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.1358\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1383\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.1320\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.1442\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.1275\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 0.1245\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1227\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1288\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.1222\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.1222\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.1214\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0945 - val_loss: 0.1223\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.1170\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0925 - val_loss: 0.1173\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.1180\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0911 - val_loss: 0.1131\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.1172\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 0.1171\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.1166\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.1182\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.1129\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.1169\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.1174\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.1177\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.1122\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.1148\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.1184\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.1131\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.1121\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.1165\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.1211\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.1151\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.1234\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.1148\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.1156\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.1212\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.1121\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.1173\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.1131\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.1201\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.1218\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.1128\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.1119\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.1200\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.1155\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.1146\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.1189\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.1161\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.1122\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.1204\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.1149\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.1177\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.1148\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.1147\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1882 - val_loss: 0.1809\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1571 - val_loss: 0.1739\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1430 - val_loss: 0.1642\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1356 - val_loss: 0.1643\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1307 - val_loss: 0.1616\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1541\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1230 - val_loss: 0.1527\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1187 - val_loss: 0.1464\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1378\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.1391\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1075 - val_loss: 0.1383\n",
      "Epoch 12/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.1235\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.1221\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.1217\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.1229\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.1170\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.1203\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.1199\n",
      "Epoch 19/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.1256\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.1130\n",
      "Epoch 21/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.1171\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.1145\n",
      "Epoch 23/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.1254\n",
      "Epoch 24/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.1108\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.1291\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.1140\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.1097\n",
      "Epoch 28/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.1108\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.1088\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.1150\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.1303\n",
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.1086\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.1147\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.1245\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.1084\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.1132\n",
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.1165\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.1104\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.1133\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.1140\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.1073\n",
      "Epoch 1/47\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1690 - val_loss: 0.1172\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1191 - val_loss: 0.0834\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1021 - val_loss: 0.0754\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0920 - val_loss: 0.0791\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0829 - val_loss: 0.0713\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0797 - val_loss: 0.0720\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0765 - val_loss: 0.0717\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0764 - val_loss: 0.0720\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0755 - val_loss: 0.0761\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0770 - val_loss: 0.0723\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0760 - val_loss: 0.0711\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0716 - val_loss: 0.0721\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0728 - val_loss: 0.0715\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0739 - val_loss: 0.0745\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0737 - val_loss: 0.0701\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0772 - val_loss: 0.0750\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0705 - val_loss: 0.0686\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0688 - val_loss: 0.0681\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0696 - val_loss: 0.0682\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0695 - val_loss: 0.0680\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0699 - val_loss: 0.0713\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0695 - val_loss: 0.0708\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0680 - val_loss: 0.0680\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0648 - val_loss: 0.0676\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0646 - val_loss: 0.0684\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0644 - val_loss: 0.0674\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0644 - val_loss: 0.0673\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0635 - val_loss: 0.0682\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0644 - val_loss: 0.0676\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0650 - val_loss: 0.0746\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0678 - val_loss: 0.0669\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0614 - val_loss: 0.0723\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0625 - val_loss: 0.0680\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0612 - val_loss: 0.0660\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0616 - val_loss: 0.0661\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0642 - val_loss: 0.0708\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0648 - val_loss: 0.0657\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0614 - val_loss: 0.0685\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0612 - val_loss: 0.0660\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0613 - val_loss: 0.0665\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0605 - val_loss: 0.0681\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0616 - val_loss: 0.0659\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0598 - val_loss: 0.0662\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0587 - val_loss: 0.0658\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0583 - val_loss: 0.0691\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0600 - val_loss: 0.0653\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.2097 - val_loss: 0.1610\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1458 - val_loss: 0.1216\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1190 - val_loss: 0.0978\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1058 - val_loss: 0.0879\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0954 - val_loss: 0.0766\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0862 - val_loss: 0.0723\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0821 - val_loss: 0.0710\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0786 - val_loss: 0.0710\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0766 - val_loss: 0.0714\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0791 - val_loss: 0.0712\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0800 - val_loss: 0.0739\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0745 - val_loss: 0.0723\n",
      "Epoch 13/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0742 - val_loss: 0.0722\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0752 - val_loss: 0.0802\n",
      "Epoch 15/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0759 - val_loss: 0.0731\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0785 - val_loss: 0.0848\n",
      "Epoch 17/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0724 - val_loss: 0.0736\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0755 - val_loss: 0.0727\n",
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0728 - val_loss: 0.0754\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0749 - val_loss: 0.0747\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0729 - val_loss: 0.0742\n",
      "Epoch 22/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0719 - val_loss: 0.0849\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0728 - val_loss: 0.0743\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0714 - val_loss: 0.0762\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0682 - val_loss: 0.0756\n",
      "Epoch 26/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0701 - val_loss: 0.0762\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0692 - val_loss: 0.0782\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0692 - val_loss: 0.0754\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0684 - val_loss: 0.0775\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0705 - val_loss: 0.0873\n",
      "Epoch 31/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0705 - val_loss: 0.0779\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0667 - val_loss: 0.0790\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0683 - val_loss: 0.0784\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0673 - val_loss: 0.0779\n",
      "Epoch 35/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0691 - val_loss: 0.0789\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0673 - val_loss: 0.0797\n",
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0679 - val_loss: 0.0809\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0674 - val_loss: 0.0827\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0701 - val_loss: 0.0820\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0666 - val_loss: 0.0809\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0669 - val_loss: 0.0816\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0658 - val_loss: 0.0823\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0665 - val_loss: 0.0828\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0681 - val_loss: 0.0835\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0651 - val_loss: 0.0836\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.2536 - val_loss: 0.1474\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1345 - val_loss: 0.1145\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1129 - val_loss: 0.0892\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1005 - val_loss: 0.0755\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0898 - val_loss: 0.0722\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0804 - val_loss: 0.0736\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0827 - val_loss: 0.0709\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0785 - val_loss: 0.0713\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0773 - val_loss: 0.0718\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0852 - val_loss: 0.0764\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0790 - val_loss: 0.0719\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0762 - val_loss: 0.0730\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0762 - val_loss: 0.0733\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0734 - val_loss: 0.0749\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0745 - val_loss: 0.0743\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0803 - val_loss: 0.0749\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0752 - val_loss: 0.0756\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0773 - val_loss: 0.0817\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0749 - val_loss: 0.0784\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0744 - val_loss: 0.0770\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0735 - val_loss: 0.0768\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0759 - val_loss: 0.0771\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0720 - val_loss: 0.0773\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3224 - val_loss: 0.1630\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1585 - val_loss: 0.1502\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1346 - val_loss: 0.1269\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1191 - val_loss: 0.1100\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1088 - val_loss: 0.0965\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1005 - val_loss: 0.0869\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0951 - val_loss: 0.0809\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0899 - val_loss: 0.0794\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0861 - val_loss: 0.0764\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0911 - val_loss: 0.0772\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0884 - val_loss: 0.0748\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0845 - val_loss: 0.0744\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0853 - val_loss: 0.0743\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0809 - val_loss: 0.0743\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0840 - val_loss: 0.0746\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0837 - val_loss: 0.0742\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0812 - val_loss: 0.0737\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0814 - val_loss: 0.0741\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0811 - val_loss: 0.0730\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0789 - val_loss: 0.0727\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0818 - val_loss: 0.0729\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0830 - val_loss: 0.0742\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0797 - val_loss: 0.0746\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3527 - val_loss: 0.2007\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1783 - val_loss: 0.1735\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1448 - val_loss: 0.1333\n",
      "Epoch 4/31\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1306 - val_loss: 0.1108\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1089 - val_loss: 0.0963\n",
      "Epoch 6/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1013 - val_loss: 0.0869\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0955 - val_loss: 0.0832\n",
      "Epoch 8/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0939 - val_loss: 0.0805\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0872 - val_loss: 0.0789\n",
      "Epoch 10/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0897 - val_loss: 0.0761\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0866 - val_loss: 0.0755\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0822 - val_loss: 0.0741\n",
      "Epoch 13/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0904 - val_loss: 0.0752\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0844 - val_loss: 0.0730\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0807 - val_loss: 0.0723\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0828 - val_loss: 0.0720\n",
      "Epoch 17/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0803 - val_loss: 0.0719\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0800 - val_loss: 0.0724\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0799 - val_loss: 0.0718\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0785 - val_loss: 0.0712\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0796 - val_loss: 0.0711\n",
      "Epoch 22/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0818 - val_loss: 0.0767\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0815 - val_loss: 0.0719\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0789 - val_loss: 0.0731\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0790 - val_loss: 0.0721\n",
      "Epoch 26/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0803 - val_loss: 0.0722\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0771 - val_loss: 0.0722\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0771 - val_loss: 0.0737\n",
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0780 - val_loss: 0.0726\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0748 - val_loss: 0.0729\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0767 - val_loss: 0.0724\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 0.855200, val loss - 0.110542\n",
      "Epoch 2/15: loss - 0.133325, val loss - 0.084523\n",
      "Epoch 3/15: loss - 0.096926, val loss - 0.093496\n",
      "Epoch 4/15: loss - 0.084368, val loss - 0.079296\n",
      "Epoch 5/15: loss - 0.088004, val loss - 0.082765\n",
      "Epoch 6/15: loss - 0.090709, val loss - 0.076779\n",
      "Epoch 7/15: loss - 0.081750, val loss - 0.072520\n",
      "Epoch 8/15: loss - 0.078156, val loss - 0.075148\n",
      "Epoch 9/15: loss - 0.079304, val loss - 0.068526\n",
      "Epoch 10/15: loss - 0.075247, val loss - 0.067816\n",
      "Epoch 11/15: loss - 0.071275, val loss - 0.065230\n",
      "Epoch 12/15: loss - 0.071847, val loss - 0.065284\n",
      "Epoch 13/15: loss - 0.070417, val loss - 0.068471\n",
      "Epoch 14/15: loss - 0.070510, val loss - 0.065628\n",
      "Epoch 15/15: loss - 0.071120, val loss - 0.064394\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.314442, val loss - 0.171049\n",
      "Epoch 2/176: loss - 0.154486, val loss - 0.134025\n",
      "Epoch 3/176: loss - 0.126851, val loss - 0.120482\n",
      "Epoch 4/176: loss - 0.128591, val loss - 0.111039\n",
      "Epoch 5/176: loss - 0.120461, val loss - 0.109669\n",
      "Epoch 6/176: loss - 0.118984, val loss - 0.097050\n",
      "Epoch 7/176: loss - 0.110086, val loss - 0.091059\n",
      "Epoch 8/176: loss - 0.099908, val loss - 0.101897\n",
      "Epoch 9/176: loss - 0.097871, val loss - 0.088579\n",
      "Epoch 10/176: loss - 0.102781, val loss - 0.096457\n",
      "Epoch 11/176: loss - 0.092019, val loss - 0.086864\n",
      "Epoch 12/176: loss - 0.088510, val loss - 0.082995\n",
      "Epoch 13/176: loss - 0.088515, val loss - 0.084613\n",
      "Epoch 14/176: loss - 0.095813, val loss - 0.096224\n",
      "Epoch 15/176: loss - 0.094747, val loss - 0.094055\n",
      "Epoch 16/176: loss - 0.091918, val loss - 0.097478\n",
      "Epoch 17/176: loss - 0.087049, val loss - 0.083463\n",
      "Epoch 18/176: loss - 0.090331, val loss - 0.081886\n",
      "Epoch 19/176: loss - 0.079428, val loss - 0.085383\n",
      "Epoch 20/176: loss - 0.088116, val loss - 0.084119\n",
      "Epoch 21/176: loss - 0.086098, val loss - 0.091836\n",
      "Epoch 22/176: loss - 0.084609, val loss - 0.091788\n",
      "Epoch 23/176: loss - 0.083040, val loss - 0.081592\n",
      "Epoch 24/176: loss - 0.081590, val loss - 0.087295\n",
      "Epoch 25/176: loss - 0.079229, val loss - 0.083426\n",
      "Epoch 26/176: loss - 0.081203, val loss - 0.079535\n",
      "Epoch 27/176: loss - 0.078333, val loss - 0.079304\n",
      "Epoch 28/176: loss - 0.072501, val loss - 0.085129\n",
      "Epoch 29/176: loss - 0.085940, val loss - 0.088010\n",
      "Epoch 30/176: loss - 0.078471, val loss - 0.077738\n",
      "Epoch 31/176: loss - 0.071348, val loss - 0.080725\n",
      "Epoch 32/176: loss - 0.070117, val loss - 0.086614\n",
      "Epoch 33/176: loss - 0.072996, val loss - 0.085834\n",
      "Epoch 34/176: loss - 0.072747, val loss - 0.083879\n",
      "Epoch 35/176: loss - 0.073833, val loss - 0.083413\n",
      "Epoch 36/176: loss - 0.069871, val loss - 0.082190\n",
      "Epoch 37/176: loss - 0.074565, val loss - 0.083183\n",
      "Epoch 38/176: loss - 0.068748, val loss - 0.083061\n",
      "Epoch 39/176: loss - 0.062734, val loss - 0.081411\n",
      "Epoch 40/176: loss - 0.067010, val loss - 0.080180\n",
      "Epoch 41/176: loss - 0.065734, val loss - 0.076040\n",
      "Epoch 42/176: loss - 0.067004, val loss - 0.092310\n",
      "Epoch 43/176: loss - 0.068056, val loss - 0.080438\n",
      "Epoch 44/176: loss - 0.067204, val loss - 0.079959\n",
      "Epoch 45/176: loss - 0.066937, val loss - 0.077306\n",
      "Epoch 46/176: loss - 0.062615, val loss - 0.077011\n",
      "Epoch 47/176: loss - 0.058618, val loss - 0.077843\n",
      "Epoch 48/176: loss - 0.061949, val loss - 0.083790\n",
      "Epoch 49/176: loss - 0.064956, val loss - 0.078746\n",
      "Epoch 50/176: loss - 0.060611, val loss - 0.087088\n",
      "Epoch 51/176: loss - 0.063338, val loss - 0.078294\n",
      "Epoch 52/176: loss - 0.062434, val loss - 0.075228\n",
      "Epoch 53/176: loss - 0.060193, val loss - 0.078591\n",
      "Epoch 54/176: loss - 0.065385, val loss - 0.073090\n",
      "Epoch 55/176: loss - 0.054317, val loss - 0.078896\n",
      "Epoch 56/176: loss - 0.064043, val loss - 0.089998\n",
      "Epoch 57/176: loss - 0.055807, val loss - 0.081660\n",
      "Epoch 58/176: loss - 0.058257, val loss - 0.080978\n",
      "Epoch 59/176: loss - 0.062640, val loss - 0.079028\n",
      "Epoch 60/176: loss - 0.055454, val loss - 0.078668\n",
      "Epoch 61/176: loss - 0.054478, val loss - 0.081213\n",
      "Epoch 62/176: loss - 0.051149, val loss - 0.078605\n",
      "Epoch 63/176: loss - 0.051188, val loss - 0.074026\n",
      "Epoch 64/176: loss - 0.047951, val loss - 0.079440\n",
      "Epoch 65/176: loss - 0.052853, val loss - 0.078645\n",
      "Epoch 66/176: loss - 0.051924, val loss - 0.080855\n",
      "Epoch 67/176: loss - 0.047878, val loss - 0.075353\n",
      "Epoch 68/176: loss - 0.053046, val loss - 0.073979\n",
      "Epoch 69/176: loss - 0.049906, val loss - 0.094851\n",
      "Epoch 70/176: loss - 0.077813, val loss - 0.084665\n",
      "Epoch 71/176: loss - 0.075447, val loss - 0.076610\n",
      "Epoch 72/176: loss - 0.063362, val loss - 0.075573\n",
      "Epoch 73/176: loss - 0.058889, val loss - 0.078028\n",
      "Epoch 74/176: loss - 0.056205, val loss - 0.070692\n",
      "Epoch 75/176: loss - 0.056335, val loss - 0.077577\n",
      "Epoch 76/176: loss - 0.051568, val loss - 0.083165\n",
      "Epoch 77/176: loss - 0.058680, val loss - 0.089097\n",
      "Epoch 78/176: loss - 0.058207, val loss - 0.075918\n",
      "Epoch 79/176: loss - 0.050413, val loss - 0.084232\n",
      "Epoch 80/176: loss - 0.047630, val loss - 0.083269\n",
      "Epoch 81/176: loss - 0.049285, val loss - 0.081047\n",
      "Epoch 82/176: loss - 0.047602, val loss - 0.079733\n",
      "Epoch 83/176: loss - 0.047601, val loss - 0.078691\n",
      "Epoch 84/176: loss - 0.048363, val loss - 0.073439\n",
      "Epoch 85/176: loss - 0.048295, val loss - 0.078627\n",
      "Epoch 86/176: loss - 0.050010, val loss - 0.076337\n",
      "Epoch 87/176: loss - 0.047846, val loss - 0.074663\n",
      "Epoch 88/176: loss - 0.045450, val loss - 0.076884\n",
      "Epoch 89/176: loss - 0.045479, val loss - 0.079027\n",
      "Epoch 90/176: loss - 0.044264, val loss - 0.076353\n",
      "Epoch 91/176: loss - 0.052225, val loss - 0.082119\n",
      "Epoch 92/176: loss - 0.050766, val loss - 0.079488\n",
      "Epoch 93/176: loss - 0.044138, val loss - 0.078027\n",
      "Epoch 94/176: loss - 0.045929, val loss - 0.073015\n",
      "Epoch 95/176: loss - 0.046669, val loss - 0.073991\n",
      "Epoch 96/176: loss - 0.042874, val loss - 0.077966\n",
      "Epoch 97/176: loss - 0.049045, val loss - 0.075169\n",
      "Epoch 98/176: loss - 0.048938, val loss - 0.076454\n",
      "Epoch 99/176: loss - 0.048567, val loss - 0.074698\n",
      "Epoch 100/176: loss - 0.044679, val loss - 0.078093\n",
      "Epoch 101/176: loss - 0.043484, val loss - 0.076005\n",
      "Epoch 102/176: loss - 0.042315, val loss - 0.076056\n",
      "Epoch 103/176: loss - 0.042407, val loss - 0.073843\n",
      "Epoch 104/176: loss - 0.041216, val loss - 0.078154\n",
      "Epoch 105/176: loss - 0.042160, val loss - 0.073925\n",
      "Epoch 106/176: loss - 0.042666, val loss - 0.081557\n",
      "Epoch 107/176: loss - 0.047009, val loss - 0.081236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/176: loss - 0.050066, val loss - 0.083477\n",
      "Epoch 109/176: loss - 0.042664, val loss - 0.073769\n",
      "Epoch 110/176: loss - 0.043904, val loss - 0.076310\n",
      "Epoch 111/176: loss - 0.040991, val loss - 0.077871\n",
      "Epoch 112/176: loss - 0.039736, val loss - 0.079326\n",
      "Epoch 113/176: loss - 0.041011, val loss - 0.071661\n",
      "Epoch 114/176: loss - 0.044359, val loss - 0.081806\n",
      "Epoch 115/176: loss - 0.041621, val loss - 0.078190\n",
      "Epoch 116/176: loss - 0.045074, val loss - 0.077405\n",
      "Epoch 117/176: loss - 0.045033, val loss - 0.086960\n",
      "Epoch 118/176: loss - 0.052371, val loss - 0.074692\n",
      "Epoch 119/176: loss - 0.042802, val loss - 0.076713\n",
      "Epoch 120/176: loss - 0.045130, val loss - 0.085604\n",
      "Epoch 121/176: loss - 0.043014, val loss - 0.096211\n",
      "Epoch 122/176: loss - 0.047063, val loss - 0.083678\n",
      "Epoch 123/176: loss - 0.042488, val loss - 0.084833\n",
      "Epoch 124/176: loss - 0.040958, val loss - 0.078533\n",
      "Epoch 125/176: loss - 0.039869, val loss - 0.075550\n",
      "Epoch 126/176: loss - 0.039108, val loss - 0.076269\n",
      "Epoch 127/176: loss - 0.042973, val loss - 0.080422\n",
      "Epoch 128/176: loss - 0.044013, val loss - 0.079321\n",
      "Epoch 129/176: loss - 0.045773, val loss - 0.078084\n",
      "Epoch 130/176: loss - 0.042012, val loss - 0.081962\n",
      "Epoch 131/176: loss - 0.041344, val loss - 0.075038\n",
      "Epoch 132/176: loss - 0.038323, val loss - 0.081172\n",
      "Epoch 133/176: loss - 0.039969, val loss - 0.079320\n",
      "Epoch 134/176: loss - 0.039504, val loss - 0.073282\n",
      "Epoch 135/176: loss - 0.042241, val loss - 0.079250\n",
      "Epoch 136/176: loss - 0.042579, val loss - 0.088440\n",
      "Epoch 137/176: loss - 0.042515, val loss - 0.086545\n",
      "Epoch 138/176: loss - 0.044992, val loss - 0.084886\n",
      "Epoch 139/176: loss - 0.043564, val loss - 0.092836\n",
      "Epoch 140/176: loss - 0.048907, val loss - 0.092930\n",
      "Epoch 141/176: loss - 0.041987, val loss - 0.081520\n",
      "Epoch 142/176: loss - 0.038686, val loss - 0.078236\n",
      "Epoch 143/176: loss - 0.037633, val loss - 0.089632\n",
      "Epoch 144/176: loss - 0.038164, val loss - 0.080984\n",
      "Epoch 145/176: loss - 0.037750, val loss - 0.090933\n",
      "Epoch 146/176: loss - 0.042373, val loss - 0.072991\n",
      "Epoch 147/176: loss - 0.043795, val loss - 0.086105\n",
      "Epoch 148/176: loss - 0.043193, val loss - 0.078970\n",
      "Epoch 149/176: loss - 0.047319, val loss - 0.087683\n",
      "Epoch 150/176: loss - 0.049833, val loss - 0.073260\n",
      "Epoch 151/176: loss - 0.046634, val loss - 0.089767\n",
      "Epoch 152/176: loss - 0.043919, val loss - 0.074823\n",
      "Epoch 153/176: loss - 0.042429, val loss - 0.080480\n",
      "Epoch 154/176: loss - 0.042300, val loss - 0.082627\n",
      "Epoch 155/176: loss - 0.040828, val loss - 0.089089\n",
      "Epoch 156/176: loss - 0.040944, val loss - 0.083322\n",
      "Epoch 157/176: loss - 0.040394, val loss - 0.098662\n",
      "Epoch 158/176: loss - 0.041108, val loss - 0.072441\n",
      "Epoch 159/176: loss - 0.041585, val loss - 0.086644\n",
      "Epoch 160/176: loss - 0.040153, val loss - 0.090119\n",
      "Epoch 161/176: loss - 0.041078, val loss - 0.086006\n",
      "Epoch 162/176: loss - 0.044292, val loss - 0.081772\n",
      "Epoch 163/176: loss - 0.049191, val loss - 0.083136\n",
      "Epoch 164/176: loss - 0.052907, val loss - 0.079005\n",
      "Epoch 165/176: loss - 0.048971, val loss - 0.081564\n",
      "Epoch 166/176: loss - 0.040624, val loss - 0.085238\n",
      "Epoch 167/176: loss - 0.040407, val loss - 0.087443\n",
      "Epoch 168/176: loss - 0.040374, val loss - 0.091029\n",
      "Epoch 169/176: loss - 0.037990, val loss - 0.081733\n",
      "Epoch 170/176: loss - 0.037633, val loss - 0.077004\n",
      "Epoch 171/176: loss - 0.037008, val loss - 0.082556\n",
      "Epoch 172/176: loss - 0.044951, val loss - 0.081716\n",
      "Epoch 173/176: loss - 0.056478, val loss - 0.091295\n",
      "Epoch 174/176: loss - 0.050228, val loss - 0.074987\n",
      "Epoch 175/176: loss - 0.049827, val loss - 0.077225\n",
      "Epoch 176/176: loss - 0.046709, val loss - 0.077334\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.186790, val loss - 0.152811\n",
      "Epoch 2/24: loss - 0.137238, val loss - 0.118684\n",
      "Epoch 3/24: loss - 0.131906, val loss - 0.122537\n",
      "Epoch 4/24: loss - 0.117164, val loss - 0.100847\n",
      "Epoch 5/24: loss - 0.115631, val loss - 0.098250\n",
      "Epoch 6/24: loss - 0.097545, val loss - 0.087952\n",
      "Epoch 7/24: loss - 0.095199, val loss - 0.093706\n",
      "Epoch 8/24: loss - 0.099953, val loss - 0.099287\n",
      "Epoch 9/24: loss - 0.093259, val loss - 0.098623\n",
      "Epoch 10/24: loss - 0.088145, val loss - 0.084357\n",
      "Epoch 11/24: loss - 0.090841, val loss - 0.094350\n",
      "Epoch 12/24: loss - 0.084789, val loss - 0.088460\n",
      "Epoch 13/24: loss - 0.081909, val loss - 0.085648\n",
      "Epoch 14/24: loss - 0.084536, val loss - 0.102900\n",
      "Epoch 15/24: loss - 0.085496, val loss - 0.086897\n",
      "Epoch 16/24: loss - 0.082181, val loss - 0.090551\n",
      "Epoch 17/24: loss - 0.082074, val loss - 0.086933\n",
      "Epoch 18/24: loss - 0.079291, val loss - 0.092289\n",
      "Epoch 19/24: loss - 0.077475, val loss - 0.090416\n",
      "Epoch 20/24: loss - 0.077737, val loss - 0.089348\n",
      "Epoch 21/24: loss - 0.078803, val loss - 0.089422\n",
      "Epoch 22/24: loss - 0.077403, val loss - 0.095918\n",
      "Epoch 23/24: loss - 0.074380, val loss - 0.091679\n",
      "Epoch 24/24: loss - 0.076596, val loss - 0.091638\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.190670, val loss - 0.129509\n",
      "Epoch 2/66: loss - 0.132422, val loss - 0.118011\n",
      "Epoch 3/66: loss - 0.129123, val loss - 0.121262\n",
      "Epoch 4/66: loss - 0.124927, val loss - 0.114424\n",
      "Epoch 5/66: loss - 0.117590, val loss - 0.105626\n",
      "Epoch 6/66: loss - 0.110557, val loss - 0.109403\n",
      "Epoch 7/66: loss - 0.109146, val loss - 0.101378\n",
      "Epoch 8/66: loss - 0.102812, val loss - 0.105937\n",
      "Epoch 9/66: loss - 0.103883, val loss - 0.096964\n",
      "Epoch 10/66: loss - 0.090588, val loss - 0.092117\n",
      "Epoch 11/66: loss - 0.101901, val loss - 0.088407\n",
      "Epoch 12/66: loss - 0.102861, val loss - 0.102008\n",
      "Epoch 13/66: loss - 0.092357, val loss - 0.105063\n",
      "Epoch 14/66: loss - 0.090389, val loss - 0.090835\n",
      "Epoch 15/66: loss - 0.091386, val loss - 0.096910\n",
      "Epoch 16/66: loss - 0.088145, val loss - 0.086127\n",
      "Epoch 17/66: loss - 0.092116, val loss - 0.085306\n",
      "Epoch 18/66: loss - 0.083823, val loss - 0.093039\n",
      "Epoch 19/66: loss - 0.083666, val loss - 0.089308\n",
      "Epoch 20/66: loss - 0.087574, val loss - 0.093262\n",
      "Epoch 21/66: loss - 0.081288, val loss - 0.087098\n",
      "Epoch 22/66: loss - 0.083971, val loss - 0.090328\n",
      "Epoch 23/66: loss - 0.082695, val loss - 0.097855\n",
      "Epoch 24/66: loss - 0.082518, val loss - 0.092818\n",
      "Epoch 25/66: loss - 0.083299, val loss - 0.085300\n",
      "Epoch 26/66: loss - 0.082626, val loss - 0.088498\n",
      "Epoch 27/66: loss - 0.082548, val loss - 0.087023\n",
      "Epoch 28/66: loss - 0.082645, val loss - 0.087814\n",
      "Epoch 29/66: loss - 0.079167, val loss - 0.091034\n",
      "Epoch 30/66: loss - 0.079534, val loss - 0.091715\n",
      "Epoch 31/66: loss - 0.081032, val loss - 0.088921\n",
      "Epoch 32/66: loss - 0.087083, val loss - 0.085745\n",
      "Epoch 33/66: loss - 0.078468, val loss - 0.083279\n",
      "Epoch 34/66: loss - 0.079788, val loss - 0.084409\n",
      "Epoch 35/66: loss - 0.078152, val loss - 0.091454\n",
      "Epoch 36/66: loss - 0.081000, val loss - 0.086006\n",
      "Epoch 37/66: loss - 0.080787, val loss - 0.086529\n",
      "Epoch 38/66: loss - 0.081520, val loss - 0.092236\n",
      "Epoch 39/66: loss - 0.081769, val loss - 0.086722\n",
      "Epoch 40/66: loss - 0.077999, val loss - 0.096161\n",
      "Epoch 41/66: loss - 0.077285, val loss - 0.090760\n",
      "Epoch 42/66: loss - 0.077721, val loss - 0.090826\n",
      "Epoch 43/66: loss - 0.079513, val loss - 0.086104\n",
      "Epoch 44/66: loss - 0.077891, val loss - 0.089613\n",
      "Epoch 45/66: loss - 0.078847, val loss - 0.088253\n",
      "Epoch 46/66: loss - 0.073623, val loss - 0.090637\n",
      "Epoch 47/66: loss - 0.079255, val loss - 0.088995\n",
      "Epoch 48/66: loss - 0.077720, val loss - 0.092426\n",
      "Epoch 49/66: loss - 0.076705, val loss - 0.092883\n",
      "Epoch 50/66: loss - 0.075613, val loss - 0.097140\n",
      "Epoch 51/66: loss - 0.078530, val loss - 0.085421\n",
      "Epoch 52/66: loss - 0.073790, val loss - 0.090916\n",
      "Epoch 53/66: loss - 0.077068, val loss - 0.088126\n",
      "Epoch 54/66: loss - 0.075429, val loss - 0.090609\n",
      "Epoch 55/66: loss - 0.074586, val loss - 0.088959\n",
      "Epoch 56/66: loss - 0.073714, val loss - 0.094521\n",
      "Epoch 57/66: loss - 0.077810, val loss - 0.089372\n",
      "Epoch 58/66: loss - 0.076445, val loss - 0.088554\n",
      "Epoch 59/66: loss - 0.075655, val loss - 0.088507\n",
      "Epoch 60/66: loss - 0.077286, val loss - 0.087164\n",
      "Epoch 61/66: loss - 0.077224, val loss - 0.089554\n",
      "Epoch 62/66: loss - 0.078895, val loss - 0.088704\n",
      "Epoch 63/66: loss - 0.075731, val loss - 0.086698\n",
      "Epoch 64/66: loss - 0.078101, val loss - 0.090347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/66: loss - 0.074884, val loss - 0.090588\n",
      "Epoch 66/66: loss - 0.075657, val loss - 0.086358\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.188055, val loss - 0.145839\n",
      "Epoch 2/24: loss - 0.145370, val loss - 0.131446\n",
      "Epoch 3/24: loss - 0.135852, val loss - 0.131950\n",
      "Epoch 4/24: loss - 0.126649, val loss - 0.113556\n",
      "Epoch 5/24: loss - 0.137409, val loss - 0.119556\n",
      "Epoch 6/24: loss - 0.114740, val loss - 0.107559\n",
      "Epoch 7/24: loss - 0.097577, val loss - 0.102880\n",
      "Epoch 8/24: loss - 0.100911, val loss - 0.087983\n",
      "Epoch 9/24: loss - 0.094639, val loss - 0.106607\n",
      "Epoch 10/24: loss - 0.092572, val loss - 0.096911\n",
      "Epoch 11/24: loss - 0.101054, val loss - 0.098795\n",
      "Epoch 12/24: loss - 0.095746, val loss - 0.101073\n",
      "Epoch 13/24: loss - 0.095904, val loss - 0.100905\n",
      "Epoch 14/24: loss - 0.088175, val loss - 0.089440\n",
      "Epoch 15/24: loss - 0.090612, val loss - 0.097112\n",
      "Epoch 16/24: loss - 0.082559, val loss - 0.084745\n",
      "Epoch 17/24: loss - 0.087727, val loss - 0.094629\n",
      "Epoch 18/24: loss - 0.088248, val loss - 0.086030\n",
      "Epoch 19/24: loss - 0.089164, val loss - 0.091193\n",
      "Epoch 20/24: loss - 0.083010, val loss - 0.089698\n",
      "Epoch 21/24: loss - 0.084880, val loss - 0.088963\n",
      "Epoch 22/24: loss - 0.082820, val loss - 0.086882\n",
      "Epoch 23/24: loss - 0.083733, val loss - 0.089321\n",
      "Epoch 24/24: loss - 0.079846, val loss - 0.081415\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1975 - val_loss: 0.1064\n",
      "Epoch 2/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.0775\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0782\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0764\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0749\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0715\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0707\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0663\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0703\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0703\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0664\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0664\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0632\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0668\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0616\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0655 - val_loss: 0.0626\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0657\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0677\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0660\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0731\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0625\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0676\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0637\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0631\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0732\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0677\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0740\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0661\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2379 - val_loss: 0.1624\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1344 - val_loss: 0.1313\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1045\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1105 - val_loss: 0.0948\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0823\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.0741\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.0771\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0949\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0737\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0706\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0773\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.0819\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0709\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0714\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0758\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0832\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0719\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0750\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0705\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0706\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0880\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0670\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0727\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0710\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0684\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0680\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0713\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0713\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0711\n",
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0703\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.0733\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.0732\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0821\n",
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.1004\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0787\n",
      "Epoch 1/29\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3080 - val_loss: 0.1606\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1171\n",
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1145 - val_loss: 0.0950\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0979 - val_loss: 0.1064\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0847 - val_loss: 0.0838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0903\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.1026\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.1032\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0826\n",
      "Epoch 10/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0762\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0818\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0768\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0751\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0780\n",
      "Epoch 15/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0730\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0707\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0706\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0813\n",
      "Epoch 19/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0702\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0771\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0743\n",
      "Epoch 22/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0998\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0691\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0788\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0673\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0800\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0760\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0823\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0672\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2688 - val_loss: 0.1573\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1383 - val_loss: 0.1266\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.0933\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.1100\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.0848\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.0862\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0785\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0766\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0827\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0777\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0826\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.1007\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0726\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0762\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.1315\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.0697\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0828\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.0761\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0721\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0845\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0721\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0750\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0723\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0755\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0773\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0782\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0760\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0726\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0728\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0678\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0829\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0683\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0743\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0766\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.7609 - val_loss: 0.5480\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4109 - val_loss: 0.3027\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2269 - val_loss: 0.1877\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1501 - val_loss: 0.1547\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1353 - val_loss: 0.1491\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1317 - val_loss: 0.1442\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1278 - val_loss: 0.1401\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1244 - val_loss: 0.1365\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1214 - val_loss: 0.1330\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.1294\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1158 - val_loss: 0.1264\n",
      "Epoch 12/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1129 - val_loss: 0.1232\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1103 - val_loss: 0.1201\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.1171\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1052 - val_loss: 0.1144\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.1117\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.1090\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0991 - val_loss: 0.1068\n",
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0975 - val_loss: 0.1046\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.1025\n",
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0943 - val_loss: 0.1008\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0936 - val_loss: 0.0993\n",
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0923 - val_loss: 0.0981\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0919 - val_loss: 0.0970\n",
      "Epoch 25/108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0909 - val_loss: 0.0959\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.0951\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0896 - val_loss: 0.0943\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0933\n",
      "Epoch 29/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.0927\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.0920\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0912\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0903\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.0900\n",
      "Epoch 34/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.0896\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0889\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.0884\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.0882\n",
      "Epoch 38/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0851 - val_loss: 0.0875\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.0875\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0869\n",
      "Epoch 41/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0863\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0859\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.0858\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0854\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0850\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0854\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0845\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0843\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0840\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0835\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0833\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.0833\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0831\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0831\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0826\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0828\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0790 - val_loss: 0.0823\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0824\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0822\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0821\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.0821\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.0828\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.0817\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.0826\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0813\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0773 - val_loss: 0.0814\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.0812\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0811\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0766 - val_loss: 0.0814\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0766 - val_loss: 0.0810\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0806\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0766 - val_loss: 0.0817\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0812\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0810\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0808\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0813\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0805\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.0810\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0808\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.0806\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0803\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.0806\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0807\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0800\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0806\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0824\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0807\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0808\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0804\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0816\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0817\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0805\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0798\n",
      "Epoch 94/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.0845\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0802\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0806\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0803\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0814\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0808\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0838\n",
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0734 - val_loss: 0.0803\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0815\n",
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0813\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0806\n",
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0813\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0815\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0716 - val_loss: 0.0810\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1146 - val_loss: 0.0810\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0723\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0801\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0717\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0681\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0656\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0698\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0640\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0673\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0727\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0692\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0646\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0665\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0644\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0674\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0712\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0662\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0701\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0657\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0676\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0790\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0613\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0657\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0649\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0702\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0619\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0729\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0631\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0710\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0720\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0582\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0754\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0650\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0611\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1789 - val_loss: 0.1566\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1333 - val_loss: 0.1134\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.0996\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.0904\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0888\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0905\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0859\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0956\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0850\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0889\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0911\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0851\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0901\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0893\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0832\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0900\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0862\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0933\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0867\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0924\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0935\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0936\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0892\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0991\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0935\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0832\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0891\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0852\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0916\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0955\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0882\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0940\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0894\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0945\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0881\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0880\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.9718 - val_loss: 0.7619\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6578 - val_loss: 0.5218\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.3473\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2721 - val_loss: 0.2290\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1789\n",
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1738\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1431 - val_loss: 0.1712\n",
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1670\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1369 - val_loss: 0.1639\n",
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1339 - val_loss: 0.1604\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1303 - val_loss: 0.1570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1531\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1495\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1459\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.1417\n",
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1118 - val_loss: 0.1381\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.1345\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1056 - val_loss: 0.1314\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.1288\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1262\n",
      "Epoch 21/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1237\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.1216\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.1197\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1177\n",
      "Epoch 25/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.1160\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.1142\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.1130\n",
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.1109\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.1098\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.1083\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.1074\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.1060\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.1053\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.1042\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.1034\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.1025\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.1020\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.1010\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.1006\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0997\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.0993\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0986\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0987\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0977\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0973\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0971\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0965\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.0965\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0956\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0965\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0953\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0952\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0948\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0943\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0942\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0937\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0938\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0941\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0931\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0932\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0931\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0930\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0928\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0926\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0927\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0926\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0927\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0921\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0918\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0922\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0920\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3861 - val_loss: 0.2522\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2011 - val_loss: 0.1773\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1644 - val_loss: 0.1709\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1579 - val_loss: 0.1629\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1568\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1431 - val_loss: 0.1506\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1445\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1291 - val_loss: 0.1377\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1215 - val_loss: 0.1294\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1124 - val_loss: 0.1203\n",
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.1108\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0944 - val_loss: 0.1036\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.1002\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0986\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0972\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0964\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0953\n",
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.0947\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0946\n",
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0933\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0931\n",
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0928\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0909\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0918\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0908\n",
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0904\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0896\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0895\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0894\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0899\n",
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0888\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0889\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0882\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0882\n",
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0765 - val_loss: 0.0881\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0884\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0885\n",
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0873\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0877\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0879\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0884\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0876\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0874\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0885\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0868\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0868\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0871\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0879\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0880\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0874\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0868\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0869\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0870\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0866\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0878\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0874\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0879\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0867\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0874\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0870\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0869\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2606 - val_loss: 0.1858\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1481 - val_loss: 0.1505\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1303 - val_loss: 0.1353\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1182\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.1048\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0995\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0887\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0872\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0909\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.0887\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0826\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0810\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0887\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0944\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0820\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0809\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0799\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0789\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0784\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0787\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0776\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0803\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0857\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0793\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0807\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0790\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2070 - val_loss: 0.1289\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1257 - val_loss: 0.1059\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 0.0969\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.0932\n",
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0897\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0877\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0860\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0849\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0840\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0831\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0841\n",
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0822\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0816\n",
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0814\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0821\n",
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0809\n",
      "Epoch 17/138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0838\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0807\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0806\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0805\n",
      "Epoch 21/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0800\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0803\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0809\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0798\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0809\n",
      "Epoch 26/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0795\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0801\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0809\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0789\n",
      "Epoch 30/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0791\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0815\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0797\n",
      "Epoch 33/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0790\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0788\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0783\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0789\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0803\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0785\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0778\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0774\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0785\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0778\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0773\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0784\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0776\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0784\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0773\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0804\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0763\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0774\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0811\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0781\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0774\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0798\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0777\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0806\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0779\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0775\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0797\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0795\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0788\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0813\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0789\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0795\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0799\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0820\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0822\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0817\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0788\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0817\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0821\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0808\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0796\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0845\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0808\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0826\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0829\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0793\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0820\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0822\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0845\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0818\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0812\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0821\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0825\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0823\n",
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0820\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0815\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0826\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0833\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0830\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0820\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0824\n",
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0853\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0849\n",
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0837\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0824\n",
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0825\n",
      "Epoch 99/138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0817\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0849\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0880\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0835\n",
      "Epoch 103/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0861\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0826\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0840\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0827\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0855\n",
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0817\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0830\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0876\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0832\n",
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0834\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0843\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0839\n",
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0851\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0843\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0857\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0835\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0843\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0829\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0850\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0832\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0848\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0850\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0882\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0851\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0870\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0837\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0850\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0836\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0864\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0866\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0845\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0870\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0891\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0853\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0835\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0866\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2646 - val_loss: 0.1729\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1811 - val_loss: 0.1446\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1337\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1428 - val_loss: 0.1276\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1357 - val_loss: 0.1241\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.1217\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1197\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1259 - val_loss: 0.1181\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.1167\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1222 - val_loss: 0.1158\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1207 - val_loss: 0.1146\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1137\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.1132\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.1124\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.1117\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1114\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1108\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1128 - val_loss: 0.1096\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1116 - val_loss: 0.1087\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.1085\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1071 - val_loss: 0.1071\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 0.1080\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.1082\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.1073\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.1102\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.1095\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.1062\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1083\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.1050\n",
      "Epoch 30/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0941 - val_loss: 0.1041\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.1087\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.1047\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.1026\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.1043\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.1051\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.1015\n",
      "Epoch 37/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.1057\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.1048\n",
      "Epoch 39/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.1052\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.1010\n",
      "Epoch 41/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.1007\n",
      "Epoch 42/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.1041\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1015\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.1044\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1003\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.1049\n",
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.1057\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.1022\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0980\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0982\n",
      "Epoch 51/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0986\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.1051\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.1093\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0969\n",
      "Epoch 55/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0968\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0983\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0982\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.1016\n",
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0953\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0958\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0956\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0950\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0951\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0941\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0945\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0942\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0985\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0943\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0929\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0948\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0924\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0924\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0934\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0937\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0912\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0931\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0915\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0910\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0933\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0910\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0900\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0896\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0903\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0906\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0916\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0923\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0892\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0908\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0912\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0900\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0885\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0884\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0911\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0893\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0939\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0898\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0878\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0910\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0886\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0891\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0930\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0891\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0877\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0888\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0871\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0871\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0880\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0868\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0882\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0877\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0867\n",
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0875\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0870\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0880\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0864\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0862\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0870\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0867\n",
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0862\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0861\n",
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0860\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0859\n",
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0859\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0932\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0898\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0854\n",
      "Epoch 128/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0867\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0870\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0866\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0931\n",
      "Epoch 132/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0876\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0853\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0857\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0869\n",
      "Epoch 136/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0864\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0854\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0857\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0872\n",
      "Epoch 140/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0901\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0860\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0868\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0858\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0897\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0872\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0886\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0868\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0851\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0863\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4854 - val_loss: 0.2900\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1994 - val_loss: 0.1763\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1624 - val_loss: 0.1519\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1372\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1302\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1303 - val_loss: 0.1211\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1135\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1148 - val_loss: 0.1045\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.0977\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.0936\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0944 - val_loss: 0.0887\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0922 - val_loss: 0.0887\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0860\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0849\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0846\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0843\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0852\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0843\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0831\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0863\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0841\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0849\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0829\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0945\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0841\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0899\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0838\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0860\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0826\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0872\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0837\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0867\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0844\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0851\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0859\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0893\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0878\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0870\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0835\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0850\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0851\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0864\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0845\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0869\n",
      "Epoch 45/56\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.0846\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0857\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0883\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0832\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0911\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0878\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0836\n",
      "Epoch 52/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0842\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0850\n",
      "Epoch 54/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0841\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0836\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0892\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3255 - val_loss: 0.2518\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1875 - val_loss: 0.2059\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1741\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1539\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1141 - val_loss: 0.1420\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1071 - val_loss: 0.1359\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.1310\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.1277\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.1255\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.1227\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.1209\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.1179\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.1166\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.1145\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.1151\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.1113\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.1104\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.1090\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.1096\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.1065\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.1061\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.1074\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.1045\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.1028\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.1022\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.1062\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.1013\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.1005\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0988\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0987\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0981\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.1006\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0968\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0963\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0965\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0958\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0951\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0958\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0938\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0934\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0937\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0938\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0952\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0934\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0922\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0972\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0912\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0915\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0920\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0933\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0924\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0907\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0908\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0907\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0910\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0912\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0912\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0916\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0905\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0905\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1943 - val_loss: 0.1750\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1610 - val_loss: 0.1559\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1506\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1486 - val_loss: 0.1480\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1465\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1442\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1396 - val_loss: 0.1432\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1359 - val_loss: 0.1420\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.1395\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.1368\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1280 - val_loss: 0.1341\n",
      "Epoch 12/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1230 - val_loss: 0.1292\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.1213\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 0.1102\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.1029\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.1018\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.0979\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.0985\n",
      "Epoch 19/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.0947\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0941\n",
      "Epoch 21/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0939\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0973\n",
      "Epoch 23/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0948\n",
      "Epoch 24/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0925\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.0920\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0941\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.0907\n",
      "Epoch 28/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0914\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0921\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0896\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0888\n",
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0904\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0882\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0878\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0881\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0882\n",
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0877\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0880\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0877\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0878\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0864\n",
      "Epoch 1/47\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.2177 - val_loss: 0.1596\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1471 - val_loss: 0.1100\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1115 - val_loss: 0.0873\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0957 - val_loss: 0.0810\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0850 - val_loss: 0.0809\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0884 - val_loss: 0.0766\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0881 - val_loss: 0.0746\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0814 - val_loss: 0.0760\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0750 - val_loss: 0.0720\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0779 - val_loss: 0.0707\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0766 - val_loss: 0.0701\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0739 - val_loss: 0.0687\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0695 - val_loss: 0.0669\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0729 - val_loss: 0.0691\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0696 - val_loss: 0.0652\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0684 - val_loss: 0.0646\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0702 - val_loss: 0.0656\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0723 - val_loss: 0.0667\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0653 - val_loss: 0.0643\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0649 - val_loss: 0.0621\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0692 - val_loss: 0.0605\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0646 - val_loss: 0.0643\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0615 - val_loss: 0.0601\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0638 - val_loss: 0.0637\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0628 - val_loss: 0.0590\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0613 - val_loss: 0.0591\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0607 - val_loss: 0.0584\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0626 - val_loss: 0.0589\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0649 - val_loss: 0.0585\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0622 - val_loss: 0.0604\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0603 - val_loss: 0.0569\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0590 - val_loss: 0.0574\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0586 - val_loss: 0.0567\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0605 - val_loss: 0.0602\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0573 - val_loss: 0.0579\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0568 - val_loss: 0.0564\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0570 - val_loss: 0.0568\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0567 - val_loss: 0.0561\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0597 - val_loss: 0.0567\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0596 - val_loss: 0.0563\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0614 - val_loss: 0.0561\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0571 - val_loss: 0.0558\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0562 - val_loss: 0.0566\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0552 - val_loss: 0.0569\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0556 - val_loss: 0.0558\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0563 - val_loss: 0.0565\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0552 - val_loss: 0.0559\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.2095 - val_loss: 0.1252\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1260 - val_loss: 0.0853\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0965 - val_loss: 0.0797\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0834 - val_loss: 0.0690\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0826 - val_loss: 0.0713\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0826 - val_loss: 0.0687\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0815 - val_loss: 0.0678\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0786 - val_loss: 0.0675\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0769 - val_loss: 0.0701\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0787 - val_loss: 0.0677\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0802 - val_loss: 0.0707\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0788 - val_loss: 0.0691\n",
      "Epoch 13/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0778 - val_loss: 0.0664\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0787 - val_loss: 0.0698\n",
      "Epoch 15/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0783 - val_loss: 0.0661\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0786 - val_loss: 0.0667\n",
      "Epoch 17/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0802 - val_loss: 0.0739\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0834 - val_loss: 0.0728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0771 - val_loss: 0.0760\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0779 - val_loss: 0.0655\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0747 - val_loss: 0.0735\n",
      "Epoch 22/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0767 - val_loss: 0.0703\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0729 - val_loss: 0.0653\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0743 - val_loss: 0.0671\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0756 - val_loss: 0.0658\n",
      "Epoch 26/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0735 - val_loss: 0.0659\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0731 - val_loss: 0.0698\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0744 - val_loss: 0.0656\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0777 - val_loss: 0.0659\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0766 - val_loss: 0.0645\n",
      "Epoch 31/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0766 - val_loss: 0.0647\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0729 - val_loss: 0.0706\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0729 - val_loss: 0.0649\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0743 - val_loss: 0.0644\n",
      "Epoch 35/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0721 - val_loss: 0.0679\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0732 - val_loss: 0.0650\n",
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0731 - val_loss: 0.0650\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0715 - val_loss: 0.0650\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0748 - val_loss: 0.0645\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0716 - val_loss: 0.0644\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0710 - val_loss: 0.0653\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0705 - val_loss: 0.0651\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0702 - val_loss: 0.0678\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0698 - val_loss: 0.0667\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0704 - val_loss: 0.0665\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3778 - val_loss: 0.1578\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1519 - val_loss: 0.1302\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1180 - val_loss: 0.0911\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1027 - val_loss: 0.0841\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0946 - val_loss: 0.0745\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0901 - val_loss: 0.0705\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0838 - val_loss: 0.0702\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0812 - val_loss: 0.0665\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0811 - val_loss: 0.0668\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0787 - val_loss: 0.0766\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0820 - val_loss: 0.0767\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0787 - val_loss: 0.0668\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0785 - val_loss: 0.0696\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0753 - val_loss: 0.0660\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0746 - val_loss: 0.0657\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0793 - val_loss: 0.0659\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0763 - val_loss: 0.0659\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0771 - val_loss: 0.0740\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0743 - val_loss: 0.0655\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0757 - val_loss: 0.0653\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0728 - val_loss: 0.0657\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0733 - val_loss: 0.0662\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0753 - val_loss: 0.0657\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2728 - val_loss: 0.2252\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1991 - val_loss: 0.1980\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1638 - val_loss: 0.1466\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1362 - val_loss: 0.1168\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1165 - val_loss: 0.0929\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1018 - val_loss: 0.0790\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0913 - val_loss: 0.0747\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0937 - val_loss: 0.0722\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0902 - val_loss: 0.0732\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0867 - val_loss: 0.0779\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0870 - val_loss: 0.0687\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0855 - val_loss: 0.0712\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0861 - val_loss: 0.0764\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0817 - val_loss: 0.0699\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0811 - val_loss: 0.0677\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0876 - val_loss: 0.0723\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0814 - val_loss: 0.0709\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0807 - val_loss: 0.0740\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0801 - val_loss: 0.0677\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0842 - val_loss: 0.0673\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0767 - val_loss: 0.0676\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0804 - val_loss: 0.0681\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0841 - val_loss: 0.0725\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2538 - val_loss: 0.1363\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1388 - val_loss: 0.1269\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1185 - val_loss: 0.1005\n",
      "Epoch 4/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1023 - val_loss: 0.0867\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0964 - val_loss: 0.0860\n",
      "Epoch 6/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0949 - val_loss: 0.0778\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0913 - val_loss: 0.0738\n",
      "Epoch 8/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0955 - val_loss: 0.0731\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0915 - val_loss: 0.0778\n",
      "Epoch 10/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0810 - val_loss: 0.0753\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0829 - val_loss: 0.0708\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0906 - val_loss: 0.0761\n",
      "Epoch 13/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0802 - val_loss: 0.0723\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0822 - val_loss: 0.0709\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0850 - val_loss: 0.0732\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0807 - val_loss: 0.0719\n",
      "Epoch 17/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0787 - val_loss: 0.0731\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0804 - val_loss: 0.0880\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0871 - val_loss: 0.0701\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0826 - val_loss: 0.0719\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0780 - val_loss: 0.0833\n",
      "Epoch 22/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0823 - val_loss: 0.0747\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0801 - val_loss: 0.0727\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0760 - val_loss: 0.0755\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0825 - val_loss: 0.0739\n",
      "Epoch 26/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0739 - val_loss: 0.0711\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0745 - val_loss: 0.0806\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0766 - val_loss: 0.0717\n",
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0778 - val_loss: 0.0698\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0759 - val_loss: 0.0703\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0750 - val_loss: 0.0731\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 0.635072, val loss - 0.168914\n",
      "Epoch 2/15: loss - 0.105111, val loss - 0.086580\n",
      "Epoch 3/15: loss - 0.085819, val loss - 0.111951\n",
      "Epoch 4/15: loss - 0.082377, val loss - 0.099661\n",
      "Epoch 5/15: loss - 0.079133, val loss - 0.080903\n",
      "Epoch 6/15: loss - 0.084428, val loss - 0.095791\n",
      "Epoch 7/15: loss - 0.085543, val loss - 0.087132\n",
      "Epoch 8/15: loss - 0.073964, val loss - 0.098784\n",
      "Epoch 9/15: loss - 0.075047, val loss - 0.078813\n",
      "Epoch 10/15: loss - 0.072885, val loss - 0.077466\n",
      "Epoch 11/15: loss - 0.071740, val loss - 0.110589\n",
      "Epoch 12/15: loss - 0.072319, val loss - 0.100467\n",
      "Epoch 13/15: loss - 0.111128, val loss - 0.123768\n",
      "Epoch 14/15: loss - 0.086432, val loss - 0.099554\n",
      "Epoch 15/15: loss - 0.079757, val loss - 0.064095\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.237093, val loss - 0.128829\n",
      "Epoch 2/176: loss - 0.145725, val loss - 0.193889\n",
      "Epoch 3/176: loss - 0.140796, val loss - 0.154833\n",
      "Epoch 4/176: loss - 0.126558, val loss - 0.191358\n",
      "Epoch 5/176: loss - 0.121432, val loss - 0.189614\n",
      "Epoch 6/176: loss - 0.120848, val loss - 0.119843\n",
      "Epoch 7/176: loss - 0.097720, val loss - 0.127761\n",
      "Epoch 8/176: loss - 0.091253, val loss - 0.076299\n",
      "Epoch 9/176: loss - 0.093523, val loss - 0.077860\n",
      "Epoch 10/176: loss - 0.082476, val loss - 0.095049\n",
      "Epoch 11/176: loss - 0.084595, val loss - 0.087694\n",
      "Epoch 12/176: loss - 0.079195, val loss - 0.087715\n",
      "Epoch 13/176: loss - 0.081572, val loss - 0.095248\n",
      "Epoch 14/176: loss - 0.078424, val loss - 0.078952\n",
      "Epoch 15/176: loss - 0.074585, val loss - 0.090674\n",
      "Epoch 16/176: loss - 0.066320, val loss - 0.071318\n",
      "Epoch 17/176: loss - 0.071531, val loss - 0.113503\n",
      "Epoch 18/176: loss - 0.082538, val loss - 0.085518\n",
      "Epoch 19/176: loss - 0.076762, val loss - 0.087206\n",
      "Epoch 20/176: loss - 0.078727, val loss - 0.123281\n",
      "Epoch 21/176: loss - 0.089583, val loss - 0.107956\n",
      "Epoch 22/176: loss - 0.100833, val loss - 0.140300\n",
      "Epoch 23/176: loss - 0.109806, val loss - 0.126647\n",
      "Epoch 24/176: loss - 0.096908, val loss - 0.118555\n",
      "Epoch 25/176: loss - 0.089863, val loss - 0.131815\n",
      "Epoch 26/176: loss - 0.099332, val loss - 0.142915\n",
      "Epoch 27/176: loss - 0.092820, val loss - 0.100497\n",
      "Epoch 28/176: loss - 0.086529, val loss - 0.069543\n",
      "Epoch 29/176: loss - 0.090032, val loss - 0.093573\n",
      "Epoch 30/176: loss - 0.080038, val loss - 0.086694\n",
      "Epoch 31/176: loss - 0.086789, val loss - 0.074605\n",
      "Epoch 32/176: loss - 0.077285, val loss - 0.085577\n",
      "Epoch 33/176: loss - 0.095889, val loss - 0.135177\n",
      "Epoch 34/176: loss - 0.095709, val loss - 0.104798\n",
      "Epoch 35/176: loss - 0.090597, val loss - 0.068489\n",
      "Epoch 36/176: loss - 0.081098, val loss - 0.090551\n",
      "Epoch 37/176: loss - 0.081557, val loss - 0.079182\n",
      "Epoch 38/176: loss - 0.079321, val loss - 0.074119\n",
      "Epoch 39/176: loss - 0.074131, val loss - 0.068695\n",
      "Epoch 40/176: loss - 0.072801, val loss - 0.119185\n",
      "Epoch 41/176: loss - 0.067617, val loss - 0.076692\n",
      "Epoch 42/176: loss - 0.068543, val loss - 0.083015\n",
      "Epoch 43/176: loss - 0.064087, val loss - 0.062897\n",
      "Epoch 44/176: loss - 0.073154, val loss - 0.073254\n",
      "Epoch 45/176: loss - 0.076688, val loss - 0.071311\n",
      "Epoch 46/176: loss - 0.075176, val loss - 0.108362\n",
      "Epoch 47/176: loss - 0.072498, val loss - 0.113322\n",
      "Epoch 48/176: loss - 0.075754, val loss - 0.090980\n",
      "Epoch 49/176: loss - 0.069642, val loss - 0.084780\n",
      "Epoch 50/176: loss - 0.076585, val loss - 0.067193\n",
      "Epoch 51/176: loss - 0.064054, val loss - 0.064065\n",
      "Epoch 52/176: loss - 0.069459, val loss - 0.086052\n",
      "Epoch 53/176: loss - 0.061416, val loss - 0.067504\n",
      "Epoch 54/176: loss - 0.056208, val loss - 0.062436\n",
      "Epoch 55/176: loss - 0.055242, val loss - 0.065273\n",
      "Epoch 56/176: loss - 0.055436, val loss - 0.072598\n",
      "Epoch 57/176: loss - 0.050315, val loss - 0.064033\n",
      "Epoch 58/176: loss - 0.063671, val loss - 0.095548\n",
      "Epoch 59/176: loss - 0.069989, val loss - 0.064221\n",
      "Epoch 60/176: loss - 0.063306, val loss - 0.059456\n",
      "Epoch 61/176: loss - 0.065721, val loss - 0.088133\n",
      "Epoch 62/176: loss - 0.058652, val loss - 0.064154\n",
      "Epoch 63/176: loss - 0.059351, val loss - 0.053460\n",
      "Epoch 64/176: loss - 0.055409, val loss - 0.074280\n",
      "Epoch 65/176: loss - 0.054042, val loss - 0.076321\n",
      "Epoch 66/176: loss - 0.063966, val loss - 0.062580\n",
      "Epoch 67/176: loss - 0.054029, val loss - 0.061461\n",
      "Epoch 68/176: loss - 0.059080, val loss - 0.071369\n",
      "Epoch 69/176: loss - 0.061619, val loss - 0.076738\n",
      "Epoch 70/176: loss - 0.055025, val loss - 0.067832\n",
      "Epoch 71/176: loss - 0.051155, val loss - 0.068126\n",
      "Epoch 72/176: loss - 0.051629, val loss - 0.063884\n",
      "Epoch 73/176: loss - 0.052871, val loss - 0.054896\n",
      "Epoch 74/176: loss - 0.049594, val loss - 0.058186\n",
      "Epoch 75/176: loss - 0.054351, val loss - 0.066796\n",
      "Epoch 76/176: loss - 0.047408, val loss - 0.056896\n",
      "Epoch 77/176: loss - 0.050877, val loss - 0.071742\n",
      "Epoch 78/176: loss - 0.057886, val loss - 0.069783\n",
      "Epoch 79/176: loss - 0.053637, val loss - 0.069281\n",
      "Epoch 80/176: loss - 0.061232, val loss - 0.068869\n",
      "Epoch 81/176: loss - 0.055841, val loss - 0.060628\n",
      "Epoch 82/176: loss - 0.061729, val loss - 0.080696\n",
      "Epoch 83/176: loss - 0.060030, val loss - 0.054674\n",
      "Epoch 84/176: loss - 0.053451, val loss - 0.073830\n",
      "Epoch 85/176: loss - 0.053101, val loss - 0.073504\n",
      "Epoch 86/176: loss - 0.052957, val loss - 0.078752\n",
      "Epoch 87/176: loss - 0.053917, val loss - 0.070739\n",
      "Epoch 88/176: loss - 0.054964, val loss - 0.059122\n",
      "Epoch 89/176: loss - 0.049550, val loss - 0.056443\n",
      "Epoch 90/176: loss - 0.046688, val loss - 0.069706\n",
      "Epoch 91/176: loss - 0.052477, val loss - 0.060548\n",
      "Epoch 92/176: loss - 0.050970, val loss - 0.067671\n",
      "Epoch 93/176: loss - 0.048614, val loss - 0.073108\n",
      "Epoch 94/176: loss - 0.052261, val loss - 0.071804\n",
      "Epoch 95/176: loss - 0.048544, val loss - 0.071810\n",
      "Epoch 96/176: loss - 0.047485, val loss - 0.059029\n",
      "Epoch 97/176: loss - 0.047853, val loss - 0.071649\n",
      "Epoch 98/176: loss - 0.051037, val loss - 0.062439\n",
      "Epoch 99/176: loss - 0.053260, val loss - 0.064863\n",
      "Epoch 100/176: loss - 0.056523, val loss - 0.078231\n",
      "Epoch 101/176: loss - 0.054439, val loss - 0.076563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/176: loss - 0.056018, val loss - 0.055581\n",
      "Epoch 103/176: loss - 0.052749, val loss - 0.067603\n",
      "Epoch 104/176: loss - 0.051399, val loss - 0.070877\n",
      "Epoch 105/176: loss - 0.053199, val loss - 0.058743\n",
      "Epoch 106/176: loss - 0.054946, val loss - 0.066586\n",
      "Epoch 107/176: loss - 0.047480, val loss - 0.072456\n",
      "Epoch 108/176: loss - 0.049666, val loss - 0.065383\n",
      "Epoch 109/176: loss - 0.050206, val loss - 0.087069\n",
      "Epoch 110/176: loss - 0.050936, val loss - 0.068552\n",
      "Epoch 111/176: loss - 0.057280, val loss - 0.064525\n",
      "Epoch 112/176: loss - 0.055536, val loss - 0.052535\n",
      "Epoch 113/176: loss - 0.048805, val loss - 0.066083\n",
      "Epoch 114/176: loss - 0.047729, val loss - 0.069509\n",
      "Epoch 115/176: loss - 0.048911, val loss - 0.059162\n",
      "Epoch 116/176: loss - 0.049792, val loss - 0.075346\n",
      "Epoch 117/176: loss - 0.055878, val loss - 0.086891\n",
      "Epoch 118/176: loss - 0.059548, val loss - 0.071343\n",
      "Epoch 119/176: loss - 0.058338, val loss - 0.077900\n",
      "Epoch 120/176: loss - 0.063435, val loss - 0.075892\n",
      "Epoch 121/176: loss - 0.054265, val loss - 0.076926\n",
      "Epoch 122/176: loss - 0.056423, val loss - 0.066499\n",
      "Epoch 123/176: loss - 0.052214, val loss - 0.070185\n",
      "Epoch 124/176: loss - 0.052868, val loss - 0.076429\n",
      "Epoch 125/176: loss - 0.053064, val loss - 0.068356\n",
      "Epoch 126/176: loss - 0.051318, val loss - 0.059471\n",
      "Epoch 127/176: loss - 0.050722, val loss - 0.071404\n",
      "Epoch 128/176: loss - 0.051896, val loss - 0.064877\n",
      "Epoch 129/176: loss - 0.049338, val loss - 0.079165\n",
      "Epoch 130/176: loss - 0.054130, val loss - 0.063545\n",
      "Epoch 131/176: loss - 0.049756, val loss - 0.070914\n",
      "Epoch 132/176: loss - 0.052959, val loss - 0.065136\n",
      "Epoch 133/176: loss - 0.046543, val loss - 0.062768\n",
      "Epoch 134/176: loss - 0.054117, val loss - 0.071486\n",
      "Epoch 135/176: loss - 0.048272, val loss - 0.061466\n",
      "Epoch 136/176: loss - 0.053458, val loss - 0.067967\n",
      "Epoch 137/176: loss - 0.052689, val loss - 0.059636\n",
      "Epoch 138/176: loss - 0.048670, val loss - 0.073621\n",
      "Epoch 139/176: loss - 0.046966, val loss - 0.067456\n",
      "Epoch 140/176: loss - 0.051044, val loss - 0.057726\n",
      "Epoch 141/176: loss - 0.049571, val loss - 0.065546\n",
      "Epoch 142/176: loss - 0.048513, val loss - 0.060304\n",
      "Epoch 143/176: loss - 0.049353, val loss - 0.061150\n",
      "Epoch 144/176: loss - 0.047770, val loss - 0.071226\n",
      "Epoch 145/176: loss - 0.046873, val loss - 0.063336\n",
      "Epoch 146/176: loss - 0.046718, val loss - 0.057148\n",
      "Epoch 147/176: loss - 0.045683, val loss - 0.058948\n",
      "Epoch 148/176: loss - 0.051403, val loss - 0.078959\n",
      "Epoch 149/176: loss - 0.049873, val loss - 0.059547\n",
      "Epoch 150/176: loss - 0.047051, val loss - 0.059651\n",
      "Epoch 151/176: loss - 0.045197, val loss - 0.068202\n",
      "Epoch 152/176: loss - 0.045410, val loss - 0.057084\n",
      "Epoch 153/176: loss - 0.046402, val loss - 0.074923\n",
      "Epoch 154/176: loss - 0.049160, val loss - 0.062580\n",
      "Epoch 155/176: loss - 0.044279, val loss - 0.060382\n",
      "Epoch 156/176: loss - 0.045453, val loss - 0.062163\n",
      "Epoch 157/176: loss - 0.043185, val loss - 0.058316\n",
      "Epoch 158/176: loss - 0.047549, val loss - 0.067159\n",
      "Epoch 159/176: loss - 0.045295, val loss - 0.057401\n",
      "Epoch 160/176: loss - 0.044807, val loss - 0.059369\n",
      "Epoch 161/176: loss - 0.048064, val loss - 0.056648\n",
      "Epoch 162/176: loss - 0.043133, val loss - 0.060785\n",
      "Epoch 163/176: loss - 0.042973, val loss - 0.056045\n",
      "Epoch 164/176: loss - 0.046218, val loss - 0.059776\n",
      "Epoch 165/176: loss - 0.041973, val loss - 0.055437\n",
      "Epoch 166/176: loss - 0.043596, val loss - 0.057818\n",
      "Epoch 167/176: loss - 0.042281, val loss - 0.060869\n",
      "Epoch 168/176: loss - 0.044946, val loss - 0.060953\n",
      "Epoch 169/176: loss - 0.045277, val loss - 0.069110\n",
      "Epoch 170/176: loss - 0.049441, val loss - 0.075275\n",
      "Epoch 171/176: loss - 0.049116, val loss - 0.072308\n",
      "Epoch 172/176: loss - 0.048976, val loss - 0.063763\n",
      "Epoch 173/176: loss - 0.049600, val loss - 0.063512\n",
      "Epoch 174/176: loss - 0.043473, val loss - 0.054030\n",
      "Epoch 175/176: loss - 0.046549, val loss - 0.057177\n",
      "Epoch 176/176: loss - 0.043871, val loss - 0.057126\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.161236, val loss - 0.197403\n",
      "Epoch 2/24: loss - 0.128008, val loss - 0.284346\n",
      "Epoch 3/24: loss - 0.139525, val loss - 0.140741\n",
      "Epoch 4/24: loss - 0.123390, val loss - 0.115041\n",
      "Epoch 5/24: loss - 0.124491, val loss - 0.165647\n",
      "Epoch 6/24: loss - 0.109004, val loss - 0.181264\n",
      "Epoch 7/24: loss - 0.125440, val loss - 0.151128\n",
      "Epoch 8/24: loss - 0.104907, val loss - 0.165022\n",
      "Epoch 9/24: loss - 0.096061, val loss - 0.115734\n",
      "Epoch 10/24: loss - 0.095982, val loss - 0.125418\n",
      "Epoch 11/24: loss - 0.093171, val loss - 0.124712\n",
      "Epoch 12/24: loss - 0.091412, val loss - 0.114536\n",
      "Epoch 13/24: loss - 0.087219, val loss - 0.131334\n",
      "Epoch 14/24: loss - 0.090659, val loss - 0.112547\n",
      "Epoch 15/24: loss - 0.090903, val loss - 0.083892\n",
      "Epoch 16/24: loss - 0.083136, val loss - 0.113665\n",
      "Epoch 17/24: loss - 0.080332, val loss - 0.086954\n",
      "Epoch 18/24: loss - 0.079661, val loss - 0.107668\n",
      "Epoch 19/24: loss - 0.082652, val loss - 0.091958\n",
      "Epoch 20/24: loss - 0.084000, val loss - 0.093380\n",
      "Epoch 21/24: loss - 0.081199, val loss - 0.079820\n",
      "Epoch 22/24: loss - 0.079346, val loss - 0.093873\n",
      "Epoch 23/24: loss - 0.077392, val loss - 0.089919\n",
      "Epoch 24/24: loss - 0.075994, val loss - 0.084454\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.258994, val loss - 0.147514\n",
      "Epoch 2/66: loss - 0.121424, val loss - 0.123928\n",
      "Epoch 3/66: loss - 0.120299, val loss - 0.149539\n",
      "Epoch 4/66: loss - 0.108764, val loss - 0.140364\n",
      "Epoch 5/66: loss - 0.104878, val loss - 0.146740\n",
      "Epoch 6/66: loss - 0.101451, val loss - 0.133844\n",
      "Epoch 7/66: loss - 0.090503, val loss - 0.102754\n",
      "Epoch 8/66: loss - 0.090480, val loss - 0.106809\n",
      "Epoch 9/66: loss - 0.092041, val loss - 0.087201\n",
      "Epoch 10/66: loss - 0.080520, val loss - 0.117798\n",
      "Epoch 11/66: loss - 0.086414, val loss - 0.085827\n",
      "Epoch 12/66: loss - 0.080490, val loss - 0.102421\n",
      "Epoch 13/66: loss - 0.084500, val loss - 0.076965\n",
      "Epoch 14/66: loss - 0.075481, val loss - 0.069624\n",
      "Epoch 15/66: loss - 0.075479, val loss - 0.080393\n",
      "Epoch 16/66: loss - 0.079731, val loss - 0.072102\n",
      "Epoch 17/66: loss - 0.079122, val loss - 0.074529\n",
      "Epoch 18/66: loss - 0.075546, val loss - 0.072766\n",
      "Epoch 19/66: loss - 0.077398, val loss - 0.074746\n",
      "Epoch 20/66: loss - 0.073237, val loss - 0.088188\n",
      "Epoch 21/66: loss - 0.073632, val loss - 0.085931\n",
      "Epoch 22/66: loss - 0.073078, val loss - 0.082762\n",
      "Epoch 23/66: loss - 0.073981, val loss - 0.097041\n",
      "Epoch 24/66: loss - 0.071918, val loss - 0.080783\n",
      "Epoch 25/66: loss - 0.070634, val loss - 0.087079\n",
      "Epoch 26/66: loss - 0.072809, val loss - 0.083226\n",
      "Epoch 27/66: loss - 0.069707, val loss - 0.081102\n",
      "Epoch 28/66: loss - 0.071482, val loss - 0.087531\n",
      "Epoch 29/66: loss - 0.069276, val loss - 0.079125\n",
      "Epoch 30/66: loss - 0.073512, val loss - 0.074747\n",
      "Epoch 31/66: loss - 0.070842, val loss - 0.090645\n",
      "Epoch 32/66: loss - 0.068638, val loss - 0.080151\n",
      "Epoch 33/66: loss - 0.069332, val loss - 0.079500\n",
      "Epoch 34/66: loss - 0.070419, val loss - 0.084042\n",
      "Epoch 35/66: loss - 0.066061, val loss - 0.082373\n",
      "Epoch 36/66: loss - 0.071754, val loss - 0.082176\n",
      "Epoch 37/66: loss - 0.068318, val loss - 0.080598\n",
      "Epoch 38/66: loss - 0.068406, val loss - 0.089274\n",
      "Epoch 39/66: loss - 0.067750, val loss - 0.103993\n",
      "Epoch 40/66: loss - 0.067338, val loss - 0.086222\n",
      "Epoch 41/66: loss - 0.067824, val loss - 0.076650\n",
      "Epoch 42/66: loss - 0.068102, val loss - 0.086445\n",
      "Epoch 43/66: loss - 0.069640, val loss - 0.080866\n",
      "Epoch 44/66: loss - 0.066116, val loss - 0.072924\n",
      "Epoch 45/66: loss - 0.066219, val loss - 0.083051\n",
      "Epoch 46/66: loss - 0.066603, val loss - 0.074161\n",
      "Epoch 47/66: loss - 0.064411, val loss - 0.073518\n",
      "Epoch 48/66: loss - 0.067485, val loss - 0.079239\n",
      "Epoch 49/66: loss - 0.064199, val loss - 0.087744\n",
      "Epoch 50/66: loss - 0.066769, val loss - 0.073880\n",
      "Epoch 51/66: loss - 0.065127, val loss - 0.077765\n",
      "Epoch 52/66: loss - 0.064276, val loss - 0.075505\n",
      "Epoch 53/66: loss - 0.063343, val loss - 0.087609\n",
      "Epoch 54/66: loss - 0.067275, val loss - 0.075487\n",
      "Epoch 55/66: loss - 0.065951, val loss - 0.071999\n",
      "Epoch 56/66: loss - 0.063218, val loss - 0.076217\n",
      "Epoch 57/66: loss - 0.063626, val loss - 0.089290\n",
      "Epoch 58/66: loss - 0.064223, val loss - 0.071504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/66: loss - 0.064216, val loss - 0.080195\n",
      "Epoch 60/66: loss - 0.066434, val loss - 0.087206\n",
      "Epoch 61/66: loss - 0.067605, val loss - 0.073837\n",
      "Epoch 62/66: loss - 0.062061, val loss - 0.082324\n",
      "Epoch 63/66: loss - 0.062477, val loss - 0.088814\n",
      "Epoch 64/66: loss - 0.065636, val loss - 0.071197\n",
      "Epoch 65/66: loss - 0.064589, val loss - 0.076691\n",
      "Epoch 66/66: loss - 0.062591, val loss - 0.082364\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.199074, val loss - 0.189623\n",
      "Epoch 2/24: loss - 0.135335, val loss - 0.140339\n",
      "Epoch 3/24: loss - 0.125621, val loss - 0.179563\n",
      "Epoch 4/24: loss - 0.117392, val loss - 0.150840\n",
      "Epoch 5/24: loss - 0.125677, val loss - 0.165553\n",
      "Epoch 6/24: loss - 0.119776, val loss - 0.173646\n",
      "Epoch 7/24: loss - 0.109000, val loss - 0.110876\n",
      "Epoch 8/24: loss - 0.095174, val loss - 0.181885\n",
      "Epoch 9/24: loss - 0.097499, val loss - 0.149368\n",
      "Epoch 10/24: loss - 0.107228, val loss - 0.086270\n",
      "Epoch 11/24: loss - 0.085669, val loss - 0.126410\n",
      "Epoch 12/24: loss - 0.088551, val loss - 0.102917\n",
      "Epoch 13/24: loss - 0.086476, val loss - 0.110800\n",
      "Epoch 14/24: loss - 0.077329, val loss - 0.104900\n",
      "Epoch 15/24: loss - 0.078404, val loss - 0.107221\n",
      "Epoch 16/24: loss - 0.074765, val loss - 0.116897\n",
      "Epoch 17/24: loss - 0.078226, val loss - 0.097202\n",
      "Epoch 18/24: loss - 0.076896, val loss - 0.094334\n",
      "Epoch 19/24: loss - 0.076174, val loss - 0.098631\n",
      "Epoch 20/24: loss - 0.081391, val loss - 0.098058\n",
      "Epoch 21/24: loss - 0.073999, val loss - 0.102513\n",
      "Epoch 22/24: loss - 0.073731, val loss - 0.089820\n",
      "Epoch 23/24: loss - 0.073583, val loss - 0.095776\n",
      "Epoch 24/24: loss - 0.074317, val loss - 0.089183\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1928 - val_loss: 0.0993\n",
      "Epoch 2/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0919 - val_loss: 0.0702\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0760 - val_loss: 0.0694\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0723 - val_loss: 0.0671\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0715 - val_loss: 0.0667\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0667 - val_loss: 0.0616\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0651 - val_loss: 0.0604\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0591 - val_loss: 0.0607\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0574 - val_loss: 0.0608\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0568 - val_loss: 0.0563\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0542 - val_loss: 0.0539\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0542 - val_loss: 0.0599\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0490 - val_loss: 0.0531\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0529 - val_loss: 0.0515\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0476 - val_loss: 0.0533\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0480 - val_loss: 0.0538\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0499 - val_loss: 0.0483\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0440 - val_loss: 0.0558\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0458 - val_loss: 0.0525\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.0481\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0408 - val_loss: 0.0478\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.0549\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0493\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.0457\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0378 - val_loss: 0.0484\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.0519\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0406 - val_loss: 0.0474\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2028 - val_loss: 0.1155\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1260 - val_loss: 0.0970\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1027 - val_loss: 0.0958\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0882 - val_loss: 0.0739\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0805 - val_loss: 0.0706\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0740 - val_loss: 0.0750\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0719 - val_loss: 0.0680\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0687 - val_loss: 0.0892\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0733 - val_loss: 0.0658\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0693 - val_loss: 0.0602\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0647 - val_loss: 0.0605\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0644 - val_loss: 0.0678\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.0574\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0563 - val_loss: 0.0554\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0525 - val_loss: 0.0613\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0512 - val_loss: 0.0555\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0505 - val_loss: 0.0610\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.0594\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0526 - val_loss: 0.0592\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0489 - val_loss: 0.0598\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0550 - val_loss: 0.0646\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0486 - val_loss: 0.0696\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.0671\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0579 - val_loss: 0.0674\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0524 - val_loss: 0.0558\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0513 - val_loss: 0.0559\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0446 - val_loss: 0.0615\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0478 - val_loss: 0.0590\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0459 - val_loss: 0.0691\n",
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0427 - val_loss: 0.0578\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0490 - val_loss: 0.0596\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0532 - val_loss: 0.0612\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.0590\n",
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0427 - val_loss: 0.0560\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0408 - val_loss: 0.0838\n",
      "Epoch 1/29\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3080 - val_loss: 0.1445\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1219 - val_loss: 0.1113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0983 - val_loss: 0.0778\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0824 - val_loss: 0.0701\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0734 - val_loss: 0.0659\n",
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0677 - val_loss: 0.0689\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0650 - val_loss: 0.0634\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.0697\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0728 - val_loss: 0.0667\n",
      "Epoch 10/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0600 - val_loss: 0.0675\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0708 - val_loss: 0.0618\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0557 - val_loss: 0.0659\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0587 - val_loss: 0.0612\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0544 - val_loss: 0.0864\n",
      "Epoch 15/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0525 - val_loss: 0.0602\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0490 - val_loss: 0.0770\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0496 - val_loss: 0.0586\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0476 - val_loss: 0.0709\n",
      "Epoch 19/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0562 - val_loss: 0.0572\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0593 - val_loss: 0.0588\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0464 - val_loss: 0.0629\n",
      "Epoch 22/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0475 - val_loss: 0.0578\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0465 - val_loss: 0.0544\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0494 - val_loss: 0.0548\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0450 - val_loss: 0.0555\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0433 - val_loss: 0.0778\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0441 - val_loss: 0.0604\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0470 - val_loss: 0.0537\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0485 - val_loss: 0.0559\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2824 - val_loss: 0.1893\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1303 - val_loss: 0.1085\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1025 - val_loss: 0.0804\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0736\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0777 - val_loss: 0.0711\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0741 - val_loss: 0.0626\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0760 - val_loss: 0.0750\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0766 - val_loss: 0.1018\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0759 - val_loss: 0.0630\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0692 - val_loss: 0.0805\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0688 - val_loss: 0.0623\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0652 - val_loss: 0.0625\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0660 - val_loss: 0.0579\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0668 - val_loss: 0.1111\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0688 - val_loss: 0.0576\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0642 - val_loss: 0.0621\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0587\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0671 - val_loss: 0.0791\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0622 - val_loss: 0.0600\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0649\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0583 - val_loss: 0.0671\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0612 - val_loss: 0.0605\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0686\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0567 - val_loss: 0.0594\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0551 - val_loss: 0.0587\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0509 - val_loss: 0.0579\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0497 - val_loss: 0.0616\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0536 - val_loss: 0.0679\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0572 - val_loss: 0.0564\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0465 - val_loss: 0.0575\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0536 - val_loss: 0.0727\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0450 - val_loss: 0.0585\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0540 - val_loss: 0.0861\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.0587\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.7174 - val_loss: 0.6036\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3565 - val_loss: 0.2934\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1800 - val_loss: 0.1664\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1371 - val_loss: 0.1409\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1360 - val_loss: 0.1367\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1317 - val_loss: 0.1379\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1292 - val_loss: 0.1353\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1267 - val_loss: 0.1336\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1244 - val_loss: 0.1284\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1223 - val_loss: 0.1276\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 0.1229\n",
      "Epoch 12/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1179 - val_loss: 0.1201\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.1197\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1141 - val_loss: 0.1172\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1123 - val_loss: 0.1139\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1110 - val_loss: 0.1141\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1092 - val_loss: 0.1078\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1068 - val_loss: 0.1081\n",
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1052 - val_loss: 0.1065\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1034 - val_loss: 0.1028\n",
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1016 - val_loss: 0.0996\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1003 - val_loss: 0.0980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0985 - val_loss: 0.0958\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0965 - val_loss: 0.0949\n",
      "Epoch 25/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0949 - val_loss: 0.0923\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0932 - val_loss: 0.0893\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0917 - val_loss: 0.0882\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0903 - val_loss: 0.0857\n",
      "Epoch 29/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0886 - val_loss: 0.0844\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0879 - val_loss: 0.0836\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0862 - val_loss: 0.0796\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0854 - val_loss: 0.0810\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0780\n",
      "Epoch 34/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0829 - val_loss: 0.0775\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0823 - val_loss: 0.0781\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0810 - val_loss: 0.0748\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0798 - val_loss: 0.0760\n",
      "Epoch 38/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0796 - val_loss: 0.0741\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0781 - val_loss: 0.0735\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0775 - val_loss: 0.0730\n",
      "Epoch 41/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0717\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0765 - val_loss: 0.0730\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0758 - val_loss: 0.0697\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0759 - val_loss: 0.0750\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0751 - val_loss: 0.0701\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0745 - val_loss: 0.0687\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0741 - val_loss: 0.0714\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0739 - val_loss: 0.0711\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0733 - val_loss: 0.0683\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0730 - val_loss: 0.0705\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0733 - val_loss: 0.0709\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0725 - val_loss: 0.0694\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0727 - val_loss: 0.0705\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0719 - val_loss: 0.0698\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0724 - val_loss: 0.0717\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0717 - val_loss: 0.0677\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0711 - val_loss: 0.0694\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0709 - val_loss: 0.0691\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0708 - val_loss: 0.0672\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0703 - val_loss: 0.0690\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0704 - val_loss: 0.0704\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0700 - val_loss: 0.0676\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0696 - val_loss: 0.0690\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0692 - val_loss: 0.0677\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0691 - val_loss: 0.0674\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0689 - val_loss: 0.0692\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0688 - val_loss: 0.0696\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0684 - val_loss: 0.0688\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0683 - val_loss: 0.0669\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0681 - val_loss: 0.0668\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0688 - val_loss: 0.0710\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0673 - val_loss: 0.0674\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0670 - val_loss: 0.0681\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0672 - val_loss: 0.0747\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0676 - val_loss: 0.0671\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0666 - val_loss: 0.0691\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.0712\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0668 - val_loss: 0.0683\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0661 - val_loss: 0.0676\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0665 - val_loss: 0.0706\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0665 - val_loss: 0.0710\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0664 - val_loss: 0.0721\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0662 - val_loss: 0.0675\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.0701\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0655 - val_loss: 0.0673\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0657 - val_loss: 0.0679\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0641 - val_loss: 0.0723\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0643 - val_loss: 0.0684\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0664 - val_loss: 0.0699\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0648 - val_loss: 0.0708\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0643 - val_loss: 0.0714\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.0714\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.0681\n",
      "Epoch 94/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0634 - val_loss: 0.0711\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0635 - val_loss: 0.0706\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0633 - val_loss: 0.0721\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0624 - val_loss: 0.0688\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0623 - val_loss: 0.0702\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0622 - val_loss: 0.0693\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0623 - val_loss: 0.0691\n",
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0618 - val_loss: 0.0736\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0629 - val_loss: 0.0695\n",
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0627 - val_loss: 0.0699\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0617 - val_loss: 0.0738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0696\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0731\n",
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0735\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0617 - val_loss: 0.0748\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2985 - val_loss: 0.1483\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1359 - val_loss: 0.1154\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.0943\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.0808\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0807\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0697\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0687\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0664\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0677\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0616\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0624\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0594\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0585\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0638 - val_loss: 0.0596\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0600\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0565\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0567\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0568\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0587\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0591\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0564\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0561\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0577\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0604\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0560\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0562\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0592\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0617\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0688\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0556\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0619\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0631\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0566\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0610\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2523 - val_loss: 0.1264\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1325 - val_loss: 0.1247\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.1144\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1131 - val_loss: 0.1040\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.1013\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.0827\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0796\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.0736\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.0760\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0734\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0716\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0711\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0719\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0731\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0718\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0705\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0709\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0699\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0716 - val_loss: 0.0725\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0707\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0866\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0754\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0684\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0771\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0686\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0681\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0758\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0954\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0909\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0758\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0776\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0783\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0711\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0878\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0892\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0791\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1943 - val_loss: 0.1843\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1605 - val_loss: 0.1650\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1524 - val_loss: 0.1579\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1454 - val_loss: 0.1527\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1390 - val_loss: 0.1448\n",
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1331 - val_loss: 0.1376\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.1305\n",
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1205 - val_loss: 0.1221\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.1133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1057 - val_loss: 0.1053\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0962\n",
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0906\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0840\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0823\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0822\n",
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0813\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0808\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0832\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0793\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0802\n",
      "Epoch 21/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.0804\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0825\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0788\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0787\n",
      "Epoch 25/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0807\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0773\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0789\n",
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0774\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0789\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0772\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0807\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0767\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0780\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0764\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0790\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.0789\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0788\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0760\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0768\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0796\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0777\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0795\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0770\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0776\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0773\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0774\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0801\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0821\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0792\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0773\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0834\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0794\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0844\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0784\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0768\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0796\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0837\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0783\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0769\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0858\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0763\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0766\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0837\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0644 - val_loss: 0.0766\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0775\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0646 - val_loss: 0.0763\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0644 - val_loss: 0.0788\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0789\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0785\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0638 - val_loss: 0.0784\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0789\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2670 - val_loss: 0.2384\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1639\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1491 - val_loss: 0.1543\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1427 - val_loss: 0.1540\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1357 - val_loss: 0.1447\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1352\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 0.1252\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.1074\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0984 - val_loss: 0.1001\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0917 - val_loss: 0.0958\n",
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0866\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.0897\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0828\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0858\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0792\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0852\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0792\n",
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0829\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0763\n",
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0785\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0734 - val_loss: 0.0793\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0784\n",
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0723 - val_loss: 0.0752\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0793\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0723 - val_loss: 0.0733\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0751\n",
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0734\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0750\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0733\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0738\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0733\n",
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0733\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0714\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0763\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0723\n",
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0739\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0730\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0728\n",
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0729\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0731\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0761\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0706\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0722\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0720\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0711\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0717\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0783\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0716\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0706\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0767\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0707\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0754\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0705\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0723\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0723\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0737\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0721\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0700\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0765\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0710\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0693\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0719\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2556 - val_loss: 0.1788\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1446 - val_loss: 0.1354\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1146 - val_loss: 0.1154\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0748\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0804\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0735\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0839\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0754\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.0705\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0676\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.0681\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0724\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0775\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0687\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0717\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0681\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0697\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0956\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0687\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0643 - val_loss: 0.0703\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0740\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0638 - val_loss: 0.0751\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0714\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0719\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.0760\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0709\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5465 - val_loss: 0.2190\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.1244\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1096 - val_loss: 0.1137\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.0991\n",
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.0967\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0911 - val_loss: 0.0923\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0890\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.0852\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0851\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0808\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0804\n",
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0785\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0764\n",
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0764\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0744\n",
      "Epoch 17/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0733\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0761\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0716\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0714\n",
      "Epoch 21/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0731\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0704\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0698\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0720\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0689\n",
      "Epoch 26/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0704\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0689\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0686\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0678\n",
      "Epoch 30/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0677\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0711\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0680\n",
      "Epoch 33/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0675\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0670\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0724\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0685\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0668\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0681\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0666\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0663\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0665\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0659\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0680\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0672\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0653\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0681\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0669\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0642\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0659\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0744\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0645\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0645\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0651\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0657\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0657\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0648\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0647\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0638\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0682\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0631\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0636\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0635\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0676\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0632\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0634\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0630\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0653\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0672\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0627\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0654\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0628\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0655\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0643\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0621\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0670\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0689\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0631\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0623\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0643\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0631\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0646\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0634\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0621\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0630\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0646\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0639\n",
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0656\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0640\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0647\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0641\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0627\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0673\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0661\n",
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0626\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0621\n",
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0651\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0657\n",
      "Epoch 99/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0655\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0637\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0616\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0628\n",
      "Epoch 103/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0629\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0654\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0642\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0621\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0658\n",
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0640\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0667\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0633\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0634\n",
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0641\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0716\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0656\n",
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0643\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0695\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0646\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0630\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0637\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0716\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0641\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0645\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0637\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0685\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0653\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0633\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0670\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0741\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0635\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0711\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0653\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0672\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0649\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0703\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0639\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0661\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0644\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0702\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.5496 - val_loss: 1.1508\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7374 - val_loss: 0.6033\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.3645\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2463 - val_loss: 0.2613\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1909 - val_loss: 0.2086\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1627 - val_loss: 0.1803\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1478 - val_loss: 0.1637\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1393 - val_loss: 0.1534\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1341 - val_loss: 0.1457\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1303 - val_loss: 0.1408\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1272 - val_loss: 0.1356\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1249 - val_loss: 0.1318\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1292\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 0.1260\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1194 - val_loss: 0.1238\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.1224\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.1207\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1194\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.1170\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1129 - val_loss: 0.1164\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.1133\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.1131\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1116\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1080\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1064 - val_loss: 0.1076\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1037\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.1018\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.0996\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.0959\n",
      "Epoch 30/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.0926\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0922 - val_loss: 0.0904\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0867\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0834\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0821\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0832\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0809\n",
      "Epoch 37/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0813\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0817\n",
      "Epoch 39/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0800\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0801\n",
      "Epoch 41/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0801\n",
      "Epoch 42/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0799\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0814\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0801\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0801\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0816\n",
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0792\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0810\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0798\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0877\n",
      "Epoch 51/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0795\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0829\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0795\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0804\n",
      "Epoch 55/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0791\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0820\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0795\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0823\n",
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0811\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0791\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0839\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0791\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0846\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0790\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0806\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0797\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0834\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0793\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0796\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0815\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0798\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0830\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0801\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0793\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0860\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0817\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0804\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0805\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0801\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0817\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0825\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0802\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0795\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0819\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0815\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0800\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0817\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0793\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0829\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0800\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0813\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0819\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0793\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0802\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0804\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0789\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0815\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0819\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0797\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0825\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0801\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0788\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0797\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0797\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0787\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0819\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0790\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0807\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0815\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0836\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0791\n",
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0790\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0826\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0796\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0813\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0827\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0790\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0791\n",
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0796\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0799\n",
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0806\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0796\n",
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0844\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0789\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0808\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0824\n",
      "Epoch 128/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0848\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0786\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0819\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0820\n",
      "Epoch 132/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0799\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0826\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0830\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0792\n",
      "Epoch 136/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0878\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0793\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0791\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0788\n",
      "Epoch 140/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0841\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0800\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0823\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0797\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0787\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0856\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0820\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0798\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0794\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0818\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2193 - val_loss: 0.1588\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1254\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.1572\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1124 - val_loss: 0.1252\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.0905\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0939\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0824\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0812\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0829\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0893\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0860\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0858\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0938\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0930\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0825\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0797\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0864\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0804\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0808\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0805\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0808\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0834\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0803\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0796\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0957\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0831\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0814\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0792\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0798\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0843\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0840\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0807\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0844\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0883\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0885\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0862\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0823\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0871\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0908\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0922\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0816\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0853\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0924\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0816\n",
      "Epoch 45/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0892\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0840\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0869\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0825\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0848\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0853\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0837\n",
      "Epoch 52/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0855\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0898\n",
      "Epoch 54/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.1006\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0897\n",
      "Epoch 56/56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0782\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.7788 - val_loss: 0.4209\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2723 - val_loss: 0.2612\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2370 - val_loss: 0.2327\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2053 - val_loss: 0.2211\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1841 - val_loss: 0.2012\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1685 - val_loss: 0.1820\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1568 - val_loss: 0.1744\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1463 - val_loss: 0.1566\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1500\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1420\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1317\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.1287\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1116 - val_loss: 0.1198\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.1162\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.1101\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.1136\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 0.1080\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1017 - val_loss: 0.1095\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1018\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.1049\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.1020\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.1100\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0976 - val_loss: 0.1000\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.1019\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.1004\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0968\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.0986\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.0953\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.0967\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0956\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.0968\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0952\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0933\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.0933\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.0954\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0919\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.0979\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0920\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0934\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0918\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0929\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.0924\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0893\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0921\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0901\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0899\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0923\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.0954\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0892\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0884\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0959\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0877\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0940\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0861\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0924\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0872\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0931\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0877\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0867\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0932\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2814 - val_loss: 0.1436\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1416\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1444 - val_loss: 0.1373\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1359 - val_loss: 0.1235\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1289 - val_loss: 0.1212\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1222 - val_loss: 0.1176\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.1078\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1127 - val_loss: 0.1056\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1032\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1053 - val_loss: 0.0946\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.0934\n",
      "Epoch 12/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.0898\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.0880\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0945 - val_loss: 0.0870\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0926 - val_loss: 0.0840\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.0786\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0896\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.0824\n",
      "Epoch 19/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0758\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0823\n",
      "Epoch 21/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0767\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0723\n",
      "Epoch 23/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0819\n",
      "Epoch 24/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0810\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0768\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0737\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0769\n",
      "Epoch 28/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0739\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0706\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0720\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0779\n",
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0698\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0767\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0699\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0724\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0752\n",
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0752\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0787\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0712\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0746\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0700\n",
      "Epoch 1/47\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.3388 - val_loss: 0.1840\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1700 - val_loss: 0.1287\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1293 - val_loss: 0.1022\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1119 - val_loss: 0.0878\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0995 - val_loss: 0.0804\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0913 - val_loss: 0.0770\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0892 - val_loss: 0.0758\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0837 - val_loss: 0.0735\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0851 - val_loss: 0.0722\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0839 - val_loss: 0.0699\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0791 - val_loss: 0.0688\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0767 - val_loss: 0.0687\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0774 - val_loss: 0.0685\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0782 - val_loss: 0.0682\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0739 - val_loss: 0.0670\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0771 - val_loss: 0.0756\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0737 - val_loss: 0.0679\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0723 - val_loss: 0.0663\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0658\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0766 - val_loss: 0.0651\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0715 - val_loss: 0.0648\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0704 - val_loss: 0.0653\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0702 - val_loss: 0.0649\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0701 - val_loss: 0.0650\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0696 - val_loss: 0.0642\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0730 - val_loss: 0.0643\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0665\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0704 - val_loss: 0.0632\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0743 - val_loss: 0.0685\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0684 - val_loss: 0.0627\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0671 - val_loss: 0.0680\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0691 - val_loss: 0.0620\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0667 - val_loss: 0.0628\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0677 - val_loss: 0.0622\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0644 - val_loss: 0.0619\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0667 - val_loss: 0.0614\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0657 - val_loss: 0.0607\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0655 - val_loss: 0.0612\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0662 - val_loss: 0.0652\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0661 - val_loss: 0.0615\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0647 - val_loss: 0.0609\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0634 - val_loss: 0.0599\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0637 - val_loss: 0.0612\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0651 - val_loss: 0.0605\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0634 - val_loss: 0.0607\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0634 - val_loss: 0.0596\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0630 - val_loss: 0.0612\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.1516 - val_loss: 0.1206\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1219 - val_loss: 0.0970\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1016 - val_loss: 0.0837\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0957 - val_loss: 0.0731\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0898 - val_loss: 0.0707\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0829 - val_loss: 0.0684\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0825 - val_loss: 0.0720\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0802 - val_loss: 0.0709\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0794 - val_loss: 0.0696\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0844 - val_loss: 0.0692\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0813 - val_loss: 0.0658\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0778 - val_loss: 0.0664\n",
      "Epoch 13/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0792 - val_loss: 0.0665\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0809 - val_loss: 0.0662\n",
      "Epoch 15/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0789 - val_loss: 0.0655\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0794 - val_loss: 0.0691\n",
      "Epoch 17/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0779 - val_loss: 0.0651\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0783 - val_loss: 0.0651\n",
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0782 - val_loss: 0.0657\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0773 - val_loss: 0.0653\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0752 - val_loss: 0.0676\n",
      "Epoch 22/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0756 - val_loss: 0.0653\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0759 - val_loss: 0.0652\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0768 - val_loss: 0.0651\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0770 - val_loss: 0.0645\n",
      "Epoch 26/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0796 - val_loss: 0.0723\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0925 - val_loss: 0.0673\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0756 - val_loss: 0.0647\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0765 - val_loss: 0.0680\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0749 - val_loss: 0.0645\n",
      "Epoch 31/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0745 - val_loss: 0.0655\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0761 - val_loss: 0.0646\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0762 - val_loss: 0.0648\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0752 - val_loss: 0.0648\n",
      "Epoch 35/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0738 - val_loss: 0.0660\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0746 - val_loss: 0.0654\n",
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0734 - val_loss: 0.0693\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0766 - val_loss: 0.0654\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0745 - val_loss: 0.0656\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0730 - val_loss: 0.0667\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0738 - val_loss: 0.0665\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0688\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0808 - val_loss: 0.0676\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0735 - val_loss: 0.0668\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0737 - val_loss: 0.0660\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.1966 - val_loss: 0.1291\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1285 - val_loss: 0.0994\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1064 - val_loss: 0.0856\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0954 - val_loss: 0.0817\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0888 - val_loss: 0.0759\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0896 - val_loss: 0.0730\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0825 - val_loss: 0.0745\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0829 - val_loss: 0.0714\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0806 - val_loss: 0.0719\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0854 - val_loss: 0.0697\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0817 - val_loss: 0.0697\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0834 - val_loss: 0.0747\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0799 - val_loss: 0.0757\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0799 - val_loss: 0.0700\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0832 - val_loss: 0.0688\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0794 - val_loss: 0.0692\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0779 - val_loss: 0.0692\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0779 - val_loss: 0.0757\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0766 - val_loss: 0.0691\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0781 - val_loss: 0.0680\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0765 - val_loss: 0.0687\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0784 - val_loss: 0.0687\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0801 - val_loss: 0.0692\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3470 - val_loss: 0.2696\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2309 - val_loss: 0.2217\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1894 - val_loss: 0.1799\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1630 - val_loss: 0.1513\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1403 - val_loss: 0.1294\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1240 - val_loss: 0.1135\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1111 - val_loss: 0.0983\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1024 - val_loss: 0.0907\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0965 - val_loss: 0.0844\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0929 - val_loss: 0.0813\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0903 - val_loss: 0.0789\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0882 - val_loss: 0.0795\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0855 - val_loss: 0.0785\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0843 - val_loss: 0.0730\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0838 - val_loss: 0.0719\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0843 - val_loss: 0.0789\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0830 - val_loss: 0.0882\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0825 - val_loss: 0.0732\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0800 - val_loss: 0.0695\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0788 - val_loss: 0.0711\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0800 - val_loss: 0.0693\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0791 - val_loss: 0.0690\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0788 - val_loss: 0.0728\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.2113 - val_loss: 0.1776\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1486 - val_loss: 0.1230\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1117 - val_loss: 0.0939\n",
      "Epoch 4/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0967 - val_loss: 0.0797\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0879 - val_loss: 0.0755\n",
      "Epoch 6/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0848 - val_loss: 0.0732\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0845 - val_loss: 0.0725\n",
      "Epoch 8/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0831 - val_loss: 0.0806\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0841 - val_loss: 0.0703\n",
      "Epoch 10/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0800 - val_loss: 0.0796\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0828 - val_loss: 0.0718\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0814 - val_loss: 0.0692\n",
      "Epoch 13/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0827 - val_loss: 0.0700\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0810 - val_loss: 0.0688\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0779 - val_loss: 0.0715\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0788 - val_loss: 0.0697\n",
      "Epoch 17/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0794 - val_loss: 0.0739\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0796 - val_loss: 0.0750\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0774 - val_loss: 0.0683\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0788 - val_loss: 0.0703\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0773 - val_loss: 0.0746\n",
      "Epoch 22/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0788 - val_loss: 0.0708\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0796 - val_loss: 0.0746\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0758 - val_loss: 0.0694\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0793 - val_loss: 0.0681\n",
      "Epoch 26/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0793 - val_loss: 0.0734\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0784 - val_loss: 0.0751\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0761 - val_loss: 0.0682\n",
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0764 - val_loss: 0.0677\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0763 - val_loss: 0.0683\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0778 - val_loss: 0.0677\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 0.685491, val loss - 0.164864\n",
      "Epoch 2/15: loss - 0.174284, val loss - 0.117720\n",
      "Epoch 3/15: loss - 0.100873, val loss - 0.096010\n",
      "Epoch 4/15: loss - 0.093832, val loss - 0.088431\n",
      "Epoch 5/15: loss - 0.083047, val loss - 0.078584\n",
      "Epoch 6/15: loss - 0.080692, val loss - 0.077295\n",
      "Epoch 7/15: loss - 0.078010, val loss - 0.069166\n",
      "Epoch 8/15: loss - 0.073905, val loss - 0.062464\n",
      "Epoch 9/15: loss - 0.070948, val loss - 0.059796\n",
      "Epoch 10/15: loss - 0.071065, val loss - 0.063403\n",
      "Epoch 11/15: loss - 0.070101, val loss - 0.068506\n",
      "Epoch 12/15: loss - 0.070924, val loss - 0.059374\n",
      "Epoch 13/15: loss - 0.067416, val loss - 0.058016\n",
      "Epoch 14/15: loss - 0.068993, val loss - 0.057221\n",
      "Epoch 15/15: loss - 0.068642, val loss - 0.060269\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.369362, val loss - 0.136274\n",
      "Epoch 2/176: loss - 0.131902, val loss - 0.102756\n",
      "Epoch 3/176: loss - 0.117210, val loss - 0.106709\n",
      "Epoch 4/176: loss - 0.111387, val loss - 0.119246\n",
      "Epoch 5/176: loss - 0.112999, val loss - 0.117308\n",
      "Epoch 6/176: loss - 0.105299, val loss - 0.105933\n",
      "Epoch 7/176: loss - 0.112461, val loss - 0.151317\n",
      "Epoch 8/176: loss - 0.109022, val loss - 0.101266\n",
      "Epoch 9/176: loss - 0.093979, val loss - 0.086882\n",
      "Epoch 10/176: loss - 0.088951, val loss - 0.073658\n",
      "Epoch 11/176: loss - 0.087291, val loss - 0.105925\n",
      "Epoch 12/176: loss - 0.096004, val loss - 0.084270\n",
      "Epoch 13/176: loss - 0.096147, val loss - 0.137923\n",
      "Epoch 14/176: loss - 0.096029, val loss - 0.072257\n",
      "Epoch 15/176: loss - 0.087553, val loss - 0.099243\n",
      "Epoch 16/176: loss - 0.083346, val loss - 0.086165\n",
      "Epoch 17/176: loss - 0.086129, val loss - 0.069549\n",
      "Epoch 18/176: loss - 0.086495, val loss - 0.081505\n",
      "Epoch 19/176: loss - 0.082126, val loss - 0.075334\n",
      "Epoch 20/176: loss - 0.082405, val loss - 0.070024\n",
      "Epoch 21/176: loss - 0.078757, val loss - 0.068549\n",
      "Epoch 22/176: loss - 0.081710, val loss - 0.074641\n",
      "Epoch 23/176: loss - 0.077005, val loss - 0.076559\n",
      "Epoch 24/176: loss - 0.079302, val loss - 0.070614\n",
      "Epoch 25/176: loss - 0.080213, val loss - 0.074253\n",
      "Epoch 26/176: loss - 0.079534, val loss - 0.070966\n",
      "Epoch 27/176: loss - 0.076440, val loss - 0.068840\n",
      "Epoch 28/176: loss - 0.078020, val loss - 0.075152\n",
      "Epoch 29/176: loss - 0.081302, val loss - 0.072831\n",
      "Epoch 30/176: loss - 0.076980, val loss - 0.070505\n",
      "Epoch 31/176: loss - 0.076596, val loss - 0.071433\n",
      "Epoch 32/176: loss - 0.078566, val loss - 0.069559\n",
      "Epoch 33/176: loss - 0.077300, val loss - 0.074261\n",
      "Epoch 34/176: loss - 0.076489, val loss - 0.069975\n",
      "Epoch 35/176: loss - 0.075811, val loss - 0.068405\n",
      "Epoch 36/176: loss - 0.075757, val loss - 0.073757\n",
      "Epoch 37/176: loss - 0.076602, val loss - 0.073405\n",
      "Epoch 38/176: loss - 0.075877, val loss - 0.074155\n",
      "Epoch 39/176: loss - 0.078279, val loss - 0.082955\n",
      "Epoch 40/176: loss - 0.081897, val loss - 0.072211\n",
      "Epoch 41/176: loss - 0.074500, val loss - 0.068954\n",
      "Epoch 42/176: loss - 0.075845, val loss - 0.071521\n",
      "Epoch 43/176: loss - 0.075850, val loss - 0.068492\n",
      "Epoch 44/176: loss - 0.074086, val loss - 0.069345\n",
      "Epoch 45/176: loss - 0.074931, val loss - 0.075107\n",
      "Epoch 46/176: loss - 0.076197, val loss - 0.069355\n",
      "Epoch 47/176: loss - 0.073487, val loss - 0.069179\n",
      "Epoch 48/176: loss - 0.080115, val loss - 0.071033\n",
      "Epoch 49/176: loss - 0.076002, val loss - 0.068010\n",
      "Epoch 50/176: loss - 0.077327, val loss - 0.066529\n",
      "Epoch 51/176: loss - 0.072859, val loss - 0.067673\n",
      "Epoch 52/176: loss - 0.076384, val loss - 0.069371\n",
      "Epoch 53/176: loss - 0.073862, val loss - 0.068604\n",
      "Epoch 54/176: loss - 0.074336, val loss - 0.066858\n",
      "Epoch 55/176: loss - 0.074134, val loss - 0.067807\n",
      "Epoch 56/176: loss - 0.075985, val loss - 0.072120\n",
      "Epoch 57/176: loss - 0.074544, val loss - 0.070900\n",
      "Epoch 58/176: loss - 0.080911, val loss - 0.066982\n",
      "Epoch 59/176: loss - 0.071498, val loss - 0.067838\n",
      "Epoch 60/176: loss - 0.072677, val loss - 0.069132\n",
      "Epoch 61/176: loss - 0.071858, val loss - 0.066947\n",
      "Epoch 62/176: loss - 0.072892, val loss - 0.066973\n",
      "Epoch 63/176: loss - 0.075576, val loss - 0.080860\n",
      "Epoch 64/176: loss - 0.075146, val loss - 0.076146\n",
      "Epoch 65/176: loss - 0.076119, val loss - 0.068653\n",
      "Epoch 66/176: loss - 0.074449, val loss - 0.066669\n",
      "Epoch 67/176: loss - 0.088872, val loss - 0.096989\n",
      "Epoch 68/176: loss - 0.082387, val loss - 0.067004\n",
      "Epoch 69/176: loss - 0.073947, val loss - 0.084379\n",
      "Epoch 70/176: loss - 0.074213, val loss - 0.077175\n",
      "Epoch 71/176: loss - 0.076950, val loss - 0.085493\n",
      "Epoch 72/176: loss - 0.080561, val loss - 0.088256\n",
      "Epoch 73/176: loss - 0.081308, val loss - 0.067451\n",
      "Epoch 74/176: loss - 0.077463, val loss - 0.080395\n",
      "Epoch 75/176: loss - 0.079850, val loss - 0.077565\n",
      "Epoch 76/176: loss - 0.075714, val loss - 0.067866\n",
      "Epoch 77/176: loss - 0.082024, val loss - 0.074648\n",
      "Epoch 78/176: loss - 0.074766, val loss - 0.073672\n",
      "Epoch 79/176: loss - 0.073548, val loss - 0.072968\n",
      "Epoch 80/176: loss - 0.076597, val loss - 0.071959\n",
      "Epoch 81/176: loss - 0.073988, val loss - 0.068726\n",
      "Epoch 82/176: loss - 0.070976, val loss - 0.073394\n",
      "Epoch 83/176: loss - 0.068324, val loss - 0.069431\n",
      "Epoch 84/176: loss - 0.070323, val loss - 0.071682\n",
      "Epoch 85/176: loss - 0.075018, val loss - 0.077465\n",
      "Epoch 86/176: loss - 0.079624, val loss - 0.074796\n",
      "Epoch 87/176: loss - 0.076210, val loss - 0.067222\n",
      "Epoch 88/176: loss - 0.077600, val loss - 0.073531\n",
      "Epoch 89/176: loss - 0.076073, val loss - 0.076202\n",
      "Epoch 90/176: loss - 0.073779, val loss - 0.079380\n",
      "Epoch 91/176: loss - 0.071632, val loss - 0.076327\n",
      "Epoch 92/176: loss - 0.073061, val loss - 0.071410\n",
      "Epoch 93/176: loss - 0.074892, val loss - 0.071281\n",
      "Epoch 94/176: loss - 0.079821, val loss - 0.078578\n",
      "Epoch 95/176: loss - 0.070214, val loss - 0.080196\n",
      "Epoch 96/176: loss - 0.077968, val loss - 0.072459\n",
      "Epoch 97/176: loss - 0.077241, val loss - 0.084231\n",
      "Epoch 98/176: loss - 0.073175, val loss - 0.071848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/176: loss - 0.074015, val loss - 0.074218\n",
      "Epoch 100/176: loss - 0.071661, val loss - 0.071053\n",
      "Epoch 101/176: loss - 0.068058, val loss - 0.070117\n",
      "Epoch 102/176: loss - 0.065227, val loss - 0.071388\n",
      "Epoch 103/176: loss - 0.066081, val loss - 0.069848\n",
      "Epoch 104/176: loss - 0.065871, val loss - 0.067969\n",
      "Epoch 105/176: loss - 0.062268, val loss - 0.066681\n",
      "Epoch 106/176: loss - 0.061533, val loss - 0.067926\n",
      "Epoch 107/176: loss - 0.068518, val loss - 0.074465\n",
      "Epoch 108/176: loss - 0.064902, val loss - 0.064836\n",
      "Epoch 109/176: loss - 0.065010, val loss - 0.069233\n",
      "Epoch 110/176: loss - 0.064576, val loss - 0.072618\n",
      "Epoch 111/176: loss - 0.067539, val loss - 0.072574\n",
      "Epoch 112/176: loss - 0.066563, val loss - 0.065314\n",
      "Epoch 113/176: loss - 0.067126, val loss - 0.083204\n",
      "Epoch 114/176: loss - 0.072835, val loss - 0.076641\n",
      "Epoch 115/176: loss - 0.069070, val loss - 0.076807\n",
      "Epoch 116/176: loss - 0.069324, val loss - 0.076662\n",
      "Epoch 117/176: loss - 0.072988, val loss - 0.068406\n",
      "Epoch 118/176: loss - 0.068715, val loss - 0.073679\n",
      "Epoch 119/176: loss - 0.068210, val loss - 0.064524\n",
      "Epoch 120/176: loss - 0.061695, val loss - 0.066965\n",
      "Epoch 121/176: loss - 0.066740, val loss - 0.073089\n",
      "Epoch 122/176: loss - 0.068631, val loss - 0.069790\n",
      "Epoch 123/176: loss - 0.065529, val loss - 0.065870\n",
      "Epoch 124/176: loss - 0.065388, val loss - 0.068102\n",
      "Epoch 125/176: loss - 0.068750, val loss - 0.067222\n",
      "Epoch 126/176: loss - 0.067307, val loss - 0.074188\n",
      "Epoch 127/176: loss - 0.068977, val loss - 0.070927\n",
      "Epoch 128/176: loss - 0.069137, val loss - 0.074832\n",
      "Epoch 129/176: loss - 0.068143, val loss - 0.071192\n",
      "Epoch 130/176: loss - 0.064120, val loss - 0.070435\n",
      "Epoch 131/176: loss - 0.064316, val loss - 0.068950\n",
      "Epoch 132/176: loss - 0.067054, val loss - 0.069075\n",
      "Epoch 133/176: loss - 0.067986, val loss - 0.077246\n",
      "Epoch 134/176: loss - 0.085019, val loss - 0.074019\n",
      "Epoch 135/176: loss - 0.071146, val loss - 0.068409\n",
      "Epoch 136/176: loss - 0.065048, val loss - 0.064674\n",
      "Epoch 137/176: loss - 0.063309, val loss - 0.066844\n",
      "Epoch 138/176: loss - 0.061496, val loss - 0.068683\n",
      "Epoch 139/176: loss - 0.062771, val loss - 0.062822\n",
      "Epoch 140/176: loss - 0.084131, val loss - 0.075540\n",
      "Epoch 141/176: loss - 0.076991, val loss - 0.077328\n",
      "Epoch 142/176: loss - 0.081228, val loss - 0.078308\n",
      "Epoch 143/176: loss - 0.075063, val loss - 0.070572\n",
      "Epoch 144/176: loss - 0.073814, val loss - 0.068327\n",
      "Epoch 145/176: loss - 0.065317, val loss - 0.067458\n",
      "Epoch 146/176: loss - 0.063739, val loss - 0.068825\n",
      "Epoch 147/176: loss - 0.069209, val loss - 0.072021\n",
      "Epoch 148/176: loss - 0.069151, val loss - 0.079980\n",
      "Epoch 149/176: loss - 0.075631, val loss - 0.079619\n",
      "Epoch 150/176: loss - 0.069656, val loss - 0.074522\n",
      "Epoch 151/176: loss - 0.065789, val loss - 0.075418\n",
      "Epoch 152/176: loss - 0.066007, val loss - 0.076045\n",
      "Epoch 153/176: loss - 0.065149, val loss - 0.075967\n",
      "Epoch 154/176: loss - 0.069038, val loss - 0.076635\n",
      "Epoch 155/176: loss - 0.064623, val loss - 0.070656\n",
      "Epoch 156/176: loss - 0.062507, val loss - 0.067150\n",
      "Epoch 157/176: loss - 0.060536, val loss - 0.068069\n",
      "Epoch 158/176: loss - 0.059504, val loss - 0.068521\n",
      "Epoch 159/176: loss - 0.060013, val loss - 0.073673\n",
      "Epoch 160/176: loss - 0.061028, val loss - 0.066079\n",
      "Epoch 161/176: loss - 0.058180, val loss - 0.070574\n",
      "Epoch 162/176: loss - 0.059406, val loss - 0.069345\n",
      "Epoch 163/176: loss - 0.058413, val loss - 0.063258\n",
      "Epoch 164/176: loss - 0.059717, val loss - 0.070626\n",
      "Epoch 165/176: loss - 0.061976, val loss - 0.070417\n",
      "Epoch 166/176: loss - 0.059034, val loss - 0.075395\n",
      "Epoch 167/176: loss - 0.062501, val loss - 0.070549\n",
      "Epoch 168/176: loss - 0.058872, val loss - 0.068329\n",
      "Epoch 169/176: loss - 0.058205, val loss - 0.073299\n",
      "Epoch 170/176: loss - 0.062955, val loss - 0.080854\n",
      "Epoch 171/176: loss - 0.062940, val loss - 0.074691\n",
      "Epoch 172/176: loss - 0.061454, val loss - 0.075264\n",
      "Epoch 173/176: loss - 0.061585, val loss - 0.070772\n",
      "Epoch 174/176: loss - 0.062588, val loss - 0.073378\n",
      "Epoch 175/176: loss - 0.062020, val loss - 0.070838\n",
      "Epoch 176/176: loss - 0.062218, val loss - 0.069207\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.174972, val loss - 0.132463\n",
      "Epoch 2/24: loss - 0.128896, val loss - 0.109620\n",
      "Epoch 3/24: loss - 0.124839, val loss - 0.104581\n",
      "Epoch 4/24: loss - 0.112396, val loss - 0.121395\n",
      "Epoch 5/24: loss - 0.120175, val loss - 0.092217\n",
      "Epoch 6/24: loss - 0.111395, val loss - 0.099718\n",
      "Epoch 7/24: loss - 0.108045, val loss - 0.088228\n",
      "Epoch 8/24: loss - 0.103419, val loss - 0.093632\n",
      "Epoch 9/24: loss - 0.100254, val loss - 0.094008\n",
      "Epoch 10/24: loss - 0.100534, val loss - 0.083915\n",
      "Epoch 11/24: loss - 0.095209, val loss - 0.087503\n",
      "Epoch 12/24: loss - 0.094064, val loss - 0.081969\n",
      "Epoch 13/24: loss - 0.093814, val loss - 0.080830\n",
      "Epoch 14/24: loss - 0.091487, val loss - 0.096111\n",
      "Epoch 15/24: loss - 0.096313, val loss - 0.078229\n",
      "Epoch 16/24: loss - 0.088526, val loss - 0.076902\n",
      "Epoch 17/24: loss - 0.086773, val loss - 0.077339\n",
      "Epoch 18/24: loss - 0.085102, val loss - 0.077484\n",
      "Epoch 19/24: loss - 0.081689, val loss - 0.073909\n",
      "Epoch 20/24: loss - 0.087196, val loss - 0.073848\n",
      "Epoch 21/24: loss - 0.084815, val loss - 0.078024\n",
      "Epoch 22/24: loss - 0.087721, val loss - 0.073065\n",
      "Epoch 23/24: loss - 0.084381, val loss - 0.073927\n",
      "Epoch 24/24: loss - 0.084681, val loss - 0.070213\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.183187, val loss - 0.128776\n",
      "Epoch 2/66: loss - 0.121309, val loss - 0.116918\n",
      "Epoch 3/66: loss - 0.114558, val loss - 0.108792\n",
      "Epoch 4/66: loss - 0.109111, val loss - 0.093472\n",
      "Epoch 5/66: loss - 0.103996, val loss - 0.082184\n",
      "Epoch 6/66: loss - 0.094494, val loss - 0.079744\n",
      "Epoch 7/66: loss - 0.087516, val loss - 0.081810\n",
      "Epoch 8/66: loss - 0.098548, val loss - 0.075343\n",
      "Epoch 9/66: loss - 0.088011, val loss - 0.083247\n",
      "Epoch 10/66: loss - 0.091956, val loss - 0.077831\n",
      "Epoch 11/66: loss - 0.085921, val loss - 0.080251\n",
      "Epoch 12/66: loss - 0.085211, val loss - 0.076362\n",
      "Epoch 13/66: loss - 0.084097, val loss - 0.074736\n",
      "Epoch 14/66: loss - 0.085313, val loss - 0.074631\n",
      "Epoch 15/66: loss - 0.084414, val loss - 0.073618\n",
      "Epoch 16/66: loss - 0.082351, val loss - 0.070534\n",
      "Epoch 17/66: loss - 0.085021, val loss - 0.076283\n",
      "Epoch 18/66: loss - 0.083255, val loss - 0.070485\n",
      "Epoch 19/66: loss - 0.085109, val loss - 0.072598\n",
      "Epoch 20/66: loss - 0.082265, val loss - 0.069597\n",
      "Epoch 21/66: loss - 0.079147, val loss - 0.071851\n",
      "Epoch 22/66: loss - 0.082061, val loss - 0.076769\n",
      "Epoch 23/66: loss - 0.082826, val loss - 0.073576\n",
      "Epoch 24/66: loss - 0.084556, val loss - 0.069420\n",
      "Epoch 25/66: loss - 0.079969, val loss - 0.071323\n",
      "Epoch 26/66: loss - 0.081530, val loss - 0.069020\n",
      "Epoch 27/66: loss - 0.079780, val loss - 0.070780\n",
      "Epoch 28/66: loss - 0.081816, val loss - 0.069610\n",
      "Epoch 29/66: loss - 0.079641, val loss - 0.068124\n",
      "Epoch 30/66: loss - 0.081936, val loss - 0.069850\n",
      "Epoch 31/66: loss - 0.079498, val loss - 0.069572\n",
      "Epoch 32/66: loss - 0.079497, val loss - 0.074833\n",
      "Epoch 33/66: loss - 0.082605, val loss - 0.068622\n",
      "Epoch 34/66: loss - 0.081458, val loss - 0.068393\n",
      "Epoch 35/66: loss - 0.080451, val loss - 0.069210\n",
      "Epoch 36/66: loss - 0.078927, val loss - 0.070144\n",
      "Epoch 37/66: loss - 0.078581, val loss - 0.067175\n",
      "Epoch 38/66: loss - 0.077777, val loss - 0.069269\n",
      "Epoch 39/66: loss - 0.078636, val loss - 0.068721\n",
      "Epoch 40/66: loss - 0.076646, val loss - 0.070841\n",
      "Epoch 41/66: loss - 0.080726, val loss - 0.069647\n",
      "Epoch 42/66: loss - 0.079909, val loss - 0.067790\n",
      "Epoch 43/66: loss - 0.078512, val loss - 0.067892\n",
      "Epoch 44/66: loss - 0.078553, val loss - 0.068476\n",
      "Epoch 45/66: loss - 0.076788, val loss - 0.069376\n",
      "Epoch 46/66: loss - 0.077209, val loss - 0.067466\n",
      "Epoch 47/66: loss - 0.075808, val loss - 0.068432\n",
      "Epoch 48/66: loss - 0.077523, val loss - 0.069456\n",
      "Epoch 49/66: loss - 0.077788, val loss - 0.067595\n",
      "Epoch 50/66: loss - 0.079481, val loss - 0.068174\n",
      "Epoch 51/66: loss - 0.074134, val loss - 0.067455\n",
      "Epoch 52/66: loss - 0.075993, val loss - 0.067857\n",
      "Epoch 53/66: loss - 0.075770, val loss - 0.068576\n",
      "Epoch 54/66: loss - 0.076529, val loss - 0.068013\n",
      "Epoch 55/66: loss - 0.073427, val loss - 0.067646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/66: loss - 0.074558, val loss - 0.067545\n",
      "Epoch 57/66: loss - 0.074155, val loss - 0.066750\n",
      "Epoch 58/66: loss - 0.074007, val loss - 0.067368\n",
      "Epoch 59/66: loss - 0.074405, val loss - 0.067690\n",
      "Epoch 60/66: loss - 0.074701, val loss - 0.067651\n",
      "Epoch 61/66: loss - 0.079284, val loss - 0.066775\n",
      "Epoch 62/66: loss - 0.073129, val loss - 0.072421\n",
      "Epoch 63/66: loss - 0.072962, val loss - 0.067241\n",
      "Epoch 64/66: loss - 0.073898, val loss - 0.067142\n",
      "Epoch 65/66: loss - 0.074601, val loss - 0.068007\n",
      "Epoch 66/66: loss - 0.073749, val loss - 0.068513\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.155850, val loss - 0.113982\n",
      "Epoch 2/24: loss - 0.120584, val loss - 0.122447\n",
      "Epoch 3/24: loss - 0.116387, val loss - 0.103388\n",
      "Epoch 4/24: loss - 0.121072, val loss - 0.081416\n",
      "Epoch 5/24: loss - 0.097216, val loss - 0.123330\n",
      "Epoch 6/24: loss - 0.091078, val loss - 0.102453\n",
      "Epoch 7/24: loss - 0.088181, val loss - 0.078039\n",
      "Epoch 8/24: loss - 0.086990, val loss - 0.082692\n",
      "Epoch 9/24: loss - 0.080164, val loss - 0.075846\n",
      "Epoch 10/24: loss - 0.085879, val loss - 0.072005\n",
      "Epoch 11/24: loss - 0.080052, val loss - 0.075597\n",
      "Epoch 12/24: loss - 0.077724, val loss - 0.075375\n",
      "Epoch 13/24: loss - 0.080119, val loss - 0.075496\n",
      "Epoch 14/24: loss - 0.077865, val loss - 0.076218\n",
      "Epoch 15/24: loss - 0.073898, val loss - 0.082538\n",
      "Epoch 16/24: loss - 0.079919, val loss - 0.071994\n",
      "Epoch 17/24: loss - 0.073224, val loss - 0.070035\n",
      "Epoch 18/24: loss - 0.074432, val loss - 0.072271\n",
      "Epoch 19/24: loss - 0.076406, val loss - 0.071288\n",
      "Epoch 20/24: loss - 0.075669, val loss - 0.069719\n",
      "Epoch 21/24: loss - 0.075918, val loss - 0.069556\n",
      "Epoch 22/24: loss - 0.073840, val loss - 0.069160\n",
      "Epoch 23/24: loss - 0.075489, val loss - 0.071106\n",
      "Epoch 24/24: loss - 0.073444, val loss - 0.070778\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2186 - val_loss: 0.1250\n",
      "Epoch 2/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.0783\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0732\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.0772\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0803\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0700\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0699\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0670\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0716\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0658\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0681\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0612\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0613\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0655\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0619\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0597\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0630 - val_loss: 0.0634\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0559\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0544\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0533\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0600\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0756\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0565\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0547\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0526\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0719\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0519\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0500\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1476 - val_loss: 0.1032\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.0891\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0949 - val_loss: 0.0762\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0683\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0770\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0827\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0642\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0654\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0643\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0642\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0719 - val_loss: 0.0777\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0622\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0655 - val_loss: 0.0553\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0581\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0930\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0555\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0564\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0671\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0554\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0547\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.0578\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0579\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0663\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0575\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0602\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0758\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0540\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0544\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0587\n",
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0605\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0615\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0622\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0707\n",
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0826\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0603\n",
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2552 - val_loss: 0.1673\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1061\n",
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1052 - val_loss: 0.0990\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1154 - val_loss: 0.1340\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1019 - val_loss: 0.0869\n",
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.0677\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0680\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0627\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0642\n",
      "Epoch 10/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0626\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0608\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0607\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0649\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0595\n",
      "Epoch 15/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0624\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0684\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0778\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0610\n",
      "Epoch 19/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0619\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.0601\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0590\n",
      "Epoch 22/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0749\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0633\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0661\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0598\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0682\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0694\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0603\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0623\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3784 - val_loss: 0.1533\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 0.1086\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1007 - val_loss: 0.0750\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.0671\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0710\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0672\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0738\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0680\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0759\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0649\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0664\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0705\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0666\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0619\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0657\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0610\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0624\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0793\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0673\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.0644\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0608\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0597\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0606\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0596\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0640\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0566\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0612\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.1157\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0638 - val_loss: 0.0737\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0642\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0703\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0634\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0736\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0582\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2455 - val_loss: 0.1689\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1467\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1469 - val_loss: 0.1415\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1405 - val_loss: 0.1368\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1343 - val_loss: 0.1300\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1296 - val_loss: 0.1245\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1256 - val_loss: 0.1214\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1220 - val_loss: 0.1151\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.1129\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1143 - val_loss: 0.1081\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1107 - val_loss: 0.1046\n",
      "Epoch 12/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1081 - val_loss: 0.1004\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.0980\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1015 - val_loss: 0.0935\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.0926\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0961 - val_loss: 0.0875\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0941 - val_loss: 0.0864\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0916 - val_loss: 0.0818\n",
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0896 - val_loss: 0.0817\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0780\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0849 - val_loss: 0.0756\n",
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.0784\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0721\n",
      "Epoch 25/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.0770\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0730\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0707\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0731\n",
      "Epoch 29/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0700\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0766\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.0698\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0696\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.0744\n",
      "Epoch 34/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0687\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0717\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0689\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0718\n",
      "Epoch 38/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0688\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0766\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0690\n",
      "Epoch 41/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0719\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0712\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.0703\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0680\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0709\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0683\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0681\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0713\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0684\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0734 - val_loss: 0.0704\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0676\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0693\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0741\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0680\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0735\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0711\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.0684\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0725 - val_loss: 0.0692\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0709\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0692\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0738\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0674\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0752\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0719 - val_loss: 0.0680\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0701\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0716\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0691\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0722\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.0686\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0681\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0712\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0676\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0741\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.0681\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0701\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0684\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.0718\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0686\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0730\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0712\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0684\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0689\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0689\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0716 - val_loss: 0.0679\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0713 - val_loss: 0.0745\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0690\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0680\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0725\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0682\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0700\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0727\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0699\n",
      "Epoch 94/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0680\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0704\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0738\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0686\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0699\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0710\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0684\n",
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0715\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0698\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0694\n",
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0680\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0725\n",
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0707\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0687\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1243 - val_loss: 0.0931\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0726\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0717\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0692\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0713\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0609\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0670\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0592\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0733\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0574\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0624\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0608\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0575\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0592\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0575\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0557\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0569\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0566\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0567\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0570\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0551\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0550\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0631\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0565\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0551\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0629\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0697\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0540\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0562\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0549\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0532\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0586\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0548\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0535\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4109 - val_loss: 0.1681\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1438 - val_loss: 0.1325\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1243\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.1139\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.1086\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.1047\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1075 - val_loss: 0.1049\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.1009\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1043 - val_loss: 0.0989\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1031 - val_loss: 0.0993\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0954\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.0921\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0951 - val_loss: 0.0887\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0896 - val_loss: 0.0817\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.0749\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0717\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0722\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.0728\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0732\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0708\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0710\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0667\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0766 - val_loss: 0.0696\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0686\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0691\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0976\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0881 - val_loss: 0.0905\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0793 - val_loss: 0.0702\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.0716\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0674\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0661\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0699\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0656\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0648\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0668\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0653\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4160 - val_loss: 0.3344\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2319 - val_loss: 0.1997\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1532 - val_loss: 0.1482\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1348 - val_loss: 0.1384\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1355\n",
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1304 - val_loss: 0.1330\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1267\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1231\n",
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.1185\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1135\n",
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.1091\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.1031\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1049 - val_loss: 0.0982\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.0943\n",
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.0927\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.0908\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0888\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.0877\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0950 - val_loss: 0.0855\n",
      "Epoch 21/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.0858\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0840\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.0845\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.0824\n",
      "Epoch 25/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0907 - val_loss: 0.0819\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0816\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0817\n",
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 0.0795\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0797\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0783\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0793\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0775\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0775\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0764\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0772\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0770\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0758\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0747\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0752\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0746\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0731\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0736\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0728\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0727\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0721\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0749\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0713\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0733\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0705\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0723\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0717\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0698\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0705\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0719\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0694\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0695\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0698\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0720\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0690\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0686\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0710\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0691\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0695\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0744\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0699\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0700\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0696\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0695\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0757\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0712\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0690\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2936 - val_loss: 0.2421\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1804 - val_loss: 0.1751\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1564 - val_loss: 0.1630\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1520 - val_loss: 0.1573\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1521\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1410 - val_loss: 0.1461\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1362 - val_loss: 0.1391\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1298 - val_loss: 0.1302\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.1196\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.1025\n",
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.0888\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.0839\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.0818\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0819\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0793\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0827\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0795\n",
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0782\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.0767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0766\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0753\n",
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0764\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0764\n",
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0740\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0786\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0744\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0764\n",
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0723\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0736\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0759\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0730\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0722\n",
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0738\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0731\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0729\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0762\n",
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0719\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0742\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0755\n",
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0765 - val_loss: 0.0727\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0714\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0738\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0716\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0727\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0725\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0732\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0717\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0738\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0711\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0742\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0713\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0713\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0753\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0724\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0713\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0761\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0719\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0750\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0706\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0736\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0730\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.0721\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0735\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2427 - val_loss: 0.1623\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1491 - val_loss: 0.1355\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1218 - val_loss: 0.1129\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0813\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.0737\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0842 - val_loss: 0.0740\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0790 - val_loss: 0.0758\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0736\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.0720\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.0715\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0775 - val_loss: 0.0728\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0815\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0810\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0752\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0747\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0711\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0699\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0720\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0709\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0725 - val_loss: 0.0749\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0767\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0705\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.0723\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0719 - val_loss: 0.0768\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0699\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0698\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6763 - val_loss: 0.5045\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.3676\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.2820\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2703 - val_loss: 0.2179\n",
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2123 - val_loss: 0.1754\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1750 - val_loss: 0.1503\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1529 - val_loss: 0.1338\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1239\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1146\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1206 - val_loss: 0.1086\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1037\n",
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.0995\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.0961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.0937\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.0910\n",
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.0910\n",
      "Epoch 17/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.0877\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.0878\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0926 - val_loss: 0.0846\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0835\n",
      "Epoch 21/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0825\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0816\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0812\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0805\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0801\n",
      "Epoch 26/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0802\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0799\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0797\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0788\n",
      "Epoch 30/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.0789\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0796\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0789\n",
      "Epoch 33/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0779\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0775\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0774\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0772\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0768\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0764\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0782\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0772\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0757\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0755\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0766\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0748\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0749\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0745\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0738\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0740\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0732\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0764\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0752\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0724\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0720\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0759\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0717\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0723\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0709\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0706\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0707\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0704\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0702\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0698\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0702\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0699\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0690\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0695\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0694\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0686\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0691\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0681\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0703\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0678\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0681\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0682\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0673\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0676\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0682\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0676\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0681\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0666\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0679\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0667\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0663\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0663\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0673\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0691\n",
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0695\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0658\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0678\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0668\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0655\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0657\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0669\n",
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0661\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0657\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0654\n",
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0668\n",
      "Epoch 99/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0657\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0676\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0695\n",
      "Epoch 103/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0650\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0649\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0649\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0655\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0654\n",
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0658\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0735\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0648\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0657\n",
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0685\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0665\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0653\n",
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0680\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0650\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0659\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0654\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0655\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0687\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0677\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0652\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0673\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0719\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0660\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0659\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0701\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0653\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0658\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0670\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0654\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0656\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0661\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0715\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0657\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0652\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0663\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0669\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3639 - val_loss: 0.2224\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2263 - val_loss: 0.1874\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1896 - val_loss: 0.1609\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1652 - val_loss: 0.1485\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1377\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1397 - val_loss: 0.1314\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1322 - val_loss: 0.1279\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.1254\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1228 - val_loss: 0.1227\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1201 - val_loss: 0.1207\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.1197\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.1185\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1173\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.1164\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.1150\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.1140\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1135\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.1129\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1088 - val_loss: 0.1116\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1081 - val_loss: 0.1116\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1075 - val_loss: 0.1105\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.1104\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1063 - val_loss: 0.1095\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.1092\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.1088\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.1077\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1053 - val_loss: 0.1088\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.1076\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1070\n",
      "Epoch 30/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1039 - val_loss: 0.1072\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1066\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.1066\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1032 - val_loss: 0.1067\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1029 - val_loss: 0.1057\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.1051\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.1056\n",
      "Epoch 37/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.1045\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1020 - val_loss: 0.1049\n",
      "Epoch 39/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.1044\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.1043\n",
      "Epoch 41/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1040\n",
      "Epoch 42/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.1043\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.1033\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1036\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1004 - val_loss: 0.1030\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1005 - val_loss: 0.1027\n",
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1026\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.1025\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.1025\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1017\n",
      "Epoch 51/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.1017\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.1020\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.1018\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0993 - val_loss: 0.1015\n",
      "Epoch 55/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.1016\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.1005\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.1006\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.0999\n",
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.1003\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.1002\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.0990\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0997\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0961 - val_loss: 0.0988\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0961 - val_loss: 0.0980\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0951 - val_loss: 0.0980\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.0983\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0966\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.0963\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0985\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0948\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.0938\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0945\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.0934\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0946\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0918\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0929\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0941\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0894\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0907\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0906\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0898\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0875\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0882\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0905\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0854\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0857\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.0932\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0835\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0847\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0835\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0851\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0850\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0845\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.0818\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0814\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0821\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0821\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.0817\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0851\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0812\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0800\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0825\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0805\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0804\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0823\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0781\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0793\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0778\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0822\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0777\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0880\n",
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0768\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0776\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0791\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0895\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0760\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0830\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0755\n",
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0761\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0766\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0743\n",
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0756\n",
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0797\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0747\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0750\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0835\n",
      "Epoch 128/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0732\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0749\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0764\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0735\n",
      "Epoch 132/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0730\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0734\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0738\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0740\n",
      "Epoch 136/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0727\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0727\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0729\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0728\n",
      "Epoch 140/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0716\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0721\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0740\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0749\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0748\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0707\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0820\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0706\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0727\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0849\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1687 - val_loss: 0.1483\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1339 - val_loss: 0.1364\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1228\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1283\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.1174\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.1133\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.1050\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1061 - val_loss: 0.0957\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0974 - val_loss: 0.0861\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0902\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0829\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.0760\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0939\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0800\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0746\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0754\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0744\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.0800\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0732\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0836\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0975\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0841\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0798\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0733\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0833\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0731\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0740\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0727\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0752\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0737\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0725\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0755\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0733\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.1010\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.0750\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0720\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0743\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0713\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0766\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0749\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0704\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0704\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0732\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0740\n",
      "Epoch 45/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0709\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0785\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0724\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0717\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0733\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0704\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0721\n",
      "Epoch 52/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0709\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 54/56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0715\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0731\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0768\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.4005 - val_loss: 0.6036\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.3383\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 0.2988\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2983 - val_loss: 0.2750\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2646 - val_loss: 0.2419\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2384 - val_loss: 0.2195\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2165 - val_loss: 0.2014\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1967 - val_loss: 0.1829\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1796 - val_loss: 0.1689\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1523\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1418\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1388 - val_loss: 0.1320\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1289 - val_loss: 0.1249\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1219\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1153\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1124 - val_loss: 0.1195\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1096 - val_loss: 0.1141\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 0.1106\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 0.1073\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.1037\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.1028\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.1014\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.1008\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.0977\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.1020\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0951\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0978\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0928\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0903\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0953\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0894\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0885\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0927\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.0900\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.0866\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0908\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0896\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0873\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0927\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0869\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0835\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0866\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0871\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0840\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0838\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0899\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0828\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0871\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0827\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0824\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0829\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0824\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0853\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0876\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0807\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0856\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0831\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0896\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0804\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0816\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3395 - val_loss: 0.2588\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2361 - val_loss: 0.2043\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1907 - val_loss: 0.1708\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1621 - val_loss: 0.1555\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1485 - val_loss: 0.1478\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1416\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1354 - val_loss: 0.1388\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1321 - val_loss: 0.1373\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1329\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.1331\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1310\n",
      "Epoch 12/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1248 - val_loss: 0.1271\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1272\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1197 - val_loss: 0.1251\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.1242\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1203\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1198\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1118 - val_loss: 0.1135\n",
      "Epoch 19/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.1090\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1143\n",
      "Epoch 21/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1049 - val_loss: 0.1203\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.0983\n",
      "Epoch 23/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.1006\n",
      "Epoch 24/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.0932\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.0856\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.0868\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.0837\n",
      "Epoch 28/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0822\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.0804\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0941\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0810\n",
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0781\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0820\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0772\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0769\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0796\n",
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0820\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0745\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0774\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0769\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0787\n",
      "Epoch 1/47\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.1738 - val_loss: 0.1258\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1222 - val_loss: 0.1006\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0980 - val_loss: 0.0828\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0866 - val_loss: 0.0759\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0797 - val_loss: 0.0722\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0760 - val_loss: 0.0751\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0733 - val_loss: 0.0697\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0711 - val_loss: 0.0730\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0700 - val_loss: 0.0694\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0674 - val_loss: 0.0701\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0690 - val_loss: 0.0681\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0673 - val_loss: 0.0682\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0665 - val_loss: 0.0678\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0655 - val_loss: 0.0708\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0672 - val_loss: 0.0699\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0698 - val_loss: 0.0672\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0619 - val_loss: 0.0680\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0648 - val_loss: 0.0674\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0625 - val_loss: 0.0681\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0650 - val_loss: 0.0705\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0634 - val_loss: 0.0669\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0595 - val_loss: 0.0675\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0602 - val_loss: 0.0678\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0605 - val_loss: 0.0687\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0592 - val_loss: 0.0682\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0598 - val_loss: 0.0689\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0621 - val_loss: 0.0675\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0589 - val_loss: 0.0675\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0572 - val_loss: 0.0674\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0568 - val_loss: 0.0678\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0574 - val_loss: 0.0692\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0579 - val_loss: 0.0680\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0579 - val_loss: 0.0682\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0565 - val_loss: 0.0736\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0565 - val_loss: 0.0694\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0561 - val_loss: 0.0691\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0561 - val_loss: 0.0690\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0563 - val_loss: 0.0720\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0587 - val_loss: 0.0712\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0555 - val_loss: 0.0686\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0561 - val_loss: 0.0692\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0550 - val_loss: 0.0704\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0571 - val_loss: 0.0694\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0548 - val_loss: 0.0716\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0555 - val_loss: 0.0695\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0542 - val_loss: 0.0696\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0548 - val_loss: 0.0722\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.2914 - val_loss: 0.1566\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1617 - val_loss: 0.1366\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1232 - val_loss: 0.1050\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1069 - val_loss: 0.0908\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0930 - val_loss: 0.0824\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0873 - val_loss: 0.0787\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0850 - val_loss: 0.0779\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0811 - val_loss: 0.0758\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0885 - val_loss: 0.0888\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0816 - val_loss: 0.0775\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0803 - val_loss: 0.0750\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0772 - val_loss: 0.0748\n",
      "Epoch 13/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0784 - val_loss: 0.0749\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0775 - val_loss: 0.0837\n",
      "Epoch 15/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0790 - val_loss: 0.0760\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0756 - val_loss: 0.0767\n",
      "Epoch 17/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0715 - val_loss: 0.0761\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0729 - val_loss: 0.0758\n",
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0728 - val_loss: 0.0760\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0798 - val_loss: 0.0760\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0726 - val_loss: 0.0767\n",
      "Epoch 22/45\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0708 - val_loss: 0.0774\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0721 - val_loss: 0.0839\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0714 - val_loss: 0.0777\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0697 - val_loss: 0.0827\n",
      "Epoch 26/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0724 - val_loss: 0.0777\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0702 - val_loss: 0.0789\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0709 - val_loss: 0.0801\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0681 - val_loss: 0.0809\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0680 - val_loss: 0.0792\n",
      "Epoch 31/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0693 - val_loss: 0.0816\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0676 - val_loss: 0.0797\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0665 - val_loss: 0.0801\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0666 - val_loss: 0.0845\n",
      "Epoch 35/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0676 - val_loss: 0.0824\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0663 - val_loss: 0.0820\n",
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0660 - val_loss: 0.0814\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0645 - val_loss: 0.0815\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0667 - val_loss: 0.0820\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0661 - val_loss: 0.0821\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0658 - val_loss: 0.0825\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0655 - val_loss: 0.0839\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0665 - val_loss: 0.0829\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0662 - val_loss: 0.0857\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0640 - val_loss: 0.0838\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.2532 - val_loss: 0.1398\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1521 - val_loss: 0.1507\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1199 - val_loss: 0.0994\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1080 - val_loss: 0.0941\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0942 - val_loss: 0.0824\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0879 - val_loss: 0.0728\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0887 - val_loss: 0.0782\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0805 - val_loss: 0.0695\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0804 - val_loss: 0.0710\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0769 - val_loss: 0.0687\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0781 - val_loss: 0.0794\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0809 - val_loss: 0.0708\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0767 - val_loss: 0.0911\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0751 - val_loss: 0.0702\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0706 - val_loss: 0.0718\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0714 - val_loss: 0.0713\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0679 - val_loss: 0.0749\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0697 - val_loss: 0.0755\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0692 - val_loss: 0.0723\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0681 - val_loss: 0.0730\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0632 - val_loss: 0.0734\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0647 - val_loss: 0.0745\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0652 - val_loss: 0.0757\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.2811 - val_loss: 0.1549\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1391 - val_loss: 0.1137\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1241 - val_loss: 0.1157\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1099 - val_loss: 0.0985\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0996 - val_loss: 0.0923\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0919 - val_loss: 0.0850\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0917 - val_loss: 0.0876\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0834 - val_loss: 0.0766\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0805 - val_loss: 0.0755\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0787 - val_loss: 0.0740\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0780 - val_loss: 0.0737\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0800 - val_loss: 0.0794\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0785 - val_loss: 0.0771\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0766 - val_loss: 0.0745\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0739 - val_loss: 0.0729\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0725 - val_loss: 0.0731\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0703 - val_loss: 0.0739\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0747 - val_loss: 0.0732\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0718 - val_loss: 0.0740\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0685 - val_loss: 0.0740\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0687 - val_loss: 0.0731\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0665 - val_loss: 0.0740\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0672 - val_loss: 0.0755\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1870 - val_loss: 0.1528\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1397 - val_loss: 0.1486\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1161 - val_loss: 0.1066\n",
      "Epoch 4/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1010 - val_loss: 0.1001\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0928 - val_loss: 0.0915\n",
      "Epoch 6/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0874 - val_loss: 0.0892\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0834 - val_loss: 0.0810\n",
      "Epoch 8/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0819 - val_loss: 0.0799\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0787 - val_loss: 0.0799\n",
      "Epoch 10/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0774 - val_loss: 0.0802\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0763 - val_loss: 0.0750\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0766 - val_loss: 0.0745\n",
      "Epoch 13/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0741 - val_loss: 0.0750\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0720 - val_loss: 0.0737\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0736 - val_loss: 0.0732\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0708 - val_loss: 0.0728\n",
      "Epoch 17/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0688 - val_loss: 0.0729\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0685 - val_loss: 0.0772\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0708 - val_loss: 0.0732\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0697 - val_loss: 0.0728\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0712 - val_loss: 0.0729\n",
      "Epoch 22/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0674 - val_loss: 0.0734\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0665 - val_loss: 0.0746\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0674 - val_loss: 0.0759\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0675 - val_loss: 0.0793\n",
      "Epoch 26/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0657 - val_loss: 0.0730\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0640 - val_loss: 0.0742\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0650 - val_loss: 0.0734\n",
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0674 - val_loss: 0.0744\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0628 - val_loss: 0.0737\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0606 - val_loss: 0.0782\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 0.839190, val loss - 0.117354\n",
      "Epoch 2/15: loss - 0.147170, val loss - 0.110010\n",
      "Epoch 3/15: loss - 0.084773, val loss - 0.091320\n",
      "Epoch 4/15: loss - 0.082999, val loss - 0.081030\n",
      "Epoch 5/15: loss - 0.078959, val loss - 0.088771\n",
      "Epoch 6/15: loss - 0.078313, val loss - 0.083625\n",
      "Epoch 7/15: loss - 0.078154, val loss - 0.085730\n",
      "Epoch 8/15: loss - 0.085770, val loss - 0.090270\n",
      "Epoch 9/15: loss - 0.082087, val loss - 0.092048\n",
      "Epoch 10/15: loss - 0.085557, val loss - 0.122628\n",
      "Epoch 11/15: loss - 0.094891, val loss - 0.103499\n",
      "Epoch 12/15: loss - 0.080999, val loss - 0.088942\n",
      "Epoch 13/15: loss - 0.078231, val loss - 0.088470\n",
      "Epoch 14/15: loss - 0.078358, val loss - 0.089313\n",
      "Epoch 15/15: loss - 0.077349, val loss - 0.085801\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.491499, val loss - 0.143983\n",
      "Epoch 2/176: loss - 0.157256, val loss - 0.114414\n",
      "Epoch 3/176: loss - 0.129522, val loss - 0.130607\n",
      "Epoch 4/176: loss - 0.125370, val loss - 0.173529\n",
      "Epoch 5/176: loss - 0.125620, val loss - 0.117628\n",
      "Epoch 6/176: loss - 0.114808, val loss - 0.148998\n",
      "Epoch 7/176: loss - 0.116791, val loss - 0.107241\n",
      "Epoch 8/176: loss - 0.113333, val loss - 0.100221\n",
      "Epoch 9/176: loss - 0.115676, val loss - 0.101843\n",
      "Epoch 10/176: loss - 0.097950, val loss - 0.133905\n",
      "Epoch 11/176: loss - 0.104106, val loss - 0.090734\n",
      "Epoch 12/176: loss - 0.095452, val loss - 0.102098\n",
      "Epoch 13/176: loss - 0.095687, val loss - 0.118868\n",
      "Epoch 14/176: loss - 0.088518, val loss - 0.097939\n",
      "Epoch 15/176: loss - 0.083016, val loss - 0.080693\n",
      "Epoch 16/176: loss - 0.079506, val loss - 0.081585\n",
      "Epoch 17/176: loss - 0.075257, val loss - 0.079281\n",
      "Epoch 18/176: loss - 0.071169, val loss - 0.082046\n",
      "Epoch 19/176: loss - 0.068653, val loss - 0.088695\n",
      "Epoch 20/176: loss - 0.075498, val loss - 0.076918\n",
      "Epoch 21/176: loss - 0.066959, val loss - 0.071156\n",
      "Epoch 22/176: loss - 0.064469, val loss - 0.073209\n",
      "Epoch 23/176: loss - 0.062464, val loss - 0.072664\n",
      "Epoch 24/176: loss - 0.063546, val loss - 0.073614\n",
      "Epoch 25/176: loss - 0.062408, val loss - 0.078607\n",
      "Epoch 26/176: loss - 0.059574, val loss - 0.071754\n",
      "Epoch 27/176: loss - 0.056942, val loss - 0.097599\n",
      "Epoch 28/176: loss - 0.062666, val loss - 0.086664\n",
      "Epoch 29/176: loss - 0.056803, val loss - 0.075325\n",
      "Epoch 30/176: loss - 0.052439, val loss - 0.075079\n",
      "Epoch 31/176: loss - 0.056245, val loss - 0.080578\n",
      "Epoch 32/176: loss - 0.055017, val loss - 0.074232\n",
      "Epoch 33/176: loss - 0.054228, val loss - 0.081525\n",
      "Epoch 34/176: loss - 0.050836, val loss - 0.072246\n",
      "Epoch 35/176: loss - 0.054374, val loss - 0.080673\n",
      "Epoch 36/176: loss - 0.056581, val loss - 0.072663\n",
      "Epoch 37/176: loss - 0.052768, val loss - 0.077113\n",
      "Epoch 38/176: loss - 0.051246, val loss - 0.078927\n",
      "Epoch 39/176: loss - 0.051547, val loss - 0.083798\n",
      "Epoch 40/176: loss - 0.049812, val loss - 0.080731\n",
      "Epoch 41/176: loss - 0.049437, val loss - 0.082352\n",
      "Epoch 42/176: loss - 0.049675, val loss - 0.076402\n",
      "Epoch 43/176: loss - 0.051401, val loss - 0.084942\n",
      "Epoch 44/176: loss - 0.049966, val loss - 0.090059\n",
      "Epoch 45/176: loss - 0.050574, val loss - 0.087291\n",
      "Epoch 46/176: loss - 0.049606, val loss - 0.088021\n",
      "Epoch 47/176: loss - 0.051927, val loss - 0.079514\n",
      "Epoch 48/176: loss - 0.050488, val loss - 0.082085\n",
      "Epoch 49/176: loss - 0.050996, val loss - 0.077833\n",
      "Epoch 50/176: loss - 0.050472, val loss - 0.084839\n",
      "Epoch 51/176: loss - 0.050372, val loss - 0.087965\n",
      "Epoch 52/176: loss - 0.048895, val loss - 0.092559\n",
      "Epoch 53/176: loss - 0.055002, val loss - 0.077621\n",
      "Epoch 54/176: loss - 0.049629, val loss - 0.103087\n",
      "Epoch 55/176: loss - 0.052402, val loss - 0.078090\n",
      "Epoch 56/176: loss - 0.047696, val loss - 0.084565\n",
      "Epoch 57/176: loss - 0.048459, val loss - 0.093345\n",
      "Epoch 58/176: loss - 0.045696, val loss - 0.090236\n",
      "Epoch 59/176: loss - 0.045992, val loss - 0.093644\n",
      "Epoch 60/176: loss - 0.046475, val loss - 0.088724\n",
      "Epoch 61/176: loss - 0.048973, val loss - 0.081694\n",
      "Epoch 62/176: loss - 0.046351, val loss - 0.095970\n",
      "Epoch 63/176: loss - 0.045913, val loss - 0.090985\n",
      "Epoch 64/176: loss - 0.050755, val loss - 0.107574\n",
      "Epoch 65/176: loss - 0.058322, val loss - 0.076243\n",
      "Epoch 66/176: loss - 0.048254, val loss - 0.084564\n",
      "Epoch 67/176: loss - 0.046983, val loss - 0.081290\n",
      "Epoch 68/176: loss - 0.045389, val loss - 0.084383\n",
      "Epoch 69/176: loss - 0.043602, val loss - 0.091579\n",
      "Epoch 70/176: loss - 0.048692, val loss - 0.084462\n",
      "Epoch 71/176: loss - 0.061980, val loss - 0.105511\n",
      "Epoch 72/176: loss - 0.105893, val loss - 0.091397\n",
      "Epoch 73/176: loss - 0.089662, val loss - 0.089976\n",
      "Epoch 74/176: loss - 0.081866, val loss - 0.087489\n",
      "Epoch 75/176: loss - 0.082051, val loss - 0.084123\n",
      "Epoch 76/176: loss - 0.082442, val loss - 0.102962\n",
      "Epoch 77/176: loss - 0.085984, val loss - 0.106946\n",
      "Epoch 78/176: loss - 0.077752, val loss - 0.085117\n",
      "Epoch 79/176: loss - 0.071556, val loss - 0.084628\n",
      "Epoch 80/176: loss - 0.073271, val loss - 0.079237\n",
      "Epoch 81/176: loss - 0.074161, val loss - 0.083547\n",
      "Epoch 82/176: loss - 0.083915, val loss - 0.079789\n",
      "Epoch 83/176: loss - 0.078802, val loss - 0.085819\n",
      "Epoch 84/176: loss - 0.074612, val loss - 0.077579\n",
      "Epoch 85/176: loss - 0.080985, val loss - 0.085127\n",
      "Epoch 86/176: loss - 0.076586, val loss - 0.082933\n",
      "Epoch 87/176: loss - 0.072544, val loss - 0.087667\n",
      "Epoch 88/176: loss - 0.072957, val loss - 0.085472\n",
      "Epoch 89/176: loss - 0.071734, val loss - 0.100212\n",
      "Epoch 90/176: loss - 0.069424, val loss - 0.091710\n",
      "Epoch 91/176: loss - 0.069921, val loss - 0.079393\n",
      "Epoch 92/176: loss - 0.074185, val loss - 0.086072\n",
      "Epoch 93/176: loss - 0.066339, val loss - 0.086131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/176: loss - 0.063434, val loss - 0.079720\n",
      "Epoch 95/176: loss - 0.066085, val loss - 0.078440\n",
      "Epoch 96/176: loss - 0.094407, val loss - 0.084306\n",
      "Epoch 97/176: loss - 0.078791, val loss - 0.101840\n",
      "Epoch 98/176: loss - 0.070019, val loss - 0.080852\n",
      "Epoch 99/176: loss - 0.068762, val loss - 0.096906\n",
      "Epoch 100/176: loss - 0.065569, val loss - 0.079420\n",
      "Epoch 101/176: loss - 0.064962, val loss - 0.083951\n",
      "Epoch 102/176: loss - 0.069214, val loss - 0.081797\n",
      "Epoch 103/176: loss - 0.077941, val loss - 0.088894\n",
      "Epoch 104/176: loss - 0.066587, val loss - 0.090657\n",
      "Epoch 105/176: loss - 0.073732, val loss - 0.085751\n",
      "Epoch 106/176: loss - 0.075712, val loss - 0.091196\n",
      "Epoch 107/176: loss - 0.062362, val loss - 0.081203\n",
      "Epoch 108/176: loss - 0.064801, val loss - 0.088795\n",
      "Epoch 109/176: loss - 0.063668, val loss - 0.083078\n",
      "Epoch 110/176: loss - 0.057112, val loss - 0.082276\n",
      "Epoch 111/176: loss - 0.070849, val loss - 0.081630\n",
      "Epoch 112/176: loss - 0.078381, val loss - 0.091791\n",
      "Epoch 113/176: loss - 0.062295, val loss - 0.078358\n",
      "Epoch 114/176: loss - 0.066759, val loss - 0.085076\n",
      "Epoch 115/176: loss - 0.060606, val loss - 0.082436\n",
      "Epoch 116/176: loss - 0.064122, val loss - 0.093750\n",
      "Epoch 117/176: loss - 0.066567, val loss - 0.089589\n",
      "Epoch 118/176: loss - 0.070545, val loss - 0.079906\n",
      "Epoch 119/176: loss - 0.081525, val loss - 0.080195\n",
      "Epoch 120/176: loss - 0.071444, val loss - 0.091689\n",
      "Epoch 121/176: loss - 0.069124, val loss - 0.088361\n",
      "Epoch 122/176: loss - 0.062917, val loss - 0.085591\n",
      "Epoch 123/176: loss - 0.062520, val loss - 0.082002\n",
      "Epoch 124/176: loss - 0.055754, val loss - 0.086013\n",
      "Epoch 125/176: loss - 0.064348, val loss - 0.085440\n",
      "Epoch 126/176: loss - 0.062710, val loss - 0.082852\n",
      "Epoch 127/176: loss - 0.055184, val loss - 0.091922\n",
      "Epoch 128/176: loss - 0.050899, val loss - 0.090785\n",
      "Epoch 129/176: loss - 0.049594, val loss - 0.089190\n",
      "Epoch 130/176: loss - 0.047187, val loss - 0.083691\n",
      "Epoch 131/176: loss - 0.048125, val loss - 0.086305\n",
      "Epoch 132/176: loss - 0.045954, val loss - 0.090426\n",
      "Epoch 133/176: loss - 0.045549, val loss - 0.093598\n",
      "Epoch 134/176: loss - 0.043867, val loss - 0.091135\n",
      "Epoch 135/176: loss - 0.041871, val loss - 0.086837\n",
      "Epoch 136/176: loss - 0.043143, val loss - 0.087893\n",
      "Epoch 137/176: loss - 0.041659, val loss - 0.088840\n",
      "Epoch 138/176: loss - 0.040565, val loss - 0.086096\n",
      "Epoch 139/176: loss - 0.040579, val loss - 0.091182\n",
      "Epoch 140/176: loss - 0.040364, val loss - 0.086774\n",
      "Epoch 141/176: loss - 0.042142, val loss - 0.096270\n",
      "Epoch 142/176: loss - 0.044144, val loss - 0.088131\n",
      "Epoch 143/176: loss - 0.046767, val loss - 0.086026\n",
      "Epoch 144/176: loss - 0.044819, val loss - 0.088598\n",
      "Epoch 145/176: loss - 0.043444, val loss - 0.084975\n",
      "Epoch 146/176: loss - 0.040281, val loss - 0.088038\n",
      "Epoch 147/176: loss - 0.041814, val loss - 0.090762\n",
      "Epoch 148/176: loss - 0.041533, val loss - 0.094772\n",
      "Epoch 149/176: loss - 0.043063, val loss - 0.092745\n",
      "Epoch 150/176: loss - 0.041340, val loss - 0.088873\n",
      "Epoch 151/176: loss - 0.039570, val loss - 0.087873\n",
      "Epoch 152/176: loss - 0.041855, val loss - 0.089941\n",
      "Epoch 153/176: loss - 0.041490, val loss - 0.086248\n",
      "Epoch 154/176: loss - 0.040627, val loss - 0.087710\n",
      "Epoch 155/176: loss - 0.039863, val loss - 0.086785\n",
      "Epoch 156/176: loss - 0.039685, val loss - 0.086702\n",
      "Epoch 157/176: loss - 0.040721, val loss - 0.088818\n",
      "Epoch 158/176: loss - 0.039443, val loss - 0.089275\n",
      "Epoch 159/176: loss - 0.038601, val loss - 0.086886\n",
      "Epoch 160/176: loss - 0.039900, val loss - 0.088937\n",
      "Epoch 161/176: loss - 0.039524, val loss - 0.086063\n",
      "Epoch 162/176: loss - 0.039932, val loss - 0.088986\n",
      "Epoch 163/176: loss - 0.039160, val loss - 0.086543\n",
      "Epoch 164/176: loss - 0.039745, val loss - 0.092102\n",
      "Epoch 165/176: loss - 0.040228, val loss - 0.085493\n",
      "Epoch 166/176: loss - 0.039393, val loss - 0.087370\n",
      "Epoch 167/176: loss - 0.039476, val loss - 0.091444\n",
      "Epoch 168/176: loss - 0.040122, val loss - 0.084219\n",
      "Epoch 169/176: loss - 0.039221, val loss - 0.084417\n",
      "Epoch 170/176: loss - 0.042621, val loss - 0.086134\n",
      "Epoch 171/176: loss - 0.038463, val loss - 0.085402\n",
      "Epoch 172/176: loss - 0.041918, val loss - 0.092715\n",
      "Epoch 173/176: loss - 0.038060, val loss - 0.095048\n",
      "Epoch 174/176: loss - 0.041706, val loss - 0.095461\n",
      "Epoch 175/176: loss - 0.040140, val loss - 0.087803\n",
      "Epoch 176/176: loss - 0.041192, val loss - 0.091482\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.174705, val loss - 0.159141\n",
      "Epoch 2/24: loss - 0.167396, val loss - 0.193215\n",
      "Epoch 3/24: loss - 0.156633, val loss - 0.200592\n",
      "Epoch 4/24: loss - 0.127866, val loss - 0.103702\n",
      "Epoch 5/24: loss - 0.120513, val loss - 0.109656\n",
      "Epoch 6/24: loss - 0.114495, val loss - 0.140759\n",
      "Epoch 7/24: loss - 0.111107, val loss - 0.109944\n",
      "Epoch 8/24: loss - 0.112963, val loss - 0.115582\n",
      "Epoch 9/24: loss - 0.099740, val loss - 0.096616\n",
      "Epoch 10/24: loss - 0.098989, val loss - 0.083758\n",
      "Epoch 11/24: loss - 0.101038, val loss - 0.108159\n",
      "Epoch 12/24: loss - 0.105780, val loss - 0.093638\n",
      "Epoch 13/24: loss - 0.090904, val loss - 0.072698\n",
      "Epoch 14/24: loss - 0.098562, val loss - 0.073419\n",
      "Epoch 15/24: loss - 0.087054, val loss - 0.075143\n",
      "Epoch 16/24: loss - 0.087507, val loss - 0.080808\n",
      "Epoch 17/24: loss - 0.086993, val loss - 0.078644\n",
      "Epoch 18/24: loss - 0.091226, val loss - 0.080854\n",
      "Epoch 19/24: loss - 0.086349, val loss - 0.085527\n",
      "Epoch 20/24: loss - 0.084255, val loss - 0.076874\n",
      "Epoch 21/24: loss - 0.082289, val loss - 0.073845\n",
      "Epoch 22/24: loss - 0.079013, val loss - 0.076596\n",
      "Epoch 23/24: loss - 0.077652, val loss - 0.073649\n",
      "Epoch 24/24: loss - 0.075441, val loss - 0.076894\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.233974, val loss - 0.142726\n",
      "Epoch 2/66: loss - 0.135925, val loss - 0.136061\n",
      "Epoch 3/66: loss - 0.134651, val loss - 0.139915\n",
      "Epoch 4/66: loss - 0.132096, val loss - 0.125534\n",
      "Epoch 5/66: loss - 0.139501, val loss - 0.136394\n",
      "Epoch 6/66: loss - 0.132424, val loss - 0.122597\n",
      "Epoch 7/66: loss - 0.128673, val loss - 0.146642\n",
      "Epoch 8/66: loss - 0.125113, val loss - 0.104702\n",
      "Epoch 9/66: loss - 0.124107, val loss - 0.124821\n",
      "Epoch 10/66: loss - 0.117907, val loss - 0.115602\n",
      "Epoch 11/66: loss - 0.109481, val loss - 0.105704\n",
      "Epoch 12/66: loss - 0.112351, val loss - 0.118376\n",
      "Epoch 13/66: loss - 0.106900, val loss - 0.100495\n",
      "Epoch 14/66: loss - 0.105061, val loss - 0.105478\n",
      "Epoch 15/66: loss - 0.110964, val loss - 0.111224\n",
      "Epoch 16/66: loss - 0.104235, val loss - 0.094600\n",
      "Epoch 17/66: loss - 0.097473, val loss - 0.088849\n",
      "Epoch 18/66: loss - 0.096107, val loss - 0.097399\n",
      "Epoch 19/66: loss - 0.093921, val loss - 0.091860\n",
      "Epoch 20/66: loss - 0.098620, val loss - 0.104158\n",
      "Epoch 21/66: loss - 0.094200, val loss - 0.083768\n",
      "Epoch 22/66: loss - 0.087239, val loss - 0.089733\n",
      "Epoch 23/66: loss - 0.089199, val loss - 0.086362\n",
      "Epoch 24/66: loss - 0.087628, val loss - 0.084175\n",
      "Epoch 25/66: loss - 0.094691, val loss - 0.088768\n",
      "Epoch 26/66: loss - 0.085129, val loss - 0.096460\n",
      "Epoch 27/66: loss - 0.088371, val loss - 0.084172\n",
      "Epoch 28/66: loss - 0.091275, val loss - 0.086483\n",
      "Epoch 29/66: loss - 0.082776, val loss - 0.077871\n",
      "Epoch 30/66: loss - 0.082222, val loss - 0.081596\n",
      "Epoch 31/66: loss - 0.079821, val loss - 0.078861\n",
      "Epoch 32/66: loss - 0.078886, val loss - 0.079260\n",
      "Epoch 33/66: loss - 0.077708, val loss - 0.076838\n",
      "Epoch 34/66: loss - 0.078583, val loss - 0.078458\n",
      "Epoch 35/66: loss - 0.080230, val loss - 0.089727\n",
      "Epoch 36/66: loss - 0.084045, val loss - 0.077728\n",
      "Epoch 37/66: loss - 0.080199, val loss - 0.078701\n",
      "Epoch 38/66: loss - 0.076098, val loss - 0.079015\n",
      "Epoch 39/66: loss - 0.079137, val loss - 0.078105\n",
      "Epoch 40/66: loss - 0.078911, val loss - 0.077818\n",
      "Epoch 41/66: loss - 0.076750, val loss - 0.077919\n",
      "Epoch 42/66: loss - 0.077879, val loss - 0.080169\n",
      "Epoch 43/66: loss - 0.077232, val loss - 0.077159\n",
      "Epoch 44/66: loss - 0.075938, val loss - 0.079700\n",
      "Epoch 45/66: loss - 0.075533, val loss - 0.077735\n",
      "Epoch 46/66: loss - 0.074391, val loss - 0.076582\n",
      "Epoch 47/66: loss - 0.073712, val loss - 0.078504\n",
      "Epoch 48/66: loss - 0.072537, val loss - 0.075533\n",
      "Epoch 49/66: loss - 0.071036, val loss - 0.078964\n",
      "Epoch 50/66: loss - 0.071136, val loss - 0.076040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/66: loss - 0.069829, val loss - 0.076939\n",
      "Epoch 52/66: loss - 0.073217, val loss - 0.080657\n",
      "Epoch 53/66: loss - 0.074227, val loss - 0.077378\n",
      "Epoch 54/66: loss - 0.072944, val loss - 0.081187\n",
      "Epoch 55/66: loss - 0.070234, val loss - 0.075076\n",
      "Epoch 56/66: loss - 0.072174, val loss - 0.080131\n",
      "Epoch 57/66: loss - 0.072824, val loss - 0.075245\n",
      "Epoch 58/66: loss - 0.069722, val loss - 0.076394\n",
      "Epoch 59/66: loss - 0.069671, val loss - 0.081595\n",
      "Epoch 60/66: loss - 0.070033, val loss - 0.076553\n",
      "Epoch 61/66: loss - 0.068205, val loss - 0.078366\n",
      "Epoch 62/66: loss - 0.068732, val loss - 0.077816\n",
      "Epoch 63/66: loss - 0.068819, val loss - 0.080666\n",
      "Epoch 64/66: loss - 0.070006, val loss - 0.079051\n",
      "Epoch 65/66: loss - 0.068847, val loss - 0.079443\n",
      "Epoch 66/66: loss - 0.067810, val loss - 0.076918\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.190764, val loss - 0.136318\n",
      "Epoch 2/24: loss - 0.109470, val loss - 0.129403\n",
      "Epoch 3/24: loss - 0.115216, val loss - 0.148109\n",
      "Epoch 4/24: loss - 0.125191, val loss - 0.101327\n",
      "Epoch 5/24: loss - 0.105709, val loss - 0.165990\n",
      "Epoch 6/24: loss - 0.104766, val loss - 0.095769\n",
      "Epoch 7/24: loss - 0.095818, val loss - 0.082184\n",
      "Epoch 8/24: loss - 0.092782, val loss - 0.102280\n",
      "Epoch 9/24: loss - 0.089937, val loss - 0.091341\n",
      "Epoch 10/24: loss - 0.094860, val loss - 0.091420\n",
      "Epoch 11/24: loss - 0.086382, val loss - 0.090178\n",
      "Epoch 12/24: loss - 0.083649, val loss - 0.080574\n",
      "Epoch 13/24: loss - 0.083313, val loss - 0.090316\n",
      "Epoch 14/24: loss - 0.084691, val loss - 0.086503\n",
      "Epoch 15/24: loss - 0.084351, val loss - 0.084973\n",
      "Epoch 16/24: loss - 0.082510, val loss - 0.089581\n",
      "Epoch 17/24: loss - 0.086357, val loss - 0.085900\n",
      "Epoch 18/24: loss - 0.078718, val loss - 0.076827\n",
      "Epoch 19/24: loss - 0.073522, val loss - 0.084678\n",
      "Epoch 20/24: loss - 0.080816, val loss - 0.073654\n",
      "Epoch 21/24: loss - 0.077467, val loss - 0.082919\n",
      "Epoch 22/24: loss - 0.077371, val loss - 0.103005\n",
      "Epoch 23/24: loss - 0.082611, val loss - 0.092877\n",
      "Epoch 24/24: loss - 0.080870, val loss - 0.083037\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1394 - val_loss: 0.0828\n",
      "Epoch 2/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.1020\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0747 - val_loss: 0.0857\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0761\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0710\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0829\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0688\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0742\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0639\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0741\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0666\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0741\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0662\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0753\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0710\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0724\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0703\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0658\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0817\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0751\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0699\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0672\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0674\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0752\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0707\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0781\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0685\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.1104\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1711 - val_loss: 0.1090\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1087 - val_loss: 0.1005\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.1014\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0913\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0831\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0825\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0829\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0875\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.0825\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0807\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0789\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0859\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0833\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0859\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0841\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0850\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0918\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0798\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0854\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0848\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.1025\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0887\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0854\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0936\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0855\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0977\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0898\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.1087\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0986\n",
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.1031\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.1042\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.1104\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.1027\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0962\n",
      "Epoch 1/29\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2125 - val_loss: 0.0939\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0954 - val_loss: 0.0852\n",
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0883\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0818\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.1079\n",
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0719 - val_loss: 0.0769\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0802\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0843\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0861\n",
      "Epoch 10/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0811\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0803\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0814\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0937\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.1020\n",
      "Epoch 15/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.1025\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0869\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0839\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0896\n",
      "Epoch 19/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0839\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0915\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0839\n",
      "Epoch 22/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0914\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0902\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.1013\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0881\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0941\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0960\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.1065\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.1137\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3984 - val_loss: 0.1477\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1234\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1259 - val_loss: 0.1129\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1036 - val_loss: 0.0969\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.1133\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0860\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0888\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0954\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0946\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0825\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0885\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0785\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0880\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0808\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0815\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0836\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0758\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0821\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0883\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0803\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0917\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0871\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0828\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0811\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0769\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0965\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0793\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0830\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0801\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0823\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0750\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0987\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0842\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0935\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5362 - val_loss: 0.4910\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2945 - val_loss: 0.2712\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1766 - val_loss: 0.1768\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1491 - val_loss: 0.1533\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1462 - val_loss: 0.1505\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 0.1512\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1402 - val_loss: 0.1503\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1375 - val_loss: 0.1448\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1353 - val_loss: 0.1433\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1386\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1303 - val_loss: 0.1376\n",
      "Epoch 12/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1278 - val_loss: 0.1348\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1253 - val_loss: 0.1312\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1227 - val_loss: 0.1286\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1198 - val_loss: 0.1252\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.1234\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.1180\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1096 - val_loss: 0.1143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1054 - val_loss: 0.1088\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1004 - val_loss: 0.1020\n",
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0952 - val_loss: 0.0978\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.0929\n",
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0907\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.0871\n",
      "Epoch 25/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0864\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0825\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.0835\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0811\n",
      "Epoch 29/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0800\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0725 - val_loss: 0.0821\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.0799\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0787\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0781\n",
      "Epoch 34/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0785\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0776\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0769\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0826\n",
      "Epoch 38/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0771\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0766\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0774\n",
      "Epoch 41/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0797\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0772\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0768\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0781\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0773\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0777\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0801\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0781\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0782\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0792\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0795\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0791\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0796\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0809\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0804\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0837\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0809\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0829\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0829\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0817\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0839\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0833\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0840\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0854\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0841\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0840\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0842\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0847\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0872\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0850\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0858\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0865\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0886\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0851\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0884\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0860\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.0870\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0863\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0867\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0877\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0900\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0911\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0888\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0872\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0872\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0899\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.1041\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0880\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0867\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0873\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0876\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0888\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0891\n",
      "Epoch 94/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0890\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0880\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0889\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0889\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0887\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0897\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0889\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0893\n",
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0909\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0912\n",
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0887\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0902\n",
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0882\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0875\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1592 - val_loss: 0.1199\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.0910\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0839\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0806\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0799\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0814\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0786\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0755\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0746\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0746\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0760\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0798\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0753\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0854\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0717\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0730\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0731\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0734\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0749\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0713\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0728\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0800\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0699\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0714\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0712\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0934\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0763\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0775\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0725\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0706\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0755\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0727\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0750\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0690\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1547 - val_loss: 0.1552\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1138\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.0958\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.0930\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0905\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0902\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0857\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0804\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0796\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0834\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0791\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0786\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0811\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0782\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0787\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0786\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0917\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.1033\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0943\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0804\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0867\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0848\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0808\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0853\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0861\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0852\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0820\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0832\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0964\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0939\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0856\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0838\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0970\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0837\n",
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0896\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0889\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3469 - val_loss: 0.3426\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2112 - val_loss: 0.2175\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1658 - val_loss: 0.1686\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1590 - val_loss: 0.1607\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1551 - val_loss: 0.1571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1506 - val_loss: 0.1555\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1461 - val_loss: 0.1511\n",
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1416 - val_loss: 0.1447\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1368 - val_loss: 0.1394\n",
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1315 - val_loss: 0.1377\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.1274\n",
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1194 - val_loss: 0.1223\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1118 - val_loss: 0.1152\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1052 - val_loss: 0.1071\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0989 - val_loss: 0.0982\n",
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0952 - val_loss: 0.1007\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0935 - val_loss: 0.0940\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0918 - val_loss: 0.0908\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.0901\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0893\n",
      "Epoch 21/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0880 - val_loss: 0.0884\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0868\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.0859\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.0856\n",
      "Epoch 25/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.0842\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0870\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.0828\n",
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.0824\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0857\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0799\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.0850\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0785\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0806\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0790 - val_loss: 0.0803\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.0781\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0793 - val_loss: 0.0829\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.0778\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0764\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0773 - val_loss: 0.0799\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0763\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0767\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0755\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0760\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0753\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.0742\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0781\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0747\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0742\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0751\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0733\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0741\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0739\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0748\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0735\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0713 - val_loss: 0.0724\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0739\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.0737\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0744\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0720\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0742\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0722\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0725\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0742\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0723\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0731\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0732\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0722\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0717\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0750\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0739\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0720\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6704 - val_loss: 0.5698\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.2883\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1704 - val_loss: 0.1594\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.1356\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1294 - val_loss: 0.1322\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1230 - val_loss: 0.1319\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1236\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.1159\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.1117\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1005 - val_loss: 0.1053\n",
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.1004\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.0991\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.0963\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0953\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0912\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.0925\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0886\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0864\n",
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0847\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0836\n",
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0816\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0823\n",
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0805\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0789\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0803\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0775\n",
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0774\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0787\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0761\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0784\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0760\n",
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0768\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0766\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0774\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0769\n",
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0772\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0770\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0811\n",
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0775\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0779\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0792\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0790\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0795\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0793\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0801\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0803\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0800\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 0.0805\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0803\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0809\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0809\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0825\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0819\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0832\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0814\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0828\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0859\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0830\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0818\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0821\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0826\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0821\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2335 - val_loss: 0.1545\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1538\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1291 - val_loss: 0.1219\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1004 - val_loss: 0.0900\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0788\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0763\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0734 - val_loss: 0.0738\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0717\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0768\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0717\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0729\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0749\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0798\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0745\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0751\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0766\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0793\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0782\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0787\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0834\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0879\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0850\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0800\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0793\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0833\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0960\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0055 - val_loss: 0.6465\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 0.2728\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2183 - val_loss: 0.1959\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1594\n",
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1284 - val_loss: 0.1332\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1139 - val_loss: 0.1238\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1048 - val_loss: 0.1139\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.1111\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.1026\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.1021\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0942\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0899\n",
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0905\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0897\n",
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0867\n",
      "Epoch 17/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0831\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0864\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0809\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0806\n",
      "Epoch 21/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0820\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0805\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0791\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0811\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0774\n",
      "Epoch 26/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0788\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0768\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0791\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0762\n",
      "Epoch 30/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0770\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0776\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0757\n",
      "Epoch 33/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0758\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0751\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0766\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0749\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0756\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0749\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0744\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0757\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0762\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0763\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0740\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0774\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0738\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0747\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0800\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0759\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0741\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0747\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0749\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0756\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0743\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0754\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0746\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0742\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0740\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0771\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0733\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0769\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0734\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0748\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0766\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0741\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0767\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0737\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0752\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0751\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0733\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0743\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0790\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0784\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0764\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0730\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0751\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0781\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0741\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0742\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.0734\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0738\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0827\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0737\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0761\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0742\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0743\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0751\n",
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0804\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0748\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0749\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0803\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0744\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0750\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0748\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0755\n",
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0778\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0753\n",
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0760\n",
      "Epoch 99/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0762\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0757\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0786\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0795\n",
      "Epoch 103/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0764\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0762\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0763\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0769\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0775\n",
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0770\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0773\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0775\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0807\n",
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0798\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0821\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0781\n",
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0781\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0803\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0803\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0792\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0843\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0820\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0790\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0788\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0785\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0811\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0800\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0817\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0788\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0821\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0794\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0822\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0833\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0814\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0825\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0809\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0834\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0817\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0844\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0811\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.8044 - val_loss: 0.4577\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2233 - val_loss: 0.1566\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1352 - val_loss: 0.1280\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1345 - val_loss: 0.1263\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1295 - val_loss: 0.1285\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1281\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1263 - val_loss: 0.1248\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.1235\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1233 - val_loss: 0.1213\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1203\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1215 - val_loss: 0.1207\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1207 - val_loss: 0.1188\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1202 - val_loss: 0.1189\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 0.1180\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1175\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.1168\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1161\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1164\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.1160\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1162 - val_loss: 0.1160\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1149\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1143\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1156\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1115\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1141 - val_loss: 0.1143\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1125\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1134 - val_loss: 0.1139\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1128 - val_loss: 0.1111\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1130\n",
      "Epoch 30/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1118 - val_loss: 0.1131\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1118 - val_loss: 0.1121\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.1099\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.1126\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 0.1094\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.1096\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.1112\n",
      "Epoch 37/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1088\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1075 - val_loss: 0.1114\n",
      "Epoch 39/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.1066\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1060 - val_loss: 0.1096\n",
      "Epoch 41/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1050 - val_loss: 0.1059\n",
      "Epoch 42/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1052 - val_loss: 0.1095\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1006\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.1087\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.0985\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.1060\n",
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0971\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.0967\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0902\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0945\n",
      "Epoch 51/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0865\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0916\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0880\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0818\n",
      "Epoch 55/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0809\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0901\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0803\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0810\n",
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0813\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0839\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0804\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0848\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0850\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0799\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0815\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0799\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0798\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0804\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0816\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0808\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0850\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0960\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0813\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0886\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0828\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0824\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0824\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0836\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0806\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0813\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0940\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0835\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0885\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0899\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0848\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0815\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0882\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0817\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0823\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0849\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0846\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0873\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0817\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0878\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0867\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0845\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0821\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0829\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0824\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0880\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0822\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0833\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0824\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0837\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0879\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0825\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0825\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0842\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0923\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0849\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0884\n",
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0840\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0872\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0847\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0878\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0857\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0901\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0901\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0885\n",
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0839\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0842\n",
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0858\n",
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0842\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0857\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0848\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0846\n",
      "Epoch 128/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0848\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0868\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0863\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0907\n",
      "Epoch 132/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0856\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0866\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0863\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0894\n",
      "Epoch 136/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0905\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.1024\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0846\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0850\n",
      "Epoch 140/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0901\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0861\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0915\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0888\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0881\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0882\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0870\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0891\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0869\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0966\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3103 - val_loss: 0.1653\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1753 - val_loss: 0.1389\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.1412\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1406 - val_loss: 0.1313\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1362 - val_loss: 0.1383\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.1261\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1282 - val_loss: 0.1238\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1189\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1206 - val_loss: 0.1154\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.1044\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.0986\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.0979\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.0986\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0974\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0912\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0889\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0930\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0899\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0894\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0886\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0908\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0867\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0964\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0885\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0916\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0888\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0914\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0966\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0893\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0878\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0874\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0908\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0935\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0928\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0906\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.1010\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0899\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0911\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0960\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0915\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0923\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0896\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0921\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0983\n",
      "Epoch 45/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0977\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0897\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0968\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0911\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0942\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0959\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0897\n",
      "Epoch 52/56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0920\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.1008\n",
      "Epoch 54/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0905\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0930\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.1034\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1484 - val_loss: 0.1473\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.1472\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1286 - val_loss: 0.1313\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.1245\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.1174\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.1094\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.1080\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1002\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0953\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0920\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0871\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0874\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0846\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0824\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0820\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0832\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0843\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0856\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0846\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0843\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0856\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0857\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0867\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0871\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0884\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0890\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0879\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0879\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0878\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0883\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0891\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0919\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0900\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0904\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0888\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0894\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0899\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0890\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0916\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0909\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0915\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0931\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0904\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0907\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0961\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0920\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0902\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0919\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0909\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0925\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0911\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0923\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0923\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0930\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0940\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0924\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.1008\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0922\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0925\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0907\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5450 - val_loss: 0.2207\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2696 - val_loss: 0.2070\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2099 - val_loss: 0.2249\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1886 - val_loss: 0.1768\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1719 - val_loss: 0.1696\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1583 - val_loss: 0.1542\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1482 - val_loss: 0.1464\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1406 - val_loss: 0.1416\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1328\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1304 - val_loss: 0.1286\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1256 - val_loss: 0.1247\n",
      "Epoch 12/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1223 - val_loss: 0.1195\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 0.1165\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1182\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1139 - val_loss: 0.1108\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1118 - val_loss: 0.1077\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.1108\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1112\n",
      "Epoch 19/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.1025\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.1013\n",
      "Epoch 21/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1001\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0993 - val_loss: 0.0989\n",
      "Epoch 23/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.1017\n",
      "Epoch 24/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.0963\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.0991\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.0937\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0925 - val_loss: 0.0927\n",
      "Epoch 28/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0909\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0906\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0892\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0902\n",
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0904\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0866\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0896\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0890\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0843\n",
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0882\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0831\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0829\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0829\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0853\n",
      "Epoch 1/47\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2166 - val_loss: 0.1249\n",
      "Epoch 2/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1279 - val_loss: 0.0997\n",
      "Epoch 3/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0985 - val_loss: 0.0903\n",
      "Epoch 4/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0875 - val_loss: 0.0898\n",
      "Epoch 5/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0812 - val_loss: 0.0901\n",
      "Epoch 6/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0789 - val_loss: 0.0881\n",
      "Epoch 7/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0814 - val_loss: 0.0860\n",
      "Epoch 8/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0782 - val_loss: 0.0851\n",
      "Epoch 9/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0753 - val_loss: 0.0843\n",
      "Epoch 10/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0767 - val_loss: 0.0849\n",
      "Epoch 11/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0788 - val_loss: 0.0900\n",
      "Epoch 12/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0797 - val_loss: 0.1016\n",
      "Epoch 13/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0791 - val_loss: 0.0796\n",
      "Epoch 14/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0742 - val_loss: 0.0820\n",
      "Epoch 15/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0696 - val_loss: 0.0778\n",
      "Epoch 16/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0718 - val_loss: 0.0789\n",
      "Epoch 17/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0681 - val_loss: 0.0792\n",
      "Epoch 18/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0678 - val_loss: 0.0779\n",
      "Epoch 19/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0673 - val_loss: 0.0751\n",
      "Epoch 20/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0649 - val_loss: 0.0759\n",
      "Epoch 21/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0643 - val_loss: 0.0748\n",
      "Epoch 22/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0652 - val_loss: 0.0743\n",
      "Epoch 23/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0638 - val_loss: 0.0799\n",
      "Epoch 24/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0648 - val_loss: 0.0765\n",
      "Epoch 25/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0634 - val_loss: 0.0743\n",
      "Epoch 26/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0627 - val_loss: 0.0720\n",
      "Epoch 27/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0609 - val_loss: 0.0716\n",
      "Epoch 28/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0617 - val_loss: 0.0755\n",
      "Epoch 29/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0625 - val_loss: 0.0729\n",
      "Epoch 30/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0626 - val_loss: 0.0726\n",
      "Epoch 31/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0610 - val_loss: 0.0726\n",
      "Epoch 32/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0605 - val_loss: 0.0720\n",
      "Epoch 33/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0603 - val_loss: 0.0726\n",
      "Epoch 34/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0591 - val_loss: 0.0715\n",
      "Epoch 35/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0603 - val_loss: 0.0744\n",
      "Epoch 36/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0590 - val_loss: 0.0703\n",
      "Epoch 37/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0595 - val_loss: 0.0704\n",
      "Epoch 38/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0599 - val_loss: 0.0738\n",
      "Epoch 39/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0613 - val_loss: 0.0699\n",
      "Epoch 40/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0576 - val_loss: 0.0705\n",
      "Epoch 41/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0577 - val_loss: 0.0701\n",
      "Epoch 42/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0572 - val_loss: 0.0694\n",
      "Epoch 43/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0575 - val_loss: 0.0704\n",
      "Epoch 44/47\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0583 - val_loss: 0.0697\n",
      "Epoch 45/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0588 - val_loss: 0.0716\n",
      "Epoch 46/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0571 - val_loss: 0.0701\n",
      "Epoch 47/47\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0568 - val_loss: 0.0695\n",
      "Epoch 1/45\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1594 - val_loss: 0.1196\n",
      "Epoch 2/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1109 - val_loss: 0.0985\n",
      "Epoch 3/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0923 - val_loss: 0.0951\n",
      "Epoch 4/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0847 - val_loss: 0.0928\n",
      "Epoch 5/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0817 - val_loss: 0.0938\n",
      "Epoch 6/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0786 - val_loss: 0.0902\n",
      "Epoch 7/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0806 - val_loss: 0.0881\n",
      "Epoch 8/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0778 - val_loss: 0.0878\n",
      "Epoch 9/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0783 - val_loss: 0.0873\n",
      "Epoch 10/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0823 - val_loss: 0.0892\n",
      "Epoch 11/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0822 - val_loss: 0.0930\n",
      "Epoch 12/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0848 - val_loss: 0.0986\n",
      "Epoch 13/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0863 - val_loss: 0.0842\n",
      "Epoch 14/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0820 - val_loss: 0.0893\n",
      "Epoch 15/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0759 - val_loss: 0.0884\n",
      "Epoch 16/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0772 - val_loss: 0.0856\n",
      "Epoch 17/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0766 - val_loss: 0.0852\n",
      "Epoch 18/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0762 - val_loss: 0.0844\n",
      "Epoch 19/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0750 - val_loss: 0.0839\n",
      "Epoch 20/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0734 - val_loss: 0.0836\n",
      "Epoch 21/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0719 - val_loss: 0.0829\n",
      "Epoch 22/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0751 - val_loss: 0.0862\n",
      "Epoch 23/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0779 - val_loss: 0.0844\n",
      "Epoch 24/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0753 - val_loss: 0.0913\n",
      "Epoch 25/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0773 - val_loss: 0.0825\n",
      "Epoch 26/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0729 - val_loss: 0.0839\n",
      "Epoch 27/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0716 - val_loss: 0.0821\n",
      "Epoch 28/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0728 - val_loss: 0.0817\n",
      "Epoch 29/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0719 - val_loss: 0.0841\n",
      "Epoch 30/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0713 - val_loss: 0.0815\n",
      "Epoch 31/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0701 - val_loss: 0.0816\n",
      "Epoch 32/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0717 - val_loss: 0.0841\n",
      "Epoch 33/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0710 - val_loss: 0.0814\n",
      "Epoch 34/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0693 - val_loss: 0.0813\n",
      "Epoch 35/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0706 - val_loss: 0.0809\n",
      "Epoch 36/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0707 - val_loss: 0.0808\n",
      "Epoch 37/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0729 - val_loss: 0.0823\n",
      "Epoch 38/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0718 - val_loss: 0.0808\n",
      "Epoch 39/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0730 - val_loss: 0.0799\n",
      "Epoch 40/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0696 - val_loss: 0.0805\n",
      "Epoch 41/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0687 - val_loss: 0.0804\n",
      "Epoch 42/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0670 - val_loss: 0.0800\n",
      "Epoch 43/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0696 - val_loss: 0.0815\n",
      "Epoch 44/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0682 - val_loss: 0.0805\n",
      "Epoch 45/45\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0700 - val_loss: 0.0927\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.3070 - val_loss: 0.1679\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1536 - val_loss: 0.1408\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1112 - val_loss: 0.1099\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0971 - val_loss: 0.1085\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0909 - val_loss: 0.1009\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0902 - val_loss: 0.0995\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0843 - val_loss: 0.0986\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0838 - val_loss: 0.0963\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0810 - val_loss: 0.0938\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0820 - val_loss: 0.0927\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0796 - val_loss: 0.0915\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0776 - val_loss: 0.0993\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0850 - val_loss: 0.0955\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0804 - val_loss: 0.0901\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0828 - val_loss: 0.0893\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0781 - val_loss: 0.0889\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0794 - val_loss: 0.0893\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0785 - val_loss: 0.0920\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0739 - val_loss: 0.0893\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0756 - val_loss: 0.0878\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0787 - val_loss: 0.0909\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0748 - val_loss: 0.0874\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0751 - val_loss: 0.0869\n",
      "Epoch 1/23\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1446 - val_loss: 0.1224\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1209 - val_loss: 0.1117\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1127 - val_loss: 0.1106\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0981 - val_loss: 0.1002\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0935 - val_loss: 0.0975\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0921 - val_loss: 0.0921\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0852 - val_loss: 0.0908\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0834 - val_loss: 0.0893\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0840 - val_loss: 0.0867\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0818 - val_loss: 0.0855\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0799 - val_loss: 0.0844\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0790 - val_loss: 0.0862\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0842 - val_loss: 0.0863\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0803 - val_loss: 0.0837\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0820 - val_loss: 0.0834\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0773 - val_loss: 0.0841\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0779 - val_loss: 0.0862\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0791 - val_loss: 0.0873\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0762 - val_loss: 0.0847\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0811 - val_loss: 0.0847\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0776 - val_loss: 0.0832\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0762 - val_loss: 0.0840\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0771 - val_loss: 0.0839\n",
      "Epoch 1/31\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3904 - val_loss: 0.2402\n",
      "Epoch 2/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2108 - val_loss: 0.1712\n",
      "Epoch 3/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1595 - val_loss: 0.1443\n",
      "Epoch 4/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1282 - val_loss: 0.1155\n",
      "Epoch 5/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1092 - val_loss: 0.1041\n",
      "Epoch 6/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0942 - val_loss: 0.0962\n",
      "Epoch 7/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0891 - val_loss: 0.0932\n",
      "Epoch 8/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0839 - val_loss: 0.0908\n",
      "Epoch 9/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0835 - val_loss: 0.0897\n",
      "Epoch 10/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0813 - val_loss: 0.0910\n",
      "Epoch 11/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0849 - val_loss: 0.0906\n",
      "Epoch 12/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0807 - val_loss: 0.0875\n",
      "Epoch 13/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0785 - val_loss: 0.0871\n",
      "Epoch 14/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0795 - val_loss: 0.0871\n",
      "Epoch 15/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0793 - val_loss: 0.0889\n",
      "Epoch 16/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0806 - val_loss: 0.0880\n",
      "Epoch 17/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0831 - val_loss: 0.1013\n",
      "Epoch 18/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0805 - val_loss: 0.0868\n",
      "Epoch 19/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0756 - val_loss: 0.0885\n",
      "Epoch 20/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0785 - val_loss: 0.0867\n",
      "Epoch 21/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0809 - val_loss: 0.0868\n",
      "Epoch 22/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0807 - val_loss: 0.0882\n",
      "Epoch 23/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0845 - val_loss: 0.0962\n",
      "Epoch 24/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0758 - val_loss: 0.0867\n",
      "Epoch 25/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0761 - val_loss: 0.0870\n",
      "Epoch 26/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0770 - val_loss: 0.0869\n",
      "Epoch 27/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0777 - val_loss: 0.0902\n",
      "Epoch 28/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0762 - val_loss: 0.0870\n",
      "Epoch 29/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0751 - val_loss: 0.0869\n",
      "Epoch 30/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0742 - val_loss: 0.0873\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0751 - val_loss: 0.0884\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "30\n",
      "30\n",
      "15\n",
      "Epoch 1/15: loss - 1.221278, val loss - 1.274605\n",
      "Epoch 2/15: loss - 0.298963, val loss - 0.133569\n",
      "Epoch 3/15: loss - 0.090954, val loss - 0.085680\n",
      "Epoch 4/15: loss - 0.080377, val loss - 0.118807\n",
      "Epoch 5/15: loss - 0.076494, val loss - 0.094163\n",
      "Epoch 6/15: loss - 0.072633, val loss - 0.082026\n",
      "Epoch 7/15: loss - 0.071102, val loss - 0.086229\n",
      "Epoch 8/15: loss - 0.069666, val loss - 0.080614\n",
      "Epoch 9/15: loss - 0.067022, val loss - 0.081035\n",
      "Epoch 10/15: loss - 0.065252, val loss - 0.079410\n",
      "Epoch 11/15: loss - 0.064248, val loss - 0.079327\n",
      "Epoch 12/15: loss - 0.062416, val loss - 0.081373\n",
      "Epoch 13/15: loss - 0.060667, val loss - 0.075230\n",
      "Epoch 14/15: loss - 0.059784, val loss - 0.076173\n",
      "Epoch 15/15: loss - 0.059174, val loss - 0.075118\n",
      "Test Predictions\n",
      "(499,)\n",
      "Test True Value\n",
      "(499, 1)\n",
      "Test Previous Day\n",
      "(499, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "176\n",
      "Epoch 1/176: loss - 0.453473, val loss - 0.619620\n",
      "Epoch 2/176: loss - 0.190048, val loss - 0.165991\n",
      "Epoch 3/176: loss - 0.135752, val loss - 0.109143\n",
      "Epoch 4/176: loss - 0.105076, val loss - 0.128929\n",
      "Epoch 5/176: loss - 0.106640, val loss - 0.110116\n",
      "Epoch 6/176: loss - 0.102545, val loss - 0.134617\n",
      "Epoch 7/176: loss - 0.098968, val loss - 0.111045\n",
      "Epoch 8/176: loss - 0.087977, val loss - 0.115794\n",
      "Epoch 9/176: loss - 0.087507, val loss - 0.100748\n",
      "Epoch 10/176: loss - 0.084062, val loss - 0.098607\n",
      "Epoch 11/176: loss - 0.079167, val loss - 0.109510\n",
      "Epoch 12/176: loss - 0.077892, val loss - 0.102029\n",
      "Epoch 13/176: loss - 0.086778, val loss - 0.092783\n",
      "Epoch 14/176: loss - 0.077281, val loss - 0.096039\n",
      "Epoch 15/176: loss - 0.078589, val loss - 0.101270\n",
      "Epoch 16/176: loss - 0.073714, val loss - 0.101664\n",
      "Epoch 17/176: loss - 0.074516, val loss - 0.086463\n",
      "Epoch 18/176: loss - 0.069891, val loss - 0.079864\n",
      "Epoch 19/176: loss - 0.070433, val loss - 0.087776\n",
      "Epoch 20/176: loss - 0.067447, val loss - 0.077217\n",
      "Epoch 21/176: loss - 0.065434, val loss - 0.076932\n",
      "Epoch 22/176: loss - 0.065938, val loss - 0.076413\n",
      "Epoch 23/176: loss - 0.065994, val loss - 0.075602\n",
      "Epoch 24/176: loss - 0.064968, val loss - 0.077780\n",
      "Epoch 25/176: loss - 0.068141, val loss - 0.077961\n",
      "Epoch 26/176: loss - 0.062852, val loss - 0.072561\n",
      "Epoch 27/176: loss - 0.059972, val loss - 0.084409\n",
      "Epoch 28/176: loss - 0.062968, val loss - 0.073897\n",
      "Epoch 29/176: loss - 0.062353, val loss - 0.072482\n",
      "Epoch 30/176: loss - 0.060562, val loss - 0.068463\n",
      "Epoch 31/176: loss - 0.059716, val loss - 0.070624\n",
      "Epoch 32/176: loss - 0.057761, val loss - 0.070821\n",
      "Epoch 33/176: loss - 0.060392, val loss - 0.071677\n",
      "Epoch 34/176: loss - 0.060725, val loss - 0.078982\n",
      "Epoch 35/176: loss - 0.059971, val loss - 0.070995\n",
      "Epoch 36/176: loss - 0.059325, val loss - 0.071758\n",
      "Epoch 37/176: loss - 0.056979, val loss - 0.066242\n",
      "Epoch 38/176: loss - 0.056399, val loss - 0.069269\n",
      "Epoch 39/176: loss - 0.057062, val loss - 0.068247\n",
      "Epoch 40/176: loss - 0.054902, val loss - 0.067319\n",
      "Epoch 41/176: loss - 0.056447, val loss - 0.065799\n",
      "Epoch 42/176: loss - 0.057038, val loss - 0.063354\n",
      "Epoch 43/176: loss - 0.056704, val loss - 0.073109\n",
      "Epoch 44/176: loss - 0.058070, val loss - 0.065528\n",
      "Epoch 45/176: loss - 0.054764, val loss - 0.068769\n",
      "Epoch 46/176: loss - 0.055192, val loss - 0.070310\n",
      "Epoch 47/176: loss - 0.054580, val loss - 0.067008\n",
      "Epoch 48/176: loss - 0.056239, val loss - 0.066340\n",
      "Epoch 49/176: loss - 0.057153, val loss - 0.067359\n",
      "Epoch 50/176: loss - 0.055044, val loss - 0.063926\n",
      "Epoch 51/176: loss - 0.055236, val loss - 0.063698\n",
      "Epoch 52/176: loss - 0.055633, val loss - 0.067413\n",
      "Epoch 53/176: loss - 0.052141, val loss - 0.064520\n",
      "Epoch 54/176: loss - 0.052060, val loss - 0.064303\n",
      "Epoch 55/176: loss - 0.056961, val loss - 0.067748\n",
      "Epoch 56/176: loss - 0.058536, val loss - 0.066850\n",
      "Epoch 57/176: loss - 0.055638, val loss - 0.066159\n",
      "Epoch 58/176: loss - 0.054720, val loss - 0.063725\n",
      "Epoch 59/176: loss - 0.055444, val loss - 0.066153\n",
      "Epoch 60/176: loss - 0.053286, val loss - 0.064080\n",
      "Epoch 61/176: loss - 0.050758, val loss - 0.065276\n",
      "Epoch 62/176: loss - 0.049202, val loss - 0.067734\n",
      "Epoch 63/176: loss - 0.052005, val loss - 0.065350\n",
      "Epoch 64/176: loss - 0.049566, val loss - 0.068062\n",
      "Epoch 65/176: loss - 0.051724, val loss - 0.066841\n",
      "Epoch 66/176: loss - 0.051752, val loss - 0.066050\n",
      "Epoch 67/176: loss - 0.055958, val loss - 0.066751\n",
      "Epoch 68/176: loss - 0.050355, val loss - 0.068416\n",
      "Epoch 69/176: loss - 0.154095, val loss - 0.581875\n",
      "Epoch 70/176: loss - 0.200931, val loss - 0.109142\n",
      "Epoch 71/176: loss - 0.157841, val loss - 0.168455\n",
      "Epoch 72/176: loss - 0.092434, val loss - 0.133137\n",
      "Epoch 73/176: loss - 0.095585, val loss - 0.096371\n",
      "Epoch 74/176: loss - 0.084153, val loss - 0.109096\n",
      "Epoch 75/176: loss - 0.080571, val loss - 0.090291\n",
      "Epoch 76/176: loss - 0.075691, val loss - 0.093005\n",
      "Epoch 77/176: loss - 0.075340, val loss - 0.089386\n",
      "Epoch 78/176: loss - 0.073701, val loss - 0.085589\n",
      "Epoch 79/176: loss - 0.072041, val loss - 0.086437\n",
      "Epoch 80/176: loss - 0.072332, val loss - 0.088789\n",
      "Epoch 81/176: loss - 0.073190, val loss - 0.087031\n",
      "Epoch 82/176: loss - 0.074019, val loss - 0.087889\n",
      "Epoch 83/176: loss - 0.072142, val loss - 0.088334\n",
      "Epoch 84/176: loss - 0.072887, val loss - 0.085805\n",
      "Epoch 85/176: loss - 0.071411, val loss - 0.086441\n",
      "Epoch 86/176: loss - 0.071855, val loss - 0.089584\n",
      "Epoch 87/176: loss - 0.071670, val loss - 0.088705\n",
      "Epoch 88/176: loss - 0.072951, val loss - 0.085765\n",
      "Epoch 89/176: loss - 0.070721, val loss - 0.087098\n",
      "Epoch 90/176: loss - 0.072408, val loss - 0.088322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/176: loss - 0.072026, val loss - 0.085167\n",
      "Epoch 92/176: loss - 0.070093, val loss - 0.086197\n",
      "Epoch 93/176: loss - 0.071192, val loss - 0.086583\n",
      "Epoch 94/176: loss - 0.070414, val loss - 0.084252\n",
      "Epoch 95/176: loss - 0.072541, val loss - 0.084335\n",
      "Epoch 96/176: loss - 0.070486, val loss - 0.086862\n",
      "Epoch 97/176: loss - 0.070930, val loss - 0.085423\n",
      "Epoch 98/176: loss - 0.070011, val loss - 0.084784\n",
      "Epoch 99/176: loss - 0.069880, val loss - 0.086118\n",
      "Epoch 100/176: loss - 0.070061, val loss - 0.084258\n",
      "Epoch 101/176: loss - 0.069180, val loss - 0.087339\n",
      "Epoch 102/176: loss - 0.071271, val loss - 0.083722\n",
      "Epoch 103/176: loss - 0.067994, val loss - 0.086204\n",
      "Epoch 104/176: loss - 0.070031, val loss - 0.082951\n",
      "Epoch 105/176: loss - 0.070084, val loss - 0.088332\n",
      "Epoch 106/176: loss - 0.070774, val loss - 0.084254\n",
      "Epoch 107/176: loss - 0.068871, val loss - 0.087851\n",
      "Epoch 108/176: loss - 0.070228, val loss - 0.083430\n",
      "Epoch 109/176: loss - 0.068459, val loss - 0.090320\n",
      "Epoch 110/176: loss - 0.070115, val loss - 0.084908\n",
      "Epoch 111/176: loss - 0.068082, val loss - 0.083613\n",
      "Epoch 112/176: loss - 0.068271, val loss - 0.083779\n",
      "Epoch 113/176: loss - 0.069074, val loss - 0.087634\n",
      "Epoch 114/176: loss - 0.069432, val loss - 0.086410\n",
      "Epoch 115/176: loss - 0.069409, val loss - 0.084335\n",
      "Epoch 116/176: loss - 0.067616, val loss - 0.084122\n",
      "Epoch 117/176: loss - 0.068784, val loss - 0.084389\n",
      "Epoch 118/176: loss - 0.067454, val loss - 0.085516\n",
      "Epoch 119/176: loss - 0.067909, val loss - 0.082832\n",
      "Epoch 120/176: loss - 0.067649, val loss - 0.082652\n",
      "Epoch 121/176: loss - 0.067829, val loss - 0.084744\n",
      "Epoch 122/176: loss - 0.067464, val loss - 0.083734\n",
      "Epoch 123/176: loss - 0.067420, val loss - 0.084052\n",
      "Epoch 124/176: loss - 0.067660, val loss - 0.089456\n",
      "Epoch 125/176: loss - 0.067752, val loss - 0.082693\n",
      "Epoch 126/176: loss - 0.067738, val loss - 0.083754\n",
      "Epoch 127/176: loss - 0.065858, val loss - 0.084192\n",
      "Epoch 128/176: loss - 0.067414, val loss - 0.081817\n",
      "Epoch 129/176: loss - 0.065450, val loss - 0.082543\n",
      "Epoch 130/176: loss - 0.066522, val loss - 0.087035\n",
      "Epoch 131/176: loss - 0.066799, val loss - 0.083158\n",
      "Epoch 132/176: loss - 0.066954, val loss - 0.083230\n",
      "Epoch 133/176: loss - 0.065942, val loss - 0.082465\n",
      "Epoch 134/176: loss - 0.065220, val loss - 0.082810\n",
      "Epoch 135/176: loss - 0.064581, val loss - 0.081256\n",
      "Epoch 136/176: loss - 0.065190, val loss - 0.082466\n",
      "Epoch 137/176: loss - 0.066492, val loss - 0.086869\n",
      "Epoch 138/176: loss - 0.068327, val loss - 0.083530\n",
      "Epoch 139/176: loss - 0.065411, val loss - 0.080416\n",
      "Epoch 140/176: loss - 0.067304, val loss - 0.081652\n",
      "Epoch 141/176: loss - 0.066665, val loss - 0.081937\n",
      "Epoch 142/176: loss - 0.066037, val loss - 0.081057\n",
      "Epoch 143/176: loss - 0.064952, val loss - 0.081659\n",
      "Epoch 144/176: loss - 0.064538, val loss - 0.083388\n",
      "Epoch 145/176: loss - 0.065058, val loss - 0.082051\n",
      "Epoch 146/176: loss - 0.063042, val loss - 0.085033\n",
      "Epoch 147/176: loss - 0.064434, val loss - 0.084748\n",
      "Epoch 148/176: loss - 0.064912, val loss - 0.081584\n",
      "Epoch 149/176: loss - 0.063035, val loss - 0.083929\n",
      "Epoch 150/176: loss - 0.065217, val loss - 0.083787\n",
      "Epoch 151/176: loss - 0.064515, val loss - 0.079295\n",
      "Epoch 152/176: loss - 0.062661, val loss - 0.081500\n",
      "Epoch 153/176: loss - 0.062591, val loss - 0.078785\n",
      "Epoch 154/176: loss - 0.062270, val loss - 0.077920\n",
      "Epoch 155/176: loss - 0.060824, val loss - 0.080122\n",
      "Epoch 156/176: loss - 0.062912, val loss - 0.082541\n",
      "Epoch 157/176: loss - 0.063994, val loss - 0.079392\n",
      "Epoch 158/176: loss - 0.063446, val loss - 0.078706\n",
      "Epoch 159/176: loss - 0.062933, val loss - 0.079457\n",
      "Epoch 160/176: loss - 0.062215, val loss - 0.079012\n",
      "Epoch 161/176: loss - 0.062112, val loss - 0.076407\n",
      "Epoch 162/176: loss - 0.061447, val loss - 0.077646\n",
      "Epoch 163/176: loss - 0.062688, val loss - 0.076968\n",
      "Epoch 164/176: loss - 0.062698, val loss - 0.078679\n",
      "Epoch 165/176: loss - 0.059287, val loss - 0.077593\n",
      "Epoch 166/176: loss - 0.059360, val loss - 0.078763\n",
      "Epoch 167/176: loss - 0.063152, val loss - 0.083447\n",
      "Epoch 168/176: loss - 0.060370, val loss - 0.077294\n",
      "Epoch 169/176: loss - 0.061499, val loss - 0.081245\n",
      "Epoch 170/176: loss - 0.060825, val loss - 0.076712\n",
      "Epoch 171/176: loss - 0.060230, val loss - 0.079262\n",
      "Epoch 172/176: loss - 0.063536, val loss - 0.077809\n",
      "Epoch 173/176: loss - 0.059457, val loss - 0.078691\n",
      "Epoch 174/176: loss - 0.060355, val loss - 0.082261\n",
      "Epoch 175/176: loss - 0.062106, val loss - 0.076357\n",
      "Epoch 176/176: loss - 0.060632, val loss - 0.077445\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "15\n",
      "15\n",
      "24\n",
      "Epoch 1/24: loss - 0.152942, val loss - 0.201271\n",
      "Epoch 2/24: loss - 0.123556, val loss - 0.197666\n",
      "Epoch 3/24: loss - 0.121872, val loss - 0.108474\n",
      "Epoch 4/24: loss - 0.109656, val loss - 0.139004\n",
      "Epoch 5/24: loss - 0.093923, val loss - 0.134095\n",
      "Epoch 6/24: loss - 0.093413, val loss - 0.122852\n",
      "Epoch 7/24: loss - 0.092112, val loss - 0.113765\n",
      "Epoch 8/24: loss - 0.088511, val loss - 0.117814\n",
      "Epoch 9/24: loss - 0.083882, val loss - 0.110530\n",
      "Epoch 10/24: loss - 0.084303, val loss - 0.100158\n",
      "Epoch 11/24: loss - 0.083213, val loss - 0.099170\n",
      "Epoch 12/24: loss - 0.081433, val loss - 0.105981\n",
      "Epoch 13/24: loss - 0.081896, val loss - 0.105827\n",
      "Epoch 14/24: loss - 0.080141, val loss - 0.094296\n",
      "Epoch 15/24: loss - 0.077631, val loss - 0.095612\n",
      "Epoch 16/24: loss - 0.077041, val loss - 0.091465\n",
      "Epoch 17/24: loss - 0.076455, val loss - 0.093830\n",
      "Epoch 18/24: loss - 0.076205, val loss - 0.093929\n",
      "Epoch 19/24: loss - 0.075411, val loss - 0.095863\n",
      "Epoch 20/24: loss - 0.077454, val loss - 0.095201\n",
      "Epoch 21/24: loss - 0.073859, val loss - 0.097023\n",
      "Epoch 22/24: loss - 0.075216, val loss - 0.094119\n",
      "Epoch 23/24: loss - 0.073154, val loss - 0.088958\n",
      "Epoch 24/24: loss - 0.071824, val loss - 0.091690\n",
      "Test Predictions\n",
      "(498,)\n",
      "Test True Value\n",
      "(498, 1)\n",
      "Test Previous Day\n",
      "(498, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "66\n",
      "Epoch 1/66: loss - 0.194364, val loss - 0.130599\n",
      "Epoch 2/66: loss - 0.126489, val loss - 0.143508\n",
      "Epoch 3/66: loss - 0.123841, val loss - 0.138295\n",
      "Epoch 4/66: loss - 0.115697, val loss - 0.125711\n",
      "Epoch 5/66: loss - 0.106890, val loss - 0.119250\n",
      "Epoch 6/66: loss - 0.105200, val loss - 0.131606\n",
      "Epoch 7/66: loss - 0.101817, val loss - 0.115526\n",
      "Epoch 8/66: loss - 0.093701, val loss - 0.104258\n",
      "Epoch 9/66: loss - 0.092921, val loss - 0.115286\n",
      "Epoch 10/66: loss - 0.090371, val loss - 0.104925\n",
      "Epoch 11/66: loss - 0.083248, val loss - 0.108951\n",
      "Epoch 12/66: loss - 0.084936, val loss - 0.098348\n",
      "Epoch 13/66: loss - 0.087057, val loss - 0.109850\n",
      "Epoch 14/66: loss - 0.085358, val loss - 0.098504\n",
      "Epoch 15/66: loss - 0.083111, val loss - 0.094716\n",
      "Epoch 16/66: loss - 0.079548, val loss - 0.115814\n",
      "Epoch 17/66: loss - 0.081204, val loss - 0.093063\n",
      "Epoch 18/66: loss - 0.077184, val loss - 0.100828\n",
      "Epoch 19/66: loss - 0.075825, val loss - 0.094216\n",
      "Epoch 20/66: loss - 0.075361, val loss - 0.101318\n",
      "Epoch 21/66: loss - 0.078115, val loss - 0.097485\n",
      "Epoch 22/66: loss - 0.075734, val loss - 0.099393\n",
      "Epoch 23/66: loss - 0.075606, val loss - 0.095957\n",
      "Epoch 24/66: loss - 0.075529, val loss - 0.100777\n",
      "Epoch 25/66: loss - 0.076108, val loss - 0.094279\n",
      "Epoch 26/66: loss - 0.073864, val loss - 0.092680\n",
      "Epoch 27/66: loss - 0.072970, val loss - 0.096788\n",
      "Epoch 28/66: loss - 0.072646, val loss - 0.093270\n",
      "Epoch 29/66: loss - 0.072041, val loss - 0.096292\n",
      "Epoch 30/66: loss - 0.074805, val loss - 0.099604\n",
      "Epoch 31/66: loss - 0.072710, val loss - 0.094369\n",
      "Epoch 32/66: loss - 0.071177, val loss - 0.094186\n",
      "Epoch 33/66: loss - 0.070912, val loss - 0.091540\n",
      "Epoch 34/66: loss - 0.069893, val loss - 0.090932\n",
      "Epoch 35/66: loss - 0.068889, val loss - 0.087486\n",
      "Epoch 36/66: loss - 0.069505, val loss - 0.089770\n",
      "Epoch 37/66: loss - 0.071257, val loss - 0.098035\n",
      "Epoch 38/66: loss - 0.072514, val loss - 0.087575\n",
      "Epoch 39/66: loss - 0.069364, val loss - 0.089051\n",
      "Epoch 40/66: loss - 0.069963, val loss - 0.094438\n",
      "Epoch 41/66: loss - 0.069218, val loss - 0.092548\n",
      "Epoch 42/66: loss - 0.069539, val loss - 0.089247\n",
      "Epoch 43/66: loss - 0.068086, val loss - 0.092004\n",
      "Epoch 44/66: loss - 0.070861, val loss - 0.087578\n",
      "Epoch 45/66: loss - 0.066181, val loss - 0.086590\n",
      "Epoch 46/66: loss - 0.065681, val loss - 0.087301\n",
      "Epoch 47/66: loss - 0.065605, val loss - 0.087118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/66: loss - 0.067906, val loss - 0.087749\n",
      "Epoch 49/66: loss - 0.066100, val loss - 0.088366\n",
      "Epoch 50/66: loss - 0.064099, val loss - 0.086951\n",
      "Epoch 51/66: loss - 0.068005, val loss - 0.083946\n",
      "Epoch 52/66: loss - 0.065290, val loss - 0.087286\n",
      "Epoch 53/66: loss - 0.065790, val loss - 0.087562\n",
      "Epoch 54/66: loss - 0.063792, val loss - 0.087229\n",
      "Epoch 55/66: loss - 0.065902, val loss - 0.087500\n",
      "Epoch 56/66: loss - 0.063798, val loss - 0.088606\n",
      "Epoch 57/66: loss - 0.064420, val loss - 0.087677\n",
      "Epoch 58/66: loss - 0.062193, val loss - 0.085513\n",
      "Epoch 59/66: loss - 0.062133, val loss - 0.088284\n",
      "Epoch 60/66: loss - 0.062714, val loss - 0.089821\n",
      "Epoch 61/66: loss - 0.064822, val loss - 0.085884\n",
      "Epoch 62/66: loss - 0.063169, val loss - 0.086568\n",
      "Epoch 63/66: loss - 0.061916, val loss - 0.085676\n",
      "Epoch 64/66: loss - 0.062276, val loss - 0.086341\n",
      "Epoch 65/66: loss - 0.060929, val loss - 0.085680\n",
      "Epoch 66/66: loss - 0.062779, val loss - 0.087667\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "$$$$$$$$  pytorch $$$$$$$$$\n",
      "7\n",
      "7\n",
      "24\n",
      "Epoch 1/24: loss - 0.234650, val loss - 0.121705\n",
      "Epoch 2/24: loss - 0.116674, val loss - 0.133953\n",
      "Epoch 3/24: loss - 0.102508, val loss - 0.104749\n",
      "Epoch 4/24: loss - 0.092187, val loss - 0.102379\n",
      "Epoch 5/24: loss - 0.086141, val loss - 0.107998\n",
      "Epoch 6/24: loss - 0.084967, val loss - 0.106261\n",
      "Epoch 7/24: loss - 0.084679, val loss - 0.097478\n",
      "Epoch 8/24: loss - 0.086367, val loss - 0.104306\n",
      "Epoch 9/24: loss - 0.084459, val loss - 0.100191\n",
      "Epoch 10/24: loss - 0.079946, val loss - 0.109689\n",
      "Epoch 11/24: loss - 0.080785, val loss - 0.104260\n",
      "Epoch 12/24: loss - 0.082420, val loss - 0.093951\n",
      "Epoch 13/24: loss - 0.078896, val loss - 0.098355\n",
      "Epoch 14/24: loss - 0.074828, val loss - 0.099285\n",
      "Epoch 15/24: loss - 0.074493, val loss - 0.105366\n",
      "Epoch 16/24: loss - 0.076267, val loss - 0.103808\n",
      "Epoch 17/24: loss - 0.075285, val loss - 0.099437\n",
      "Epoch 18/24: loss - 0.074126, val loss - 0.097535\n",
      "Epoch 19/24: loss - 0.074945, val loss - 0.102149\n",
      "Epoch 20/24: loss - 0.072129, val loss - 0.094612\n",
      "Epoch 21/24: loss - 0.073968, val loss - 0.095482\n",
      "Epoch 22/24: loss - 0.072423, val loss - 0.094505\n",
      "Epoch 23/24: loss - 0.070617, val loss - 0.093339\n",
      "Epoch 24/24: loss - 0.068971, val loss - 0.092717\n",
      "Test Predictions\n",
      "(497,)\n",
      "Test True Value\n",
      "(497, 1)\n",
      "Test Previous Day\n",
      "(497, 10, 5)\n",
      "Epoch 1/28\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.1043WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1139 - val_loss: 0.0887\n",
      "Epoch 2/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0773\n",
      "Epoch 3/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0733\n",
      "Epoch 4/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0768\n",
      "Epoch 5/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0730\n",
      "Epoch 6/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0680\n",
      "Epoch 7/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0661\n",
      "Epoch 8/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0757\n",
      "Epoch 9/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0669\n",
      "Epoch 10/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0650\n",
      "Epoch 11/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0663\n",
      "Epoch 12/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0708\n",
      "Epoch 13/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0644\n",
      "Epoch 14/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0669\n",
      "Epoch 15/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0641\n",
      "Epoch 16/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0617\n",
      "Epoch 17/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0685\n",
      "Epoch 18/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0595\n",
      "Epoch 19/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0591\n",
      "Epoch 20/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0650\n",
      "Epoch 21/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0600\n",
      "Epoch 22/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0601\n",
      "Epoch 23/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0587\n",
      "Epoch 24/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0689\n",
      "Epoch 25/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0571\n",
      "Epoch 26/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0592\n",
      "Epoch 27/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0617\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0635\n",
      "Epoch 1/35\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2131 - val_loss: 0.1269\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1135 - val_loss: 0.1047\n",
      "Epoch 3/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.1008\n",
      "Epoch 4/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0981 - val_loss: 0.0951\n",
      "Epoch 5/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.0923\n",
      "Epoch 6/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0794 - val_loss: 0.0835\n",
      "Epoch 7/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.0769\n",
      "Epoch 8/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.1077\n",
      "Epoch 9/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0749\n",
      "Epoch 10/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0748\n",
      "Epoch 11/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0786\n",
      "Epoch 12/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0755\n",
      "Epoch 13/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0708\n",
      "Epoch 14/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0700\n",
      "Epoch 15/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0683\n",
      "Epoch 16/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0691\n",
      "Epoch 17/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0774\n",
      "Epoch 18/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0670\n",
      "Epoch 19/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0687\n",
      "Epoch 20/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0741\n",
      "Epoch 21/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0763\n",
      "Epoch 22/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0674\n",
      "Epoch 23/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0691\n",
      "Epoch 24/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0694\n",
      "Epoch 25/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0692\n",
      "Epoch 26/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.1081\n",
      "Epoch 27/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0741\n",
      "Epoch 28/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0732\n",
      "Epoch 29/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0852\n",
      "Epoch 31/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0723\n",
      "Epoch 32/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0752\n",
      "Epoch 33/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0756\n",
      "Epoch 34/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0706\n",
      "Epoch 35/35\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0888\n",
      "Epoch 1/29\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.3203WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3818 - val_loss: 0.1383\n",
      "Epoch 2/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1292 - val_loss: 0.1026\n",
      "Epoch 3/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0908 - val_loss: 0.0875\n",
      "Epoch 4/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0876\n",
      "Epoch 5/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0880\n",
      "Epoch 6/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.0816\n",
      "Epoch 7/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0912\n",
      "Epoch 8/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0835\n",
      "Epoch 9/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0852\n",
      "Epoch 10/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0819\n",
      "Epoch 11/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0810\n",
      "Epoch 12/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0812\n",
      "Epoch 13/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0797\n",
      "Epoch 14/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0813\n",
      "Epoch 15/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.0813\n",
      "Epoch 16/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0812\n",
      "Epoch 17/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0828\n",
      "Epoch 18/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0807\n",
      "Epoch 19/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0994\n",
      "Epoch 20/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0872\n",
      "Epoch 21/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0797\n",
      "Epoch 22/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0945\n",
      "Epoch 23/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0824\n",
      "Epoch 24/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0816\n",
      "Epoch 25/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0981\n",
      "Epoch 26/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0923\n",
      "Epoch 27/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0956\n",
      "Epoch 28/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0898\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0830\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3248 - val_loss: 0.1355\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1344 - val_loss: 0.1401\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1317 - val_loss: 0.1294\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1183 - val_loss: 0.1059\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.0836\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.0835\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0995\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0790 - val_loss: 0.0796\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0861\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0784\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.0897\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0835\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0871\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0923\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0819\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0867\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0803\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0723 - val_loss: 0.1059\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0868\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0851\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0900\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0789\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0788\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0823\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0782\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.1097\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0988\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.1065\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.1040\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0886\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0978\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0791\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0765\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0720\n",
      "Epoch 1/108\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.9961 - val_loss: 0.7724\n",
      "Epoch 2/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - val_loss: 0.3899\n",
      "Epoch 3/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2541 - val_loss: 0.2066\n",
      "Epoch 4/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 0.1484\n",
      "Epoch 5/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1414 - val_loss: 0.1381\n",
      "Epoch 6/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1381 - val_loss: 0.1368\n",
      "Epoch 7/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1344 - val_loss: 0.1363\n",
      "Epoch 8/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1320 - val_loss: 0.1347\n",
      "Epoch 9/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1295 - val_loss: 0.1319\n",
      "Epoch 10/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 0.1302\n",
      "Epoch 11/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1248 - val_loss: 0.1290\n",
      "Epoch 12/108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1272\n",
      "Epoch 13/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1206 - val_loss: 0.1259\n",
      "Epoch 14/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.1224\n",
      "Epoch 15/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1161 - val_loss: 0.1215\n",
      "Epoch 16/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1143 - val_loss: 0.1215\n",
      "Epoch 17/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1124 - val_loss: 0.1177\n",
      "Epoch 18/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1096 - val_loss: 0.1175\n",
      "Epoch 19/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1074 - val_loss: 0.1148\n",
      "Epoch 20/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.1138\n",
      "Epoch 21/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1033 - val_loss: 0.1115\n",
      "Epoch 22/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1019 - val_loss: 0.1113\n",
      "Epoch 23/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0992 - val_loss: 0.1083\n",
      "Epoch 24/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0967 - val_loss: 0.1071\n",
      "Epoch 25/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.1056\n",
      "Epoch 26/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.1040\n",
      "Epoch 27/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.1018\n",
      "Epoch 28/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.1021\n",
      "Epoch 29/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.1004\n",
      "Epoch 30/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0849 - val_loss: 0.0983\n",
      "Epoch 31/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.0984\n",
      "Epoch 32/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0964\n",
      "Epoch 33/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0970\n",
      "Epoch 34/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0794 - val_loss: 0.0953\n",
      "Epoch 35/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.0949\n",
      "Epoch 36/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0949\n",
      "Epoch 37/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0951\n",
      "Epoch 38/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0931\n",
      "Epoch 39/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0944\n",
      "Epoch 40/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0936\n",
      "Epoch 41/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0928\n",
      "Epoch 42/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.0930\n",
      "Epoch 43/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0918\n",
      "Epoch 44/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0927\n",
      "Epoch 45/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0926\n",
      "Epoch 46/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0919\n",
      "Epoch 47/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0928\n",
      "Epoch 48/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0919\n",
      "Epoch 49/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0918\n",
      "Epoch 50/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0914\n",
      "Epoch 51/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.0913\n",
      "Epoch 52/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0924\n",
      "Epoch 53/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0923\n",
      "Epoch 54/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0924\n",
      "Epoch 55/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0926\n",
      "Epoch 56/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0898\n",
      "Epoch 57/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0923\n",
      "Epoch 58/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0901\n",
      "Epoch 59/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0931\n",
      "Epoch 60/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0909\n",
      "Epoch 61/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0911\n",
      "Epoch 62/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0916\n",
      "Epoch 63/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0918\n",
      "Epoch 64/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0907\n",
      "Epoch 65/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0926\n",
      "Epoch 66/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0897\n",
      "Epoch 67/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0936\n",
      "Epoch 68/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0909\n",
      "Epoch 69/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0909\n",
      "Epoch 70/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0906\n",
      "Epoch 71/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0931\n",
      "Epoch 72/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0893\n",
      "Epoch 73/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0909\n",
      "Epoch 74/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0906\n",
      "Epoch 75/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0939\n",
      "Epoch 76/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0893\n",
      "Epoch 77/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0912\n",
      "Epoch 78/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0912\n",
      "Epoch 79/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0894\n",
      "Epoch 80/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0944\n",
      "Epoch 81/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0893\n",
      "Epoch 82/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0903\n",
      "Epoch 83/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0886\n",
      "Epoch 84/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0918\n",
      "Epoch 85/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0886\n",
      "Epoch 86/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0646 - val_loss: 0.0904\n",
      "Epoch 87/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0646 - val_loss: 0.0919\n",
      "Epoch 88/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0882\n",
      "Epoch 89/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0906\n",
      "Epoch 90/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0912\n",
      "Epoch 91/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0895\n",
      "Epoch 92/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0900\n",
      "Epoch 93/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0898\n",
      "Epoch 94/108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0924\n",
      "Epoch 95/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0902\n",
      "Epoch 96/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0904\n",
      "Epoch 97/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0630 - val_loss: 0.0920\n",
      "Epoch 98/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0900\n",
      "Epoch 99/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0898\n",
      "Epoch 100/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0887\n",
      "Epoch 101/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0630 - val_loss: 0.0914\n",
      "Epoch 102/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0921\n",
      "Epoch 103/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0885\n",
      "Epoch 104/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0893\n",
      "Epoch 105/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0921\n",
      "Epoch 106/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0884\n",
      "Epoch 107/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0896\n",
      "Epoch 108/108\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0912\n",
      "Epoch 1/34\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2574 - val_loss: 0.1208\n",
      "Epoch 2/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.0990\n",
      "Epoch 3/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0834\n",
      "Epoch 4/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0771\n",
      "Epoch 5/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0750\n",
      "Epoch 6/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0725\n",
      "Epoch 7/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0730\n",
      "Epoch 8/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0717\n",
      "Epoch 9/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0717\n",
      "Epoch 10/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0701\n",
      "Epoch 11/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0705\n",
      "Epoch 12/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0822\n",
      "Epoch 13/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0720\n",
      "Epoch 14/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0694\n",
      "Epoch 15/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0698\n",
      "Epoch 16/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0750\n",
      "Epoch 17/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0703\n",
      "Epoch 18/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0694\n",
      "Epoch 19/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0694\n",
      "Epoch 20/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0692\n",
      "Epoch 21/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0741\n",
      "Epoch 22/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0706\n",
      "Epoch 23/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0691\n",
      "Epoch 24/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0732\n",
      "Epoch 25/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0701\n",
      "Epoch 26/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0688\n",
      "Epoch 27/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0678\n",
      "Epoch 28/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0684\n",
      "Epoch 29/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0682\n",
      "Epoch 30/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0679\n",
      "Epoch 31/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0727\n",
      "Epoch 32/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0662\n",
      "Epoch 33/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0662\n",
      "Epoch 34/34\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0779\n",
      "Epoch 1/36\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1961 - val_loss: 0.1314\n",
      "Epoch 2/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.1196\n",
      "Epoch 3/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1150\n",
      "Epoch 4/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.1101\n",
      "Epoch 5/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 0.1096\n",
      "Epoch 6/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.1016\n",
      "Epoch 7/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0927 - val_loss: 0.0946\n",
      "Epoch 8/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.1042\n",
      "Epoch 9/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.0911\n",
      "Epoch 10/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0866\n",
      "Epoch 11/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0879\n",
      "Epoch 12/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0891\n",
      "Epoch 13/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0849\n",
      "Epoch 14/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0953\n",
      "Epoch 15/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0857\n",
      "Epoch 16/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0842\n",
      "Epoch 17/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0866\n",
      "Epoch 18/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0837\n",
      "Epoch 19/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0867\n",
      "Epoch 20/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0842\n",
      "Epoch 21/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0838\n",
      "Epoch 22/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0886\n",
      "Epoch 23/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0824\n",
      "Epoch 24/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0835\n",
      "Epoch 25/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0816\n",
      "Epoch 26/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0869\n",
      "Epoch 27/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0828\n",
      "Epoch 28/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0827\n",
      "Epoch 29/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0812\n",
      "Epoch 30/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0869\n",
      "Epoch 31/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0810\n",
      "Epoch 32/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0788\n",
      "Epoch 33/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0851\n",
      "Epoch 34/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/36\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0817\n",
      "Epoch 36/36\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0868\n",
      "Epoch 1/71\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2304 - val_loss: 0.1960\n",
      "Epoch 2/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1629 - val_loss: 0.1553\n",
      "Epoch 3/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1464\n",
      "Epoch 4/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1426\n",
      "Epoch 5/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1406 - val_loss: 0.1399\n",
      "Epoch 6/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1354 - val_loss: 0.1353\n",
      "Epoch 7/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1304 - val_loss: 0.1312\n",
      "Epoch 8/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1266\n",
      "Epoch 9/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1195 - val_loss: 0.1225\n",
      "Epoch 10/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.1155\n",
      "Epoch 11/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.1100\n",
      "Epoch 12/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.1055\n",
      "Epoch 13/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.1032\n",
      "Epoch 14/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0997\n",
      "Epoch 15/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.1001\n",
      "Epoch 16/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0986\n",
      "Epoch 17/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0993\n",
      "Epoch 18/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0976\n",
      "Epoch 19/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0975\n",
      "Epoch 20/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0970\n",
      "Epoch 21/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0962\n",
      "Epoch 22/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0977\n",
      "Epoch 23/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0960\n",
      "Epoch 24/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0963\n",
      "Epoch 25/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0968\n",
      "Epoch 26/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0955\n",
      "Epoch 27/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0959\n",
      "Epoch 28/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0954\n",
      "Epoch 29/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0952\n",
      "Epoch 30/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0946\n",
      "Epoch 31/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0954\n",
      "Epoch 32/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0950\n",
      "Epoch 33/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0949\n",
      "Epoch 34/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0951\n",
      "Epoch 35/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0961\n",
      "Epoch 36/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0725 - val_loss: 0.0946\n",
      "Epoch 37/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0947\n",
      "Epoch 38/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0938\n",
      "Epoch 39/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0940\n",
      "Epoch 40/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0946\n",
      "Epoch 41/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0938\n",
      "Epoch 42/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0936\n",
      "Epoch 43/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0932\n",
      "Epoch 44/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0943\n",
      "Epoch 45/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0933\n",
      "Epoch 46/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0940\n",
      "Epoch 47/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0927\n",
      "Epoch 48/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0929\n",
      "Epoch 49/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0954\n",
      "Epoch 50/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0928\n",
      "Epoch 51/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0941\n",
      "Epoch 52/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0924\n",
      "Epoch 53/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0939\n",
      "Epoch 54/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0925\n",
      "Epoch 55/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.0936\n",
      "Epoch 56/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0945\n",
      "Epoch 57/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0929\n",
      "Epoch 58/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0923\n",
      "Epoch 59/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0928\n",
      "Epoch 60/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0927\n",
      "Epoch 61/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0921\n",
      "Epoch 62/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0917\n",
      "Epoch 63/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0946\n",
      "Epoch 64/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0914\n",
      "Epoch 65/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0944\n",
      "Epoch 66/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0915\n",
      "Epoch 67/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0927\n",
      "Epoch 68/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0916\n",
      "Epoch 69/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0931\n",
      "Epoch 70/71\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0921\n",
      "Epoch 71/71\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0912\n",
      "Epoch 1/63\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1684 - val_loss: 0.1578\n",
      "Epoch 2/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1534 - val_loss: 0.1519\n",
      "Epoch 3/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1416\n",
      "Epoch 4/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1342\n",
      "Epoch 5/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1264 - val_loss: 0.1264\n",
      "Epoch 6/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1156\n",
      "Epoch 7/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.1057\n",
      "Epoch 8/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.1013\n",
      "Epoch 9/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0988\n",
      "Epoch 10/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0976\n",
      "Epoch 12/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0964\n",
      "Epoch 13/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0997\n",
      "Epoch 14/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0964\n",
      "Epoch 15/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0962\n",
      "Epoch 16/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0975\n",
      "Epoch 17/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0961\n",
      "Epoch 18/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0973\n",
      "Epoch 19/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0962\n",
      "Epoch 20/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0976\n",
      "Epoch 21/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0976\n",
      "Epoch 22/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0997\n",
      "Epoch 23/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0964\n",
      "Epoch 24/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0956\n",
      "Epoch 25/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0996\n",
      "Epoch 26/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0955\n",
      "Epoch 27/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0964\n",
      "Epoch 28/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0953\n",
      "Epoch 29/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0973\n",
      "Epoch 30/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0953\n",
      "Epoch 31/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0961\n",
      "Epoch 32/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0959\n",
      "Epoch 33/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0954\n",
      "Epoch 34/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0966\n",
      "Epoch 35/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0955\n",
      "Epoch 36/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0951\n",
      "Epoch 37/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0957\n",
      "Epoch 38/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0956\n",
      "Epoch 39/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0949\n",
      "Epoch 40/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0961\n",
      "Epoch 41/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0945\n",
      "Epoch 42/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0942\n",
      "Epoch 43/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0939\n",
      "Epoch 44/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0956\n",
      "Epoch 45/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0967\n",
      "Epoch 46/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0937\n",
      "Epoch 47/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0945\n",
      "Epoch 48/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0936\n",
      "Epoch 49/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0976\n",
      "Epoch 50/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0936\n",
      "Epoch 51/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0940\n",
      "Epoch 52/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0941\n",
      "Epoch 53/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0947\n",
      "Epoch 54/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0935\n",
      "Epoch 55/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0935\n",
      "Epoch 56/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0978\n",
      "Epoch 57/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0943\n",
      "Epoch 58/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0933\n",
      "Epoch 59/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0951\n",
      "Epoch 60/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0942\n",
      "Epoch 61/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0937\n",
      "Epoch 62/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0933\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0955\n",
      "Epoch 1/26\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1596 - val_loss: 0.1658\n",
      "Epoch 2/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.1055\n",
      "Epoch 3/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0975\n",
      "Epoch 4/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.1016\n",
      "Epoch 5/26\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0775 - val_loss: 0.0929\n",
      "Epoch 6/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0958\n",
      "Epoch 7/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0937\n",
      "Epoch 8/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0937\n",
      "Epoch 9/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0916\n",
      "Epoch 10/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0917\n",
      "Epoch 11/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0959\n",
      "Epoch 12/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0989\n",
      "Epoch 13/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0918\n",
      "Epoch 14/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.1161\n",
      "Epoch 15/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.1224\n",
      "Epoch 16/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0963\n",
      "Epoch 17/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.1141\n",
      "Epoch 18/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0984\n",
      "Epoch 19/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.1022\n",
      "Epoch 20/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0958\n",
      "Epoch 21/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.1060\n",
      "Epoch 22/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0944\n",
      "Epoch 23/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0940\n",
      "Epoch 24/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0929\n",
      "Epoch 25/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0943\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0941\n",
      "Epoch 1/138\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1837 - val_loss: 0.1606\n",
      "Epoch 2/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1217 - val_loss: 0.1291\n",
      "Epoch 3/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.1158\n",
      "Epoch 4/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.1007\n",
      "Epoch 6/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0953\n",
      "Epoch 7/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0912\n",
      "Epoch 8/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0876\n",
      "Epoch 9/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0860\n",
      "Epoch 10/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0843\n",
      "Epoch 11/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0830\n",
      "Epoch 12/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0814\n",
      "Epoch 13/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0803\n",
      "Epoch 14/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0793\n",
      "Epoch 15/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0793\n",
      "Epoch 16/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0783\n",
      "Epoch 17/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0782\n",
      "Epoch 18/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0776\n",
      "Epoch 19/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0770\n",
      "Epoch 20/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0771\n",
      "Epoch 21/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0763\n",
      "Epoch 22/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0763\n",
      "Epoch 23/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0763\n",
      "Epoch 24/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0756\n",
      "Epoch 25/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0754\n",
      "Epoch 26/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0755\n",
      "Epoch 27/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0750\n",
      "Epoch 28/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0751\n",
      "Epoch 29/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0751\n",
      "Epoch 30/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0744\n",
      "Epoch 31/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0746\n",
      "Epoch 32/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 33/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0748\n",
      "Epoch 34/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0747\n",
      "Epoch 35/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0744\n",
      "Epoch 36/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0747\n",
      "Epoch 37/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0743\n",
      "Epoch 38/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0735\n",
      "Epoch 39/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0735\n",
      "Epoch 40/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0760\n",
      "Epoch 41/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0735\n",
      "Epoch 42/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0735\n",
      "Epoch 43/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0738\n",
      "Epoch 44/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0733\n",
      "Epoch 45/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0730\n",
      "Epoch 46/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0733\n",
      "Epoch 47/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0735\n",
      "Epoch 48/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0732\n",
      "Epoch 49/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0733\n",
      "Epoch 50/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0787\n",
      "Epoch 51/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0735\n",
      "Epoch 52/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0753\n",
      "Epoch 53/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0735\n",
      "Epoch 54/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0749\n",
      "Epoch 55/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0725\n",
      "Epoch 56/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0749\n",
      "Epoch 57/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0728\n",
      "Epoch 58/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0742\n",
      "Epoch 59/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0743\n",
      "Epoch 60/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0723\n",
      "Epoch 61/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0738\n",
      "Epoch 62/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0726\n",
      "Epoch 63/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0737\n",
      "Epoch 64/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0730\n",
      "Epoch 65/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0727\n",
      "Epoch 66/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0723\n",
      "Epoch 67/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0722\n",
      "Epoch 68/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0745\n",
      "Epoch 69/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0725\n",
      "Epoch 70/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0730\n",
      "Epoch 71/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0715\n",
      "Epoch 72/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0721\n",
      "Epoch 73/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0717\n",
      "Epoch 74/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0717\n",
      "Epoch 75/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0726\n",
      "Epoch 76/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0722\n",
      "Epoch 77/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0720\n",
      "Epoch 78/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0719\n",
      "Epoch 79/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0716\n",
      "Epoch 80/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0717\n",
      "Epoch 81/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0717\n",
      "Epoch 82/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0719\n",
      "Epoch 83/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0746\n",
      "Epoch 84/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0723\n",
      "Epoch 85/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0719\n",
      "Epoch 86/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0796\n",
      "Epoch 88/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0722\n",
      "Epoch 89/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0720\n",
      "Epoch 90/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0731\n",
      "Epoch 91/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0728\n",
      "Epoch 92/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0726\n",
      "Epoch 93/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0721\n",
      "Epoch 94/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0722\n",
      "Epoch 95/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0727\n",
      "Epoch 96/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0734\n",
      "Epoch 97/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0730\n",
      "Epoch 98/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0730\n",
      "Epoch 99/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0737\n",
      "Epoch 100/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0733\n",
      "Epoch 101/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0730\n",
      "Epoch 102/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0729\n",
      "Epoch 103/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0738\n",
      "Epoch 104/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0740\n",
      "Epoch 105/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0750\n",
      "Epoch 106/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0746\n",
      "Epoch 107/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0741\n",
      "Epoch 108/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0745\n",
      "Epoch 109/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0756\n",
      "Epoch 110/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0740\n",
      "Epoch 111/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0751\n",
      "Epoch 112/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0763\n",
      "Epoch 113/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0793\n",
      "Epoch 114/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0754\n",
      "Epoch 115/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0749\n",
      "Epoch 116/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0757\n",
      "Epoch 117/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0772\n",
      "Epoch 118/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0759\n",
      "Epoch 119/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0767\n",
      "Epoch 120/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0760\n",
      "Epoch 121/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0770\n",
      "Epoch 122/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0763\n",
      "Epoch 123/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0762\n",
      "Epoch 124/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0765\n",
      "Epoch 125/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0787\n",
      "Epoch 126/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0777\n",
      "Epoch 127/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0765\n",
      "Epoch 128/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0767\n",
      "Epoch 129/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0775\n",
      "Epoch 130/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0767\n",
      "Epoch 131/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0777\n",
      "Epoch 132/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0768\n",
      "Epoch 133/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0791\n",
      "Epoch 134/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0774\n",
      "Epoch 135/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0786\n",
      "Epoch 136/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0801\n",
      "Epoch 137/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0780\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0781\n",
      "Epoch 1/149\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1912 - val_loss: 0.1490\n",
      "Epoch 2/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1397\n",
      "Epoch 3/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1369 - val_loss: 0.1339\n",
      "Epoch 4/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1312 - val_loss: 0.1292\n",
      "Epoch 5/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1275 - val_loss: 0.1245\n",
      "Epoch 6/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1227\n",
      "Epoch 7/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.1200\n",
      "Epoch 8/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.1174\n",
      "Epoch 9/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.1163\n",
      "Epoch 10/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.1144\n",
      "Epoch 11/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1147 - val_loss: 0.1140\n",
      "Epoch 12/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1142 - val_loss: 0.1124\n",
      "Epoch 13/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.1120\n",
      "Epoch 14/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1123 - val_loss: 0.1105\n",
      "Epoch 15/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.1098\n",
      "Epoch 16/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.1102\n",
      "Epoch 17/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.1087\n",
      "Epoch 18/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.1086\n",
      "Epoch 19/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1079\n",
      "Epoch 20/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1083 - val_loss: 0.1080\n",
      "Epoch 21/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1083 - val_loss: 0.1074\n",
      "Epoch 22/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1078 - val_loss: 0.1073\n",
      "Epoch 23/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1078 - val_loss: 0.1071\n",
      "Epoch 24/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1063\n",
      "Epoch 25/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.1066\n",
      "Epoch 26/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.1056\n",
      "Epoch 27/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1062 - val_loss: 0.1062\n",
      "Epoch 28/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1060 - val_loss: 0.1060\n",
      "Epoch 29/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.1055\n",
      "Epoch 30/149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.1052\n",
      "Epoch 31/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.1062\n",
      "Epoch 32/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1056 - val_loss: 0.1047\n",
      "Epoch 33/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1052 - val_loss: 0.1061\n",
      "Epoch 34/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.1046\n",
      "Epoch 35/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.1052\n",
      "Epoch 36/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 0.1051\n",
      "Epoch 37/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1045\n",
      "Epoch 38/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1044\n",
      "Epoch 39/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1049\n",
      "Epoch 40/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1039 - val_loss: 0.1041\n",
      "Epoch 41/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.1046\n",
      "Epoch 42/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1039\n",
      "Epoch 43/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.1045\n",
      "Epoch 44/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1030 - val_loss: 0.1037\n",
      "Epoch 45/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1039 - val_loss: 0.1044\n",
      "Epoch 46/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.1042\n",
      "Epoch 47/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.1036\n",
      "Epoch 48/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1021 - val_loss: 0.1037\n",
      "Epoch 49/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1017 - val_loss: 0.1033\n",
      "Epoch 50/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.1038\n",
      "Epoch 51/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1025\n",
      "Epoch 52/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.1017\n",
      "Epoch 53/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.1012\n",
      "Epoch 54/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0996\n",
      "Epoch 55/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.0984\n",
      "Epoch 56/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.0966\n",
      "Epoch 57/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.0950\n",
      "Epoch 58/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.0929\n",
      "Epoch 59/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0923\n",
      "Epoch 60/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0940\n",
      "Epoch 61/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0910\n",
      "Epoch 62/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0922\n",
      "Epoch 63/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0901\n",
      "Epoch 64/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0907\n",
      "Epoch 65/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0896\n",
      "Epoch 66/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0907\n",
      "Epoch 67/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0894\n",
      "Epoch 68/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0895\n",
      "Epoch 69/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0902\n",
      "Epoch 70/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0912\n",
      "Epoch 71/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0897\n",
      "Epoch 72/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0901\n",
      "Epoch 73/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0902\n",
      "Epoch 74/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0912\n",
      "Epoch 75/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0897\n",
      "Epoch 76/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0931\n",
      "Epoch 77/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0896\n",
      "Epoch 78/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0902\n",
      "Epoch 79/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0899\n",
      "Epoch 80/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0930\n",
      "Epoch 81/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0895\n",
      "Epoch 82/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0899\n",
      "Epoch 83/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0907\n",
      "Epoch 84/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0897\n",
      "Epoch 85/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0899\n",
      "Epoch 86/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0899\n",
      "Epoch 87/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0898\n",
      "Epoch 88/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0900\n",
      "Epoch 89/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0906\n",
      "Epoch 90/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0899\n",
      "Epoch 91/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0907\n",
      "Epoch 92/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0892\n",
      "Epoch 93/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0902\n",
      "Epoch 94/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0890\n",
      "Epoch 95/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - val_loss: 0.0897\n",
      "Epoch 96/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0895\n",
      "Epoch 97/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0891\n",
      "Epoch 98/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0894\n",
      "Epoch 99/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0887\n",
      "Epoch 100/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0887\n",
      "Epoch 101/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0892\n",
      "Epoch 102/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0891\n",
      "Epoch 103/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0891\n",
      "Epoch 104/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0893\n",
      "Epoch 105/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0889\n",
      "Epoch 106/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0889\n",
      "Epoch 107/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0894\n",
      "Epoch 108/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0883\n",
      "Epoch 109/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0894\n",
      "Epoch 110/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0890\n",
      "Epoch 111/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0883\n",
      "Epoch 113/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0889\n",
      "Epoch 114/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0886\n",
      "Epoch 115/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0890\n",
      "Epoch 116/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0886\n",
      "Epoch 117/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0905\n",
      "Epoch 118/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0883\n",
      "Epoch 119/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0888\n",
      "Epoch 120/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0885\n",
      "Epoch 121/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0886\n",
      "Epoch 122/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0888\n",
      "Epoch 123/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0888\n",
      "Epoch 124/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0891\n",
      "Epoch 125/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0890\n",
      "Epoch 126/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0897\n",
      "Epoch 127/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0884\n",
      "Epoch 128/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0886\n",
      "Epoch 129/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0889\n",
      "Epoch 130/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0893\n",
      "Epoch 131/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0889\n",
      "Epoch 132/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0885\n",
      "Epoch 133/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0887\n",
      "Epoch 134/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0894\n",
      "Epoch 135/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0889\n",
      "Epoch 136/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0888\n",
      "Epoch 137/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0889\n",
      "Epoch 138/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0894\n",
      "Epoch 139/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0891\n",
      "Epoch 140/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0891\n",
      "Epoch 141/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0893\n",
      "Epoch 142/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0894\n",
      "Epoch 143/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0912\n",
      "Epoch 144/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0896\n",
      "Epoch 145/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0894\n",
      "Epoch 146/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0893\n",
      "Epoch 147/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0901\n",
      "Epoch 148/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0893\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0897\n",
      "Epoch 1/56\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1534 - val_loss: 0.1359\n",
      "Epoch 2/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1212 - val_loss: 0.1271\n",
      "Epoch 3/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1215 - val_loss: 0.1238\n",
      "Epoch 4/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1145 - val_loss: 0.1260\n",
      "Epoch 5/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1132 - val_loss: 0.1194\n",
      "Epoch 6/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.1160\n",
      "Epoch 7/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1064 - val_loss: 0.1119\n",
      "Epoch 8/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1087\n",
      "Epoch 9/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.1060\n",
      "Epoch 10/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.1037\n",
      "Epoch 11/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.1006\n",
      "Epoch 12/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.1047\n",
      "Epoch 13/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.1083\n",
      "Epoch 14/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.1111\n",
      "Epoch 15/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.1001\n",
      "Epoch 16/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.0967\n",
      "Epoch 17/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0966\n",
      "Epoch 18/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0963\n",
      "Epoch 19/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0969\n",
      "Epoch 20/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0977\n",
      "Epoch 21/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0958\n",
      "Epoch 22/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.1031\n",
      "Epoch 23/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0976\n",
      "Epoch 24/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0957\n",
      "Epoch 25/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.1015\n",
      "Epoch 26/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0984\n",
      "Epoch 27/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0960\n",
      "Epoch 28/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0961\n",
      "Epoch 29/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0963\n",
      "Epoch 30/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0939\n",
      "Epoch 31/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0977\n",
      "Epoch 32/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0952\n",
      "Epoch 33/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0974\n",
      "Epoch 34/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0958\n",
      "Epoch 35/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.1011\n",
      "Epoch 36/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0975\n",
      "Epoch 37/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0977\n",
      "Epoch 38/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0978\n",
      "Epoch 39/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0974\n",
      "Epoch 40/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.1018\n",
      "Epoch 41/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0930\n",
      "Epoch 42/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0970\n",
      "Epoch 43/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.1051\n",
      "Epoch 44/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0932\n",
      "Epoch 45/56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0948\n",
      "Epoch 46/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0922\n",
      "Epoch 47/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0976\n",
      "Epoch 48/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0929\n",
      "Epoch 49/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0943\n",
      "Epoch 50/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0953\n",
      "Epoch 51/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0953\n",
      "Epoch 52/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0963\n",
      "Epoch 53/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.1031\n",
      "Epoch 54/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0946\n",
      "Epoch 55/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0974\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0983\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2900 - val_loss: 0.1950\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1639\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1534\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1445 - val_loss: 0.1443\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1387 - val_loss: 0.1409\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1331 - val_loss: 0.1374\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1291 - val_loss: 0.1326\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1320\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.1241\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.1257\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1187\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.1183\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1193\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.1137\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.1149\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.1126\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.1092\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.1100\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.1070\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.1066\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.1055\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.1063\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.1043\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.1030\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.1100\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0995\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.1017\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0985\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0999\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0968\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.1007\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0997\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0990\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.1046\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0981\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0949\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0978\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0976\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0953\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0975\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0951\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0939\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0930\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0939\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.1006\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0946\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0963\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0919\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0954\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0946\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0942\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0927\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0940\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0919\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0919\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0964\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0985\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0916\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0945\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0926\n",
      "Epoch 1/41\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3222 - val_loss: 0.1580\n",
      "Epoch 2/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1463 - val_loss: 0.1444\n",
      "Epoch 3/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1302 - val_loss: 0.1368\n",
      "Epoch 4/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1208 - val_loss: 0.1288\n",
      "Epoch 5/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1168 - val_loss: 0.1260\n",
      "Epoch 6/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.1234\n",
      "Epoch 7/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1202\n",
      "Epoch 8/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.1179\n",
      "Epoch 9/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.1158\n",
      "Epoch 10/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.1166\n",
      "Epoch 11/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.1140\n",
      "Epoch 12/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.1097\n",
      "Epoch 13/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.1090\n",
      "Epoch 14/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1080\n",
      "Epoch 15/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.1059\n",
      "Epoch 16/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.1051\n",
      "Epoch 17/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.1124\n",
      "Epoch 18/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.1039\n",
      "Epoch 19/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.1100\n",
      "Epoch 20/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.1033\n",
      "Epoch 21/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.1028\n",
      "Epoch 22/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.1019\n",
      "Epoch 23/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.1093\n",
      "Epoch 24/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.1002\n",
      "Epoch 25/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.1015\n",
      "Epoch 26/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.1005\n",
      "Epoch 27/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.1020\n",
      "Epoch 28/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.1002\n",
      "Epoch 29/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.1032\n",
      "Epoch 30/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.1004\n",
      "Epoch 31/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.1010\n",
      "Epoch 32/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0999\n",
      "Epoch 33/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.1030\n",
      "Epoch 34/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0989\n",
      "Epoch 35/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.1010\n",
      "Epoch 36/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.1016\n",
      "Epoch 37/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.1000\n",
      "Epoch 38/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0988\n",
      "Epoch 39/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.1052\n",
      "Epoch 40/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0994\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0986\n"
     ]
    }
   ],
   "source": [
    "# learn the data of the given stocks with the given given hyper parameters\n",
    "symbols = ['QCOM','NKE','MCD','GRMN','CERN','AAPL','SCHW',\"CVX\",\"EBAY\"]\n",
    "results =learner(symbols,best_params,callback = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "abe51d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the reports from the leaner and save it locally\n",
    "reports_matrix = results[0]\n",
    "extended_reports_matrix = results[1]\n",
    "np.save('reports.npy', reports_matrix) # save\n",
    "np.save('extended reports.npy', np.array(extended_reports_matrix,dtype=object)) # save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
